{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftotext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for \"Cleaning\" and \"participants list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(contents):\n",
    "    ### Cleaning all the unwanted rows in the transcript\n",
    "    df = pd.DataFrame(contents)\n",
    "\n",
    "    # remove the unnessary string\n",
    "    df[0] = df[0].str.replace('\\n','')\n",
    "    df[0] = df[0].str.replace('Bloomberg Transcript','')\n",
    "    df[0] = df[0].str.replace('\\x0c\\n','')\n",
    "    df[0] = df[0].str.replace('FINAL','')\n",
    "    df[0] = df[0].str.replace('A - ','')\n",
    "    df[0] = df[0].str.replace('Q - ','')\n",
    "\n",
    "    # using re to remove the unnessary string\n",
    "    def drop_unnessary(x):\n",
    "        page = re.findall(r'Page \\d+ of \\d+', x) # 'page ... of ... '\n",
    "        BIO = re.findall(r'{BIO', x) # '{BIO 18731996 <GO>}'\n",
    "        Company_Name = re.findall(r'Company N ame:', x) # 'Company N ame: H annover Rueck SE'\n",
    "        Company_Ticker = re.findall(r'Company Ticker:', x) # 'Company Ticker: H N R1 GR Equity'\n",
    "        Date = re.findall(r'Date:', x) # Date: 2015-03-10\n",
    "        if page == [] and BIO == [] and Company_Name == [] and Company_Ticker == [] and Date == []:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    true_false = df[0].apply(lambda x: drop_unnessary(x))\n",
    "    df = df[true_false]\n",
    "\n",
    "    # drop the final page declaration\n",
    "    df = df[df[0] != 'This transcript may not be 100 percent accurate and may contain misspellings and other']\n",
    "    df = df[df[0] != 'inaccuracies. This transcript is provided \"as is\", without express or implied warranties of']\n",
    "    df = df[df[0] != 'any kind. Bloomberg retains all rights to this transcript and provides it solely for your']\n",
    "    df = df[df[0] != 'personal, non-commercial use. Bloomberg, its suppliers and third-party agents shall']\n",
    "    df = df[df[0] != 'have no liability for errors in this transcript or for lost profits, losses, or direct, indirect,']\n",
    "    df = df[df[0] != 'incidental, consequential, special or punitive damages in connection with the']\n",
    "    df = df[df[0] != 'furnishing, performance or use of such transcript. Neither the information nor any']\n",
    "    df = df[df[0] != 'opinion expressed in this transcript constitutes a solicitation of the purchase or sale of']\n",
    "    df = df[df[0] != 'securities or commodities. Any opinion expressed in the transcript does not necessarily']\n",
    "    # df = df[df[0] != 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights']  \n",
    "    df = df[df[0] != 'reserved. Any reproduction, redistribution or retransmission is expressly prohibited.']\n",
    "    # ¬© could not be identified, would apply re\n",
    "    def drop_Bloomberg_mark(x):\n",
    "        Bloomberg_mark = re.findall(r'reflect the views of Bloomberg LP', x) # 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights'\n",
    "        if Bloomberg_mark == []:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    true_false = df[0].apply(lambda x: drop_Bloomberg_mark(x))\n",
    "    df = df[true_false]\n",
    "\n",
    "    # drop the empthy row\n",
    "    df = df[df[0] != '']\n",
    "    df = df[df[0] != '\f']\n",
    "\n",
    "    return df\n",
    "\n",
    "def participants_list(df):\n",
    "    # reset the index to make sure the index is continuous for better processing\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #  'Company Participants' index\n",
    "    # df.loc[df[0] == 'Company Participants']\n",
    "    Participant_start_index = df.index[df.iloc[:,0] == 'Company Participants'].tolist()\n",
    "    #  'Other Participants' index\n",
    "    # df.loc[df[0] == 'Other Participants']\n",
    "    Participant_middle_index = df.index[df.iloc[:,0] == 'Other Participants'].tolist()\n",
    "    #  'MANAGEMENT DISCUSSION SECTION' index, is the beginning of the management discussion, would stop before this row\n",
    "    # df.loc[df[0] == 'MANAGEMENT DISCUSSION SECTION']\n",
    "    Participant_end_index = df.index[df.iloc[:,0] == 'MANAGEMENT DISCUSSION SECTION' ].tolist()\n",
    "    # try to find the 'MANAGEMENT DISCUSSION SECTION' or 'Presentation' index\n",
    "    if Participant_end_index == []:\n",
    "        Participant_end_index = df.index[df.iloc[:,0] == 'Presentation'].tolist()\n",
    "\n",
    "    print(Participant_start_index, Participant_middle_index, Participant_end_index)\n",
    "\n",
    "    # make the list of company_paticipants and other_participants\n",
    "    company_paticipants = df.loc[Participant_start_index[0]+1:Participant_middle_index[0]-1]\n",
    "    company_paticipants.drop(company_paticipants.index[company_paticipants.iloc[:,0] == ''].tolist(), inplace=True)\n",
    "    company_paticipants = company_paticipants.values.tolist()\n",
    "\n",
    "    other_paticipants = df.loc[Participant_middle_index[0]+1:Participant_end_index[0]-1]\n",
    "    other_paticipants.drop(other_paticipants.index[other_paticipants.iloc[:,0] == ''].tolist(), inplace=True)\n",
    "    other_paticipants = other_paticipants.values.tolist()\n",
    "\n",
    "    # print(\"==========================\")\n",
    "    # print(\"the company paticipants is: \", company_paticipants)\n",
    "    # print(\"==========================\")\n",
    "    # print(\"the other paticipants is: \", other_paticipants)\n",
    "\n",
    "    #%%\n",
    "    # after extract the paticipants, we can drop those information to make the transcript more clear\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(range(df.index[df.iloc[:,0] == 'Company Participants'].tolist()[0],df.index[df.iloc[:,0].isin(['MANAGEMENT DISCUSSION SECTION','Presentation'])].tolist()[0]+1))\n",
    "\n",
    "    # drop the first row of the df\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.iloc[1: , :]\n",
    "\n",
    "\n",
    "    # reset the index again to make sure the index is continuous for better processing\n",
    "    df = df.reset_index(drop=True)\n",
    "    # # save to csv\n",
    "    # df.to_csv('/Users/timliu/Desktop/output/df.csv')\n",
    "    return df, company_paticipants, other_paticipants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the single company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [7] [14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [10] [24]\n",
      "[1] [4] [12]\n",
      "[1] [4] [17]\n",
      "[1] [4] [17]\n",
      "[1] [5] [21]\n",
      "[1] [6] [13]\n",
      "[1] [5] [12]\n",
      "[1] [4] [17]\n",
      "[1] [4] [13]\n",
      "[1] [6] [13]\n",
      "[1] [8] [21]\n",
      "[1] [4] [16]\n",
      "[1] [6] [20]\n",
      "[1] [5] [16]\n",
      "[1] [6] [18]\n",
      "[1] [6] [14]\n",
      "[1] [11] [27]\n",
      "[1] [5] [19]\n",
      "[1] [5] [15]\n",
      "[1] [6] [16]\n",
      "[1] [4] [17]\n",
      "[1] [6] [15]\n",
      "[1] [4] [12]\n",
      "[1] [5] [12]\n",
      "[1] [4] [12]\n",
      "[2] [5] [14]\n",
      "[1] [4] [13]\n",
      "[1] [4] [12]\n",
      "[1] [10] [28]\n",
      "[1] [6] [14]\n",
      "[2] [5] [13]\n",
      "[1] [4] [15]\n",
      "[1] [4] [17]\n",
      "[1] [5] [15]\n",
      "[1] [5] [10]\n",
      "[1] [9] [17]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20211104_Hannover_Rueck_SE-_Earnings_Call_2021-11-4_RT000000002967437630.pdf</th>\n",
       "      <th>20191023_Hannover_Rueck_SE-_Shareholder_Mtg_Call_2019-10-23_SD000000002903050937.pdf</th>\n",
       "      <th>20150506_Hannover_Rueck_SE-_Earnings_Call_2015-5-6_FS000000002212304783.pdf</th>\n",
       "      <th>20160804_Hannover_Rueck_SE-_Earnings_Call_2016-8-4_SD000000002853744569.pdf</th>\n",
       "      <th>20171108_Hannover_Rueck_SE-_Earnings_Call_2017-11-8_SD000000002868833083.pdf</th>\n",
       "      <th>20160310_Hannover_Rueck_SE-_Earnings_Call_2016-3-10_FS000000002259507768.pdf</th>\n",
       "      <th>20201104_Hannover_Rueck_SE-_Earnings_Call_2020-11-4_RT000000002931797209.pdf</th>\n",
       "      <th>20210204_Hannover_Rueck_SE-_M-A_Call_2021-2-4_RT000000002949284264.pdf</th>\n",
       "      <th>20180809_Hannover_Rueck_SE-_Earnings_Call_2018-8-9_SD000000002876144587.pdf</th>\n",
       "      <th>20190507_Hannover_Rueck_SE-_Earnings_Call_2019-5-7_DN000000002633135788.pdf</th>\n",
       "      <th>...</th>\n",
       "      <th>20200205_Hannover_Rueck_SE-_M-A_Call_2020-2-5_DN000000002787035776.pdf</th>\n",
       "      <th>20160510_Hannover_Rueck_SE-_Earnings_Call_2016-5-10_FS000000002275763746.pdf</th>\n",
       "      <th>20161020_Hannover_Rueck_SE-_Guidance_Call_2016-10-20_SD000000002902464788.pdf</th>\n",
       "      <th>20210505_Hannover_Rueck_SE-_Earnings_Call_2021-5-5_DN000000002956339792.pdf</th>\n",
       "      <th>20190205_Hannover_Rueck_SE-_Guidance_Call_2019-2-5_SD000000002901846468.pdf</th>\n",
       "      <th>20181108_Hannover_Rueck_SE-_Earnings_Call_2018-11-8_SD000000002879406671.pdf</th>\n",
       "      <th>20150805_Hannover_Rueck_SE-_Earnings_Call_2015-8-5_FS000000002223534191.pdf</th>\n",
       "      <th>20190307_Hannover_Rueck_SE-_Earnings_Call_2019-3-7_DN000000002597819789.pdf</th>\n",
       "      <th>20200506_Hannover_Rueck_SE-_Earnings_Call_2020-5-6_DN000000002833326951.pdf</th>\n",
       "      <th>20211014_Hannover_Rueck_SE-_Shareholder_Mtg_Call_2021-10-14_SD000000002965861183.pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Operator</td>\n",
       "      <td>Karl Steinle</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Ulrich Wallin</td>\n",
       "      <td>Karl Steinle</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Ulrich Wallin</td>\n",
       "      <td>Operator</td>\n",
       "      <td>...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Karl Steinle</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Call</td>\n",
       "      <td>Ulrich Wallin</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Karl Steinle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Well. Good morning to all of you. Welcome to H...</td>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>Good morning, ladies and gentlemen. Welcome to...</td>\n",
       "      <td>Good morning, ladies and gentlemen. I'd like t...</td>\n",
       "      <td>Good afternoon everybody here in Frankfurt, an...</td>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Yes. Good morning, ladies and gentlemen. I'd l...</td>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Good morning ladies and gentlemen. I welcome y...</td>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>Good morning, to all of you. Welcome to Hannov...</td>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>Good morning, ladies and gentlemen. I'd like t...</td>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Well, good afternoon to everybody here in Lond...</td>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Hello. Good morning, to the Hannover Re's Inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conference Call on the Q3 2021 Financial Resul...</td>\n",
       "      <td>really delighted that so many of you were able...</td>\n",
       "      <td>Conference Call on Interim Results 1/2015. For...</td>\n",
       "      <td>conference call on interim results (technical ...</td>\n",
       "      <td>presenting the results for the first nine mont...</td>\n",
       "      <td>via the Internet. Welcome to Hannover Re's Ana...</td>\n",
       "      <td>conference call on the Q3 2020 results. For yo...</td>\n",
       "      <td>Conference Call on 1st January, 2021, Property...</td>\n",
       "      <td>presenting the results for the first half year...</td>\n",
       "      <td>Conference Call on Q1 2019 Results. For your i...</td>\n",
       "      <td>...</td>\n",
       "      <td>Conference Call on January 1, 2020 Property an...</td>\n",
       "      <td>Conference Call on Interim Results Q1 2016. Fo...</td>\n",
       "      <td>Karl Steinle. And I'm really delighted that so...</td>\n",
       "      <td>Call on the Q1 2021 Results. For your informat...</td>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>presenting our results for the first nine mont...</td>\n",
       "      <td>Conference Call on Interim Results Q2 2015. Fo...</td>\n",
       "      <td>Internet. Welcome to Hannover Re's Analyst Con...</td>\n",
       "      <td>Conference Call on Q1 2020 Financial Results. ...</td>\n",
       "      <td>on behalf of the entire management team. Again...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>being recorded. At this time, I would like to ...</td>\n",
       "      <td>Steinle. And I'm, among other things, responsi...</td>\n",
       "      <td>recorded. At this time, I would like to hand t...</td>\n",
       "      <td>is being recorded. At this time, I would like ...</td>\n",
       "      <td>Roland Vogel.</td>\n",
       "      <td>see that so many have taken up our invitation....</td>\n",
       "      <td>recorded.</td>\n",
       "      <td>information, this conference is being recorded...</td>\n",
       "      <td>Roland Vogel.</td>\n",
       "      <td>recorded. At this time, I would like to hand t...</td>\n",
       "      <td>...</td>\n",
       "      <td>information, this conference is being recorded.</td>\n",
       "      <td>recorded. At this time, I would like to hand t...</td>\n",
       "      <td>invitation for our 19th edition of this event.</td>\n",
       "      <td>this time, I would like to hand the call over ...</td>\n",
       "      <td>Conference Call on 1st of January 2019 P&amp;C Tre...</td>\n",
       "      <td>Roland Vogel.</td>\n",
       "      <td>being recorded.</td>\n",
       "      <td>truly a pleasure to see so many of you taking ...</td>\n",
       "      <td>being recorded. At this time, I would like to ...</td>\n",
       "      <td>pandemic. So we are not broadcasting from Cope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>comms.</td>\n",
       "      <td>Wallin, Chief Executive Officer. Please go ahe...</td>\n",
       "      <td>Ulrich Wallin, Chief Executive Officer. Please...</td>\n",
       "      <td>After years of moderate losses, we saw an accu...</td>\n",
       "      <td>the figures for 2015 in greater detail, which ...</td>\n",
       "      <td>At this time, I would like to hand you over to...</td>\n",
       "      <td>over to your host today, Mr.Jean-Jacques Hench...</td>\n",
       "      <td>Our business developed rather favorable in the...</td>\n",
       "      <td>Wallin, Chief Executive Officer. Please go ahe...</td>\n",
       "      <td>...</td>\n",
       "      <td>At this time, I would like to hand the call ov...</td>\n",
       "      <td>Wallin, Chief Executive Officer. Please go ahe...</td>\n",
       "      <td>Since we are keeping the annual rotating sched...</td>\n",
       "      <td>Chief Executive Officer. Please go ahead, sir.</td>\n",
       "      <td>conference is being recorded.</td>\n",
       "      <td>The most significant event that had an influen...</td>\n",
       "      <td>At this time, I would like to hand the call ov...</td>\n",
       "      <td>interest in Hannover Re. As you know, the key ...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>Hanover. I'm happy that so many of you are alr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     20211104_Hannover_Rueck_SE-_Earnings_Call_2021-11-4_RT000000002967437630.pdf  \\\n",
       "0                                              Operator                             \n",
       "1     Good morning, ladies and gentlemen. I welcome ...                             \n",
       "2     Conference Call on the Q3 2021 Financial Resul...                             \n",
       "3     being recorded. At this time, I would like to ...                             \n",
       "4                                  Jean-Jacques Henchoz                             \n",
       "...                                                 ...                             \n",
       "2495                                                NaN                             \n",
       "2496                                                NaN                             \n",
       "2497                                                NaN                             \n",
       "2498                                                NaN                             \n",
       "2499                                                NaN                             \n",
       "\n",
       "     20191023_Hannover_Rueck_SE-_Shareholder_Mtg_Call_2019-10-23_SD000000002903050937.pdf  \\\n",
       "0                                          Karl Steinle                                     \n",
       "1     Well. Good morning to all of you. Welcome to H...                                     \n",
       "2     really delighted that so many of you were able...                                     \n",
       "3     Steinle. And I'm, among other things, responsi...                                     \n",
       "4                                                comms.                                     \n",
       "...                                                 ...                                     \n",
       "2495                                                NaN                                     \n",
       "2496                                                NaN                                     \n",
       "2497                                                NaN                                     \n",
       "2498                                                NaN                                     \n",
       "2499                                                NaN                                     \n",
       "\n",
       "     20150506_Hannover_Rueck_SE-_Earnings_Call_2015-5-6_FS000000002212304783.pdf  \\\n",
       "0                                              Operator                            \n",
       "1     Good morning, ladies and gentlemen, and welcom...                            \n",
       "2     Conference Call on Interim Results 1/2015. For...                            \n",
       "3     recorded. At this time, I would like to hand t...                            \n",
       "4     Wallin, Chief Executive Officer. Please go ahe...                            \n",
       "...                                                 ...                            \n",
       "2495                                                NaN                            \n",
       "2496                                                NaN                            \n",
       "2497                                                NaN                            \n",
       "2498                                                NaN                            \n",
       "2499                                                NaN                            \n",
       "\n",
       "     20160804_Hannover_Rueck_SE-_Earnings_Call_2016-8-4_SD000000002853744569.pdf  \\\n",
       "0                                              Operator                            \n",
       "1     Good morning, ladies and gentlemen. Welcome to...                            \n",
       "2     conference call on interim results (technical ...                            \n",
       "3     is being recorded. At this time, I would like ...                            \n",
       "4     Ulrich Wallin, Chief Executive Officer. Please...                            \n",
       "...                                                 ...                            \n",
       "2495                                                NaN                            \n",
       "2496                                                NaN                            \n",
       "2497                                                NaN                            \n",
       "2498                                                NaN                            \n",
       "2499                                                NaN                            \n",
       "\n",
       "     20171108_Hannover_Rueck_SE-_Earnings_Call_2017-11-8_SD000000002868833083.pdf  \\\n",
       "0                                         Ulrich Wallin                             \n",
       "1     Good morning, ladies and gentlemen. I'd like t...                             \n",
       "2     presenting the results for the first nine mont...                             \n",
       "3                                         Roland Vogel.                             \n",
       "4     After years of moderate losses, we saw an accu...                             \n",
       "...                                                 ...                             \n",
       "2495                                                NaN                             \n",
       "2496                                                NaN                             \n",
       "2497                                                NaN                             \n",
       "2498                                                NaN                             \n",
       "2499                                                NaN                             \n",
       "\n",
       "     20160310_Hannover_Rueck_SE-_Earnings_Call_2016-3-10_FS000000002259507768.pdf  \\\n",
       "0                                          Karl Steinle                             \n",
       "1     Good afternoon everybody here in Frankfurt, an...                             \n",
       "2     via the Internet. Welcome to Hannover Re's Ana...                             \n",
       "3     see that so many have taken up our invitation....                             \n",
       "4     the figures for 2015 in greater detail, which ...                             \n",
       "...                                                 ...                             \n",
       "2495                                                NaN                             \n",
       "2496                                                NaN                             \n",
       "2497                                                NaN                             \n",
       "2498                                                NaN                             \n",
       "2499                                                NaN                             \n",
       "\n",
       "     20201104_Hannover_Rueck_SE-_Earnings_Call_2020-11-4_RT000000002931797209.pdf  \\\n",
       "0                                              Operator                             \n",
       "1     Good morning, ladies and gentlemen. I welcome ...                             \n",
       "2     conference call on the Q3 2020 results. For yo...                             \n",
       "3                                             recorded.                             \n",
       "4     At this time, I would like to hand you over to...                             \n",
       "...                                                 ...                             \n",
       "2495                                                NaN                             \n",
       "2496                                                NaN                             \n",
       "2497                                                NaN                             \n",
       "2498                                                NaN                             \n",
       "2499                                                NaN                             \n",
       "\n",
       "     20210204_Hannover_Rueck_SE-_M-A_Call_2021-2-4_RT000000002949284264.pdf  \\\n",
       "0                                              Operator                       \n",
       "1     Good morning, ladies and gentlemen. I welcome ...                       \n",
       "2     Conference Call on 1st January, 2021, Property...                       \n",
       "3     information, this conference is being recorded...                       \n",
       "4     over to your host today, Mr.Jean-Jacques Hench...                       \n",
       "...                                                 ...                       \n",
       "2495                                                NaN                       \n",
       "2496                                                NaN                       \n",
       "2497                                                NaN                       \n",
       "2498                                                NaN                       \n",
       "2499                                                NaN                       \n",
       "\n",
       "     20180809_Hannover_Rueck_SE-_Earnings_Call_2018-8-9_SD000000002876144587.pdf  \\\n",
       "0                                         Ulrich Wallin                            \n",
       "1     Yes. Good morning, ladies and gentlemen. I'd l...                            \n",
       "2     presenting the results for the first half year...                            \n",
       "3                                         Roland Vogel.                            \n",
       "4     Our business developed rather favorable in the...                            \n",
       "...                                                 ...                            \n",
       "2495                                                NaN                            \n",
       "2496                                                NaN                            \n",
       "2497                                                NaN                            \n",
       "2498                                                NaN                            \n",
       "2499                                                NaN                            \n",
       "\n",
       "     20190507_Hannover_Rueck_SE-_Earnings_Call_2019-5-7_DN000000002633135788.pdf  \\\n",
       "0                                              Operator                            \n",
       "1     Good morning, ladies and gentlemen. I welcome ...                            \n",
       "2     Conference Call on Q1 2019 Results. For your i...                            \n",
       "3     recorded. At this time, I would like to hand t...                            \n",
       "4     Wallin, Chief Executive Officer. Please go ahe...                            \n",
       "...                                                 ...                            \n",
       "2495                                                NaN                            \n",
       "2496                                                NaN                            \n",
       "2497                                                NaN                            \n",
       "2498                                                NaN                            \n",
       "2499                                                NaN                            \n",
       "\n",
       "      ...  \\\n",
       "0     ...   \n",
       "1     ...   \n",
       "2     ...   \n",
       "3     ...   \n",
       "4     ...   \n",
       "...   ...   \n",
       "2495  ...   \n",
       "2496  ...   \n",
       "2497  ...   \n",
       "2498  ...   \n",
       "2499  ...   \n",
       "\n",
       "     20200205_Hannover_Rueck_SE-_M-A_Call_2020-2-5_DN000000002787035776.pdf  \\\n",
       "0                                              Operator                       \n",
       "1     Good morning ladies and gentlemen. I welcome y...                       \n",
       "2     Conference Call on January 1, 2020 Property an...                       \n",
       "3       information, this conference is being recorded.                       \n",
       "4     At this time, I would like to hand the call ov...                       \n",
       "...                                                 ...                       \n",
       "2495                                                NaN                       \n",
       "2496                                                NaN                       \n",
       "2497                                                NaN                       \n",
       "2498                                                NaN                       \n",
       "2499                                                NaN                       \n",
       "\n",
       "     20160510_Hannover_Rueck_SE-_Earnings_Call_2016-5-10_FS000000002275763746.pdf  \\\n",
       "0                                              Operator                             \n",
       "1     Good morning, ladies and gentlemen, and welcom...                             \n",
       "2     Conference Call on Interim Results Q1 2016. Fo...                             \n",
       "3     recorded. At this time, I would like to hand t...                             \n",
       "4     Wallin, Chief Executive Officer. Please go ahe...                             \n",
       "...                                                 ...                             \n",
       "2495                                                NaN                             \n",
       "2496                                                NaN                             \n",
       "2497                                                NaN                             \n",
       "2498                                                NaN                             \n",
       "2499                                                NaN                             \n",
       "\n",
       "     20161020_Hannover_Rueck_SE-_Guidance_Call_2016-10-20_SD000000002902464788.pdf  \\\n",
       "0                                          Karl Steinle                              \n",
       "1     Good morning, to all of you. Welcome to Hannov...                              \n",
       "2     Karl Steinle. And I'm really delighted that so...                              \n",
       "3        invitation for our 19th edition of this event.                              \n",
       "4     Since we are keeping the annual rotating sched...                              \n",
       "...                                                 ...                              \n",
       "2495                                                NaN                              \n",
       "2496                                                NaN                              \n",
       "2497                                                NaN                              \n",
       "2498                                                NaN                              \n",
       "2499                                                NaN                              \n",
       "\n",
       "     20210505_Hannover_Rueck_SE-_Earnings_Call_2021-5-5_DN000000002956339792.pdf  \\\n",
       "0                                              Operator                            \n",
       "1     Good morning, ladies and gentlemen. I welcome ...                            \n",
       "2     Call on the Q1 2021 Results. For your informat...                            \n",
       "3     this time, I would like to hand the call over ...                            \n",
       "4        Chief Executive Officer. Please go ahead, sir.                            \n",
       "...                                                 ...                            \n",
       "2495                                                NaN                            \n",
       "2496                                                NaN                            \n",
       "2497                                                NaN                            \n",
       "2498                                                NaN                            \n",
       "2499                                                NaN                            \n",
       "\n",
       "     20190205_Hannover_Rueck_SE-_Guidance_Call_2019-2-5_SD000000002901846468.pdf  \\\n",
       "0                                                  Call                            \n",
       "1                                              Operator                            \n",
       "2     Good morning, ladies and gentlemen. I welcome ...                            \n",
       "3     Conference Call on 1st of January 2019 P&C Tre...                            \n",
       "4                         conference is being recorded.                            \n",
       "...                                                 ...                            \n",
       "2495                                                NaN                            \n",
       "2496                                                NaN                            \n",
       "2497                                                NaN                            \n",
       "2498                                                NaN                            \n",
       "2499                                                NaN                            \n",
       "\n",
       "     20181108_Hannover_Rueck_SE-_Earnings_Call_2018-11-8_SD000000002879406671.pdf  \\\n",
       "0                                         Ulrich Wallin                             \n",
       "1     Good morning, ladies and gentlemen. I'd like t...                             \n",
       "2     presenting our results for the first nine mont...                             \n",
       "3                                         Roland Vogel.                             \n",
       "4     The most significant event that had an influen...                             \n",
       "...                                                 ...                             \n",
       "2495                                                NaN                             \n",
       "2496                                                NaN                             \n",
       "2497                                                NaN                             \n",
       "2498                                                NaN                             \n",
       "2499                                                NaN                             \n",
       "\n",
       "     20150805_Hannover_Rueck_SE-_Earnings_Call_2015-8-5_FS000000002223534191.pdf  \\\n",
       "0                                              Operator                            \n",
       "1     Good morning, ladies and gentlemen. I welcome ...                            \n",
       "2     Conference Call on Interim Results Q2 2015. Fo...                            \n",
       "3                                       being recorded.                            \n",
       "4     At this time, I would like to hand the call ov...                            \n",
       "...                                                 ...                            \n",
       "2495                                                NaN                            \n",
       "2496                                                NaN                            \n",
       "2497                                                NaN                            \n",
       "2498                                                NaN                            \n",
       "2499                                                NaN                            \n",
       "\n",
       "     20190307_Hannover_Rueck_SE-_Earnings_Call_2019-3-7_DN000000002597819789.pdf  \\\n",
       "0                                              Operator                            \n",
       "1     Well, good afternoon to everybody here in Lond...                            \n",
       "2     Internet. Welcome to Hannover Re's Analyst Con...                            \n",
       "3     truly a pleasure to see so many of you taking ...                            \n",
       "4     interest in Hannover Re. As you know, the key ...                            \n",
       "...                                                 ...                            \n",
       "2495                                                NaN                            \n",
       "2496                                                NaN                            \n",
       "2497                                                NaN                            \n",
       "2498                                                NaN                            \n",
       "2499                                                NaN                            \n",
       "\n",
       "     20200506_Hannover_Rueck_SE-_Earnings_Call_2020-5-6_DN000000002833326951.pdf  \\\n",
       "0                                              Operator                            \n",
       "1     Good morning, ladies and gentlemen. I welcome ...                            \n",
       "2     Conference Call on Q1 2020 Financial Results. ...                            \n",
       "3     being recorded. At this time, I would like to ...                            \n",
       "4                                  Jean-Jacques Henchoz                            \n",
       "...                                                 ...                            \n",
       "2495                                                NaN                            \n",
       "2496                                                NaN                            \n",
       "2497                                                NaN                            \n",
       "2498                                                NaN                            \n",
       "2499                                                NaN                            \n",
       "\n",
       "     20211014_Hannover_Rueck_SE-_Shareholder_Mtg_Call_2021-10-14_SD000000002965861183.pdf  \n",
       "0                                          Karl Steinle                                    \n",
       "1     Hello. Good morning, to the Hannover Re's Inve...                                    \n",
       "2     on behalf of the entire management team. Again...                                    \n",
       "3     pandemic. So we are not broadcasting from Cope...                                    \n",
       "4     Hanover. I'm happy that so many of you are alr...                                    \n",
       "...                                                 ...                                    \n",
       "2495                                                NaN                                    \n",
       "2496                                                NaN                                    \n",
       "2497                                                NaN                                    \n",
       "2498                                                NaN                                    \n",
       "2499                                                NaN                                    \n",
       "\n",
       "[2500 rows x 37 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/timliu/Documents/GitHub/data_collecting/BBG_original_file/European (Re)Insurers/HNR1 GY\" #資料夾目錄\n",
    "save_path = \"/Users/timliu/Documents/GitHub/data_collecting/output/HNR1 GY_text\"\n",
    "df = pd.DataFrame()\n",
    "# create a dataframe with 2500 rows\n",
    "df_clean_na = pd.DataFrame(np.zeros((2500,1)), columns=['index'])\n",
    "\n",
    "all_participants = []\n",
    "\n",
    "files= os.listdir(path) #得到資料夾下的所有檔名稱\n",
    "for file in files:\n",
    "    if file.endswith(\".pdf\"):\n",
    "        # print(file)\n",
    "        # Load PDF\n",
    "        with open(path+\"/\"+file, \"rb\") as f:\n",
    "            pdf = pdftotext.PDF(f)\n",
    "        # Save all text to a txt file.\n",
    "        with open(save_path+\"/\"+file.replace(\".pdf\", \".txt\"), \"w\") as f:\n",
    "            f.write(\"\\n\\n\".join(pdf))\n",
    "        # open the text file\n",
    "        with open(save_path+\"/\"+file.replace(\".pdf\", \".txt\")) as f:\n",
    "            contents = f.readlines()\n",
    "            df_clean = cleaning_text(contents)\n",
    "            # extract all the participants\n",
    "            df_pure_text,company_paticipants,other_paticipants = participants_list(df_clean)\n",
    "            all_participants.append(company_paticipants)\n",
    "            all_participants.append(other_paticipants)\n",
    "            # using the file name to set as the dataframe's column name\n",
    "            # df[f\"{files.index(file)}\"] = df_clean\n",
    "            df[f\"{files[files.index(file)]}\"] = df_pure_text\n",
    "            df_clean_na[f\"{files[files.index(file)]}\"] = df[f\"{files[files.index(file)]}\"].dropna(inplace=False).reset_index(drop=True)\n",
    "\n",
    "# drop the first column of the df\n",
    "df_clean_na = df_clean_na.iloc[:,1:]\n",
    "df_clean_na\n",
    "\n",
    "# save the dataframe\n",
    "# df_clean_na.to_csv('/Users/timliu/Documents/GitHub/data_collecting/output/test/df_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All participants in the single company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value inside the all_participants \n",
    "all_participants = [item for sublist in all_participants for item in sublist]\n",
    "all_participants = [i[0] for i in all_participants]\n",
    "# print(all_participants)\n",
    "# %%\n",
    "# exclude the title of the participants, i.e.'Roland Vogel, CFO' to 'Roland Vogel\" by using re\n",
    "all_participants = [re.sub(r'\\,.*', '', participant) for participant in all_participants]\n",
    "# exclude the 'Property & Casualty Reinsurance'\n",
    "all_participants = [re.sub(r'Property & Casualty Reinsurance', '', participant) for participant in all_participants]\n",
    "# exclude the '[0682QB-E Ulrich Wallin]'\n",
    "all_participants = [re.sub(r'\\[0682QB-E Ulrich Wallin\\]', '', participant) for participant in all_participants]\n",
    "# drop duplicated participants\n",
    "# all_participants = [i[0] for i in all_participants]\n",
    "# drop the empty string\n",
    "all_participants = [participant for participant in all_participants if participant != '']\n",
    "# remove the sapce in the string\n",
    "all_participants = [participant.strip() for participant in all_participants]\n",
    "# add the 'Operator' to the list\n",
    "all_participants.append('Operator')\n",
    "\n",
    "# drop the duplicated participants\n",
    "all_participants_copy = all_participants.copy()\n",
    "all_participants = []\n",
    "# drop the duplicated participants\n",
    "for i in all_participants_copy: \n",
    "    if i not in all_participants: \n",
    "        all_participants.append(i) \n",
    "\n",
    "all_participants = sorted(all_participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anasuya Iyer',\n",
       " 'Andreas Maerkert',\n",
       " 'Andreas Markert',\n",
       " 'Andreas MÃ¤rkert',\n",
       " 'Andreas Schaefer',\n",
       " 'Andreas Schafer',\n",
       " 'Andreas SchÃ¤fer',\n",
       " 'Andreas Schäfer',\n",
       " 'Andrew Broadfield',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Andrew James Ritchie',\n",
       " 'Andrew Richie',\n",
       " 'Andrew Ritchie',\n",
       " 'Andy D. Broadfield',\n",
       " 'Ashik Musaddi',\n",
       " 'Ben Cohen',\n",
       " 'Bill Hawkins',\n",
       " 'Claude Chevre',\n",
       " 'Claude Jacques Chevre',\n",
       " 'Claude Jacques ChÃ¨vre',\n",
       " 'Clemens Jungsthofel',\n",
       " 'Daniel Bischof',\n",
       " 'Darius Satkauskas',\n",
       " 'Dieter Hein',\n",
       " 'Eberhard Mueller',\n",
       " 'Edward Morris',\n",
       " 'Emanuele Musio',\n",
       " 'Farooq Hanif',\n",
       " 'Frank Kopfinger',\n",
       " 'Guilhem Horvath',\n",
       " 'Henry Heathfield',\n",
       " 'Iain Pearce',\n",
       " 'In-Yong Hwang',\n",
       " 'Ivan Bokhmat',\n",
       " 'James Austin Shuck',\n",
       " 'James R Oram',\n",
       " 'James Shuck',\n",
       " 'Janet Van den Berg',\n",
       " 'Jean-Jacques Hencho',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Jochen Schmitt',\n",
       " 'Jonathan Denham',\n",
       " 'Jonathan Peter Phillip Urwin',\n",
       " 'Jonathan Urwin',\n",
       " 'Jonny Urwin',\n",
       " 'Juergen Graeber',\n",
       " 'JÃ¼rgen GrÃ¤ber',\n",
       " 'Kamran Hossain',\n",
       " 'Karl Steinle',\n",
       " 'Klaus Miller',\n",
       " 'Klaus Wilhelm Miller',\n",
       " 'Michael Haid',\n",
       " 'Michael Hermann Haid',\n",
       " 'Michael Huttner',\n",
       " 'Michael I. Huttner',\n",
       " 'Michael Pickel',\n",
       " 'Nadine van der Meulen',\n",
       " 'Olivia Brindle',\n",
       " 'Olivia S. Brindle',\n",
       " 'Olivia Sylvia Brindle',\n",
       " 'Operator',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Peter Casanova',\n",
       " 'Philipp Häßler',\n",
       " 'Property and Casual Reinsurance',\n",
       " 'Rafael Villarreal',\n",
       " 'Roland Helmut Vogel',\n",
       " 'Roland Pfaender',\n",
       " 'Roland Pfander',\n",
       " 'Roland PfÃ¤nder',\n",
       " 'Roland Pfänder',\n",
       " 'Roland Vogel',\n",
       " 'Rötger Franz',\n",
       " 'Sami Taipalus',\n",
       " 'Silke Sehm',\n",
       " 'Stefan Scharff',\n",
       " 'Sven Althoff',\n",
       " 'Thilo Gorlt',\n",
       " 'Thomas Fossard',\n",
       " 'Thomas Seidl',\n",
       " 'Tim Friebertshäuser',\n",
       " 'Ulrich Wallin',\n",
       " 'Unidentified Participant',\n",
       " 'Unidentified Speaker',\n",
       " 'Unverified Participant',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Will Hardcastle',\n",
       " 'William Fraser Hardcastle',\n",
       " 'William Hardcastle',\n",
       " 'William Hawkins',\n",
       " 'Xin Mei Wang',\n",
       " 'Xinmei Wang']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "# identify the len before NaN of each column\n",
    "for column in df_clean_na.columns:\n",
    "    # end_index = len(df_clean_na[column])-df_clean_na.isnull().sum(axis = 0)[column]-1\n",
    "    # # 這邊要注意775是NaN 所以774還是有值的\n",
    "    # identify all the rows in df with all_participants in it\n",
    "    both_participants_row_index = df_clean_na[df_clean_na[column].isin(all_participants)].index.tolist()\n",
    "    # # append the end_index to the end of both_participants_row_index\n",
    "    # both_participants_row_index.append(end_index)\n",
    "    # apply the both_participants_row_index to the df_clean_na['participants']\n",
    "    new_df[column] = df_clean_na[column]\n",
    "    new_df[f\"participants_{column}\"] = df_clean_na[column].apply(lambda x: x if x in all_participants else np.nan)\n",
    "    # fill the NaN with the value of the previous row\n",
    "    new_df[f\"participants_{column}\"] = new_df[f\"participants_{column}\"].fillna(method='ffill')\n",
    "    # # exclude the row if pure_df[column]==pure_df[f\"participants_{column}\"]\n",
    "    # pure_df = pure_df[pure_df[column] != pure_df[f\"participants_{column}\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split with the file and add the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20211104_Hannover_Rueck_SE-_Earnings_Call_2021...</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well. Good morning to all of you. Welcome to H...</td>\n",
       "      <td>20191023_Hannover_Rueck_SE-_Shareholder_Mtg_Ca...</td>\n",
       "      <td>2019-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>20150506_Hannover_Rueck_SE-_Earnings_Call_2015...</td>\n",
       "      <td>2015-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good morning, ladies and gentlemen. Welcome to...</td>\n",
       "      <td>20160804_Hannover_Rueck_SE-_Earnings_Call_2016...</td>\n",
       "      <td>2016-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good morning, ladies and gentlemen. I'd like t...</td>\n",
       "      <td>20171108_Hannover_Rueck_SE-_Earnings_Call_2017...</td>\n",
       "      <td>2017-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Good afternoon everybody here in Frankfurt, an...</td>\n",
       "      <td>20160310_Hannover_Rueck_SE-_Earnings_Call_2016...</td>\n",
       "      <td>2016-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20201104_Hannover_Rueck_SE-_Earnings_Call_2020...</td>\n",
       "      <td>2020-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20210204_Hannover_Rueck_SE-_M-A_Call_2021-2-4_...</td>\n",
       "      <td>2021-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yes. Good morning, ladies and gentlemen. I'd l...</td>\n",
       "      <td>20180809_Hannover_Rueck_SE-_Earnings_Call_2018...</td>\n",
       "      <td>2018-08-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20190507_Hannover_Rueck_SE-_Earnings_Call_2019...</td>\n",
       "      <td>2019-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20200805_Hannover_Rueck_SE-_Earnings_Call_2020...</td>\n",
       "      <td>2020-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Well. Good morning to all of you. Welcome to H...</td>\n",
       "      <td>20171019_Hannover_Rueck_SE-_Shareholder_Mtg_Ca...</td>\n",
       "      <td>2017-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Good morning, ladies and gentlemen. Welcome to...</td>\n",
       "      <td>20170810_Hannover_Rueck_SE-_Earnings_Call_2017...</td>\n",
       "      <td>2017-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Good afternoon to everybody here in Frankfurt ...</td>\n",
       "      <td>20180313_Hannover_Rueck_SE-_Earnings_Call_2018...</td>\n",
       "      <td>2018-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Good afternoon to everybody here in London at ...</td>\n",
       "      <td>20170309_Hannover_Rueck_SE-_Earnings_Call_2017...</td>\n",
       "      <td>2017-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Well, good afternoon to everybody here in Lond...</td>\n",
       "      <td>20150310_Hannover_Rueck_SE-_Earnings_Call_2015...</td>\n",
       "      <td>2015-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Good morning, ladies and gentlemen, I welcome ...</td>\n",
       "      <td>20210805_Hannover_Rueck_SE-_Earnings_Call_2021...</td>\n",
       "      <td>2021-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Good morning, to all of you. Welcome to Hannov...</td>\n",
       "      <td>20151014_Hannover_Rueck_SE-_Guidance_Call_2015...</td>\n",
       "      <td>2015-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Good morning, ladies and gentlemen and welcome...</td>\n",
       "      <td>20191106_Hannover_Rueck_SE-_Earnings_Call_2019...</td>\n",
       "      <td>2019-11-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>20180507_Hannover_Rueck_SE-_Earnings_Call_2018...</td>\n",
       "      <td>2018-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thank you very much. Good morning, ladies and ...</td>\n",
       "      <td>20190808_Hannover_Rueck_SE-_Earnings_Call_2019...</td>\n",
       "      <td>2019-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Welcome to today's Hannover Re International C...</td>\n",
       "      <td>20151104_Hannover_Rueck_SE-_Earnings_Call_2015...</td>\n",
       "      <td>2015-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Good afternoon, ladies and gentlemen. I welcom...</td>\n",
       "      <td>20200311_Hannover_Rueck_SE-_Earnings_Call_2020...</td>\n",
       "      <td>2020-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Good morning, ladies and gentlemen and welcome...</td>\n",
       "      <td>20161110_Hannover_Rueck_SE-_Earnings_Call_2016...</td>\n",
       "      <td>2016-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Good afternoon, ladies and gentlemen. I welcom...</td>\n",
       "      <td>20210311_Hannover_Rueck_SE-_Earnings_Call_2021...</td>\n",
       "      <td>2021-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>20170510_Hannover_Rueck_SE-_Earnings_Call_2017...</td>\n",
       "      <td>2017-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Operator. Ladies and gentlemen, welcome to tod...</td>\n",
       "      <td>20180207_Hannover_Rueck_SE-_Guidance_Call_2018...</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Good morning ladies and gentlemen. I welcome y...</td>\n",
       "      <td>20200205_Hannover_Rueck_SE-_M-A_Call_2020-2-5_...</td>\n",
       "      <td>2020-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>20160510_Hannover_Rueck_SE-_Earnings_Call_2016...</td>\n",
       "      <td>2016-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Good morning, to all of you. Welcome to Hannov...</td>\n",
       "      <td>20161020_Hannover_Rueck_SE-_Guidance_Call_2016...</td>\n",
       "      <td>2016-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20210505_Hannover_Rueck_SE-_Earnings_Call_2021...</td>\n",
       "      <td>2021-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Operator. Good morning, ladies and gentlemen. ...</td>\n",
       "      <td>20190205_Hannover_Rueck_SE-_Guidance_Call_2019...</td>\n",
       "      <td>2019-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Good morning, ladies and gentlemen. I'd like t...</td>\n",
       "      <td>20181108_Hannover_Rueck_SE-_Earnings_Call_2018...</td>\n",
       "      <td>2018-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20150805_Hannover_Rueck_SE-_Earnings_Call_2015...</td>\n",
       "      <td>2015-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Well, good afternoon to everybody here in Lond...</td>\n",
       "      <td>20190307_Hannover_Rueck_SE-_Earnings_Call_2019...</td>\n",
       "      <td>2019-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20200506_Hannover_Rueck_SE-_Earnings_Call_2020...</td>\n",
       "      <td>2020-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Hello. Good morning, to the Hannover Re's Inve...</td>\n",
       "      <td>20211014_Hannover_Rueck_SE-_Shareholder_Mtg_Ca...</td>\n",
       "      <td>2021-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         meeting_text  \\\n",
       "0   Good morning, ladies and gentlemen. I welcome ...   \n",
       "1   Well. Good morning to all of you. Welcome to H...   \n",
       "2   Good morning, ladies and gentlemen, and welcom...   \n",
       "3   Good morning, ladies and gentlemen. Welcome to...   \n",
       "4   Good morning, ladies and gentlemen. I'd like t...   \n",
       "5   Good afternoon everybody here in Frankfurt, an...   \n",
       "6   Good morning, ladies and gentlemen. I welcome ...   \n",
       "7   Good morning, ladies and gentlemen. I welcome ...   \n",
       "8   Yes. Good morning, ladies and gentlemen. I'd l...   \n",
       "9   Good morning, ladies and gentlemen. I welcome ...   \n",
       "10  Good morning, ladies and gentlemen. I welcome ...   \n",
       "11  Well. Good morning to all of you. Welcome to H...   \n",
       "12  Good morning, ladies and gentlemen. Welcome to...   \n",
       "13  Good afternoon to everybody here in Frankfurt ...   \n",
       "14  Good afternoon to everybody here in London at ...   \n",
       "15  Well, good afternoon to everybody here in Lond...   \n",
       "16  Good morning, ladies and gentlemen, I welcome ...   \n",
       "17  Good morning, to all of you. Welcome to Hannov...   \n",
       "18  Good morning, ladies and gentlemen and welcome...   \n",
       "19  Good morning, ladies and gentlemen, and welcom...   \n",
       "20  Thank you very much. Good morning, ladies and ...   \n",
       "21  Welcome to today's Hannover Re International C...   \n",
       "22  Good afternoon, ladies and gentlemen. I welcom...   \n",
       "23  Good morning, ladies and gentlemen and welcome...   \n",
       "24  Good afternoon, ladies and gentlemen. I welcom...   \n",
       "25  Good morning, ladies and gentlemen, and welcom...   \n",
       "26  Operator. Ladies and gentlemen, welcome to tod...   \n",
       "27  Good morning ladies and gentlemen. I welcome y...   \n",
       "28  Good morning, ladies and gentlemen, and welcom...   \n",
       "29  Good morning, to all of you. Welcome to Hannov...   \n",
       "30  Good morning, ladies and gentlemen. I welcome ...   \n",
       "31  Operator. Good morning, ladies and gentlemen. ...   \n",
       "32  Good morning, ladies and gentlemen. I'd like t...   \n",
       "33  Good morning, ladies and gentlemen. I welcome ...   \n",
       "34  Well, good afternoon to everybody here in Lond...   \n",
       "35  Good morning, ladies and gentlemen. I welcome ...   \n",
       "36  Hello. Good morning, to the Hannover Re's Inve...   \n",
       "\n",
       "                                            file_name       date  \n",
       "0   20211104_Hannover_Rueck_SE-_Earnings_Call_2021... 2021-11-04  \n",
       "1   20191023_Hannover_Rueck_SE-_Shareholder_Mtg_Ca... 2019-10-23  \n",
       "2   20150506_Hannover_Rueck_SE-_Earnings_Call_2015... 2015-05-06  \n",
       "3   20160804_Hannover_Rueck_SE-_Earnings_Call_2016... 2016-08-04  \n",
       "4   20171108_Hannover_Rueck_SE-_Earnings_Call_2017... 2017-11-08  \n",
       "5   20160310_Hannover_Rueck_SE-_Earnings_Call_2016... 2016-03-10  \n",
       "6   20201104_Hannover_Rueck_SE-_Earnings_Call_2020... 2020-11-04  \n",
       "7   20210204_Hannover_Rueck_SE-_M-A_Call_2021-2-4_... 2021-02-04  \n",
       "8   20180809_Hannover_Rueck_SE-_Earnings_Call_2018... 2018-08-09  \n",
       "9   20190507_Hannover_Rueck_SE-_Earnings_Call_2019... 2019-05-07  \n",
       "10  20200805_Hannover_Rueck_SE-_Earnings_Call_2020... 2020-08-05  \n",
       "11  20171019_Hannover_Rueck_SE-_Shareholder_Mtg_Ca... 2017-10-19  \n",
       "12  20170810_Hannover_Rueck_SE-_Earnings_Call_2017... 2017-08-10  \n",
       "13  20180313_Hannover_Rueck_SE-_Earnings_Call_2018... 2018-03-13  \n",
       "14  20170309_Hannover_Rueck_SE-_Earnings_Call_2017... 2017-03-09  \n",
       "15  20150310_Hannover_Rueck_SE-_Earnings_Call_2015... 2015-03-10  \n",
       "16  20210805_Hannover_Rueck_SE-_Earnings_Call_2021... 2021-08-05  \n",
       "17  20151014_Hannover_Rueck_SE-_Guidance_Call_2015... 2015-10-14  \n",
       "18  20191106_Hannover_Rueck_SE-_Earnings_Call_2019... 2019-11-06  \n",
       "19  20180507_Hannover_Rueck_SE-_Earnings_Call_2018... 2018-05-07  \n",
       "20  20190808_Hannover_Rueck_SE-_Earnings_Call_2019... 2019-08-08  \n",
       "21  20151104_Hannover_Rueck_SE-_Earnings_Call_2015... 2015-11-04  \n",
       "22  20200311_Hannover_Rueck_SE-_Earnings_Call_2020... 2020-03-11  \n",
       "23  20161110_Hannover_Rueck_SE-_Earnings_Call_2016... 2016-11-10  \n",
       "24  20210311_Hannover_Rueck_SE-_Earnings_Call_2021... 2021-03-11  \n",
       "25  20170510_Hannover_Rueck_SE-_Earnings_Call_2017... 2017-05-10  \n",
       "26  20180207_Hannover_Rueck_SE-_Guidance_Call_2018... 2018-02-07  \n",
       "27  20200205_Hannover_Rueck_SE-_M-A_Call_2020-2-5_... 2020-02-05  \n",
       "28  20160510_Hannover_Rueck_SE-_Earnings_Call_2016... 2016-05-10  \n",
       "29  20161020_Hannover_Rueck_SE-_Guidance_Call_2016... 2016-10-20  \n",
       "30  20210505_Hannover_Rueck_SE-_Earnings_Call_2021... 2021-05-05  \n",
       "31  20190205_Hannover_Rueck_SE-_Guidance_Call_2019... 2019-02-05  \n",
       "32  20181108_Hannover_Rueck_SE-_Earnings_Call_2018... 2018-11-08  \n",
       "33  20150805_Hannover_Rueck_SE-_Earnings_Call_2015... 2015-08-05  \n",
       "34  20190307_Hannover_Rueck_SE-_Earnings_Call_2019... 2019-03-07  \n",
       "35  20200506_Hannover_Rueck_SE-_Earnings_Call_2020... 2020-05-06  \n",
       "36  20211014_Hannover_Rueck_SE-_Shareholder_Mtg_Ca... 2021-10-14  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_df = pd.DataFrame()\n",
    "# identify the len before NaN of each column\n",
    "for column in df_clean_na.columns:\n",
    "    # exclude the row if pure_df[column]==pure_df[f\"participants_{column}\"]\n",
    "    pure_df = new_df[new_df[column] != new_df[f\"participants_{column}\"]]\n",
    "# drop the column if the column start with participants\n",
    "pure_df = pure_df.drop(pure_df.columns[pure_df.columns.str.startswith('participants_')], axis=1).T\n",
    "\n",
    "# append the text of each roll into one string by using s.str.cat(sep='. ')\n",
    "pure_df = pure_df.apply(lambda x: x.str.cat(sep='. '), axis=1)\n",
    "# change the pure_df to dataframe\n",
    "pure_df = pd.DataFrame(pure_df)\n",
    "# rename the column\n",
    "pure_df.columns = ['meeting_text']\n",
    "# extract the index as column from the text\n",
    "pure_df['file_name'] = pure_df.index\n",
    "# extract the date from the index column\n",
    "pure_df['date'] = pure_df['file_name'].apply(lambda x: x.split('_')[0])\n",
    "# change the date column to datetime\n",
    "pure_df['date'] = pd.to_datetime(pure_df['date'])\n",
    "# reset the index\n",
    "pure_df = pure_df.reset_index(drop=True)\n",
    "pure_df\n",
    "\n",
    "#save the dataframe\n",
    "# pure_df.to_csv('/Users/timliu/Documents/GitHub/data_collecting/output/test/pure_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the single company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting with paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much, Clemens. On the next slid...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Question And Answer)Ladies and gentlemen, we ...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Yes. Two quick questions. The first one would ...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>And on the NatCat, so as Jean-Jacques explaine...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>And there are no further questions at this poi...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Well, thank you very much for joining, and tha...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator\n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz\n",
       "2   Thank you very much, Clemens. On the next slid...  Jean-Jacques Henchoz\n",
       "3   (Question And Answer)Ladies and gentlemen, we ...              Operator\n",
       "4   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie\n",
       "..                                                ...                   ...\n",
       "60  Yes. Two quick questions. The first one would ...        Thomas Fossard\n",
       "61  And on the NatCat, so as Jean-Jacques explaine...          Klaus Miller\n",
       "62                              Thank you. Thank you.        Thomas Fossard\n",
       "63  And there are no further questions at this poi...              Operator\n",
       "64  Well, thank you very much for joining, and tha...  Jean-Jacques Henchoz\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragrapg_df = new_df.iloc[:,:2]\n",
    "# drop the NaN\n",
    "paragrapg_df = paragrapg_df.dropna(inplace=False)\n",
    "#rename the second column to 'participants', first column to 'text'\n",
    "paragrapg_df.columns = ['text', 'participants']\n",
    "# if the text is empty, drop it\n",
    "paragrapg_df = paragrapg_df[paragrapg_df['text'] != '']\n",
    "# reset the index\n",
    "paragrapg_df = paragrapg_df.reset_index(drop=True)\n",
    "# if 'text' == 'participants', get the index of the row\n",
    "paragrapg_index = paragrapg_df[paragrapg_df['text'] == paragrapg_df['participants']].index.tolist()\n",
    "\n",
    "# +1 for every value in paragrapg_index\n",
    "start_paragrapg_index = []\n",
    "for i in range(len(paragrapg_index)):\n",
    "    start_paragrapg_index.append(paragrapg_index[i]+1)\n",
    "# disregard the last value in the list\n",
    "start_paragrapg_index = start_paragrapg_index[:-1]\n",
    "print(len(start_paragrapg_index))\n",
    "# -1 for every value in paragrapg_index\n",
    "end_paragrapg_index = []\n",
    "for i in range(len(paragrapg_index)):\n",
    "    end_paragrapg_index.append(paragrapg_index[i])\n",
    "# disregard the first value in the list\n",
    "end_paragrapg_index = end_paragrapg_index[1:]\n",
    "print(len(end_paragrapg_index))\n",
    "\n",
    "# extracct the text of the paragrapg_df between end_paragrapg_index and start_paragrapg_index\n",
    "paragraph_split_df = pd.DataFrame()\n",
    "for i in range(len(start_paragrapg_index)):\n",
    "    paragraph = paragrapg_df.iloc[start_paragrapg_index[i]:end_paragrapg_index[i]]\n",
    "    # merge the paragraph to one cell \n",
    "    paragraph_text = paragraph.apply(''.join).to_frame().T\n",
    "    # appemd the paragraph_text['text'].iloc[:,0] to the paragraph_split_df\n",
    "    paragraph_split_df = paragraph_split_df.append(paragraph_text, ignore_index=True)\n",
    "\n",
    "# look up for paragrapg_df['participants'] from the start_paragrapg_index\n",
    "participants = paragrapg_df.iloc[start_paragrapg_index,1].to_frame()\n",
    "# reset the index\n",
    "participants = participants.reset_index(drop=True)\n",
    "\n",
    "paragraph_split_df['participants'] = participants\n",
    "paragraph_split_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting with participants (a bit useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes. With regard to the major loss budget, hap...</td>\n",
       "      <td>Sven Althoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay. Now, I'm happy to take the question on t...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hey, good morning. Thank you very much. So, a ...</td>\n",
       "      <td>Vinit Malhotra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>On the cash flow, nothing really significant. ...</td>\n",
       "      <td>Unidentified Speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hi, morning, everyone. Just a quick follow-up ...</td>\n",
       "      <td>William Hardcastle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yes. Good morning. Couple of questions. The fi...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hi. Thanks for taking my questions. The first ...</td>\n",
       "      <td>Iain Pearce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Good morning. Thank you for taking my question...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator\n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz\n",
       "2   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie\n",
       "3   Yes. With regard to the major loss budget, hap...          Sven Althoff\n",
       "4   Okay. Now, I'm happy to take the question on t...          Klaus Miller\n",
       "5   Hey, good morning. Thank you very much. So, a ...        Vinit Malhotra\n",
       "6   On the cash flow, nothing really significant. ...  Unidentified Speaker\n",
       "7   Hi, morning, everyone. Just a quick follow-up ...    William Hardcastle\n",
       "8   Yes. Good morning. Couple of questions. The fi...        Thomas Fossard\n",
       "9   Hi. Thanks for taking my questions. The first ...           Iain Pearce\n",
       "10  Good morning. Thank you for taking my question...     Darius Satkauskas"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take two of the first column as test df\n",
    "single_meeting_df = new_df.iloc[:,:2]\n",
    "# rename the second column to 'participants'\n",
    "single_meeting_df.columns = ['text', 'participants']\n",
    "# drop the NaN\n",
    "single_meeting_df = single_meeting_df.dropna(inplace=False)\n",
    "# if the text is empty, drop it\n",
    "single_meeting_df = single_meeting_df[single_meeting_df['text'] != '']\n",
    "# drop if 'text' == 'participants'\n",
    "single_meeting_df = single_meeting_df[single_meeting_df['text'] != single_meeting_df['participants']]\n",
    "\n",
    "list_participants = [] \n",
    "list_participants.append(single_meeting_df['participants'].unique().tolist())\n",
    "list_participants = list_participants[0]\n",
    "\n",
    "# create participants_split_df with column of 'participants' and 'text'\n",
    "participants_split_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(list_participants)):\n",
    "    processing_df = single_meeting_df.copy()\n",
    "    # 萃取出所有的participantsj中Operator說的話\n",
    "    processing_df['participants'] = processing_df['participants'].apply(lambda x: x if x == f\"{list_participants[i]}\" else np.nan)\n",
    "    # drop the NaN\n",
    "    processing_df = processing_df.dropna(inplace=False)\n",
    "    processing_df = processing_df.apply(''.join).to_frame().T\n",
    "    processing_df['participants'] =  f\"{list_participants[i]}\"\n",
    "    participants_split_df = participants_split_df.append(processing_df, ignore_index=True)\n",
    "\n",
    "\n",
    "participants_split_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting with sentences \n",
    "and will have the participants_split_df split the text by '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Good morning, ladies and gentlemen, I welcome...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Well, good morning, everyone and welcome to o...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Thank you very much, Clemens, On the next sli...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(Question And Answer)Ladies and gentlemen, we...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Hi, Good morning, everyone, Could I just dig ...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[Yes, Two quick questions, The first one would...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[And on the NatCat, so as Jean-Jacques explain...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[Thank you, Thank you.]</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[And there are no further questions at this po...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[Well, thank you very much for joining, and th...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants\n",
       "0   [Good morning, ladies and gentlemen, I welcome...              Operator\n",
       "1   [Well, good morning, everyone and welcome to o...  Jean-Jacques Henchoz\n",
       "2   [Thank you very much, Clemens, On the next sli...  Jean-Jacques Henchoz\n",
       "3   [(Question And Answer)Ladies and gentlemen, we...              Operator\n",
       "4   [Hi, Good morning, everyone, Could I just dig ...        Andrew Ritchie\n",
       "..                                                ...                   ...\n",
       "60  [Yes, Two quick questions, The first one would...        Thomas Fossard\n",
       "61  [And on the NatCat, so as Jean-Jacques explain...          Klaus Miller\n",
       "62                            [Thank you, Thank you.]        Thomas Fossard\n",
       "63  [And there are no further questions at this po...              Operator\n",
       "64  [Well, thank you very much for joining, and th...  Jean-Jacques Henchoz\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a function to split the text by '.' in paragraph_split_df\n",
    "p_to_s_split_df = paragraph_split_df.copy()\n",
    "\n",
    "def split_text(text):\n",
    "    text = text.split(\". \")\n",
    "    return text\n",
    "# apply the function to the paragraph_split_df\n",
    "p_to_s_split_df['text'] = p_to_s_split_df['text'].apply(lambda x: split_text(x))\n",
    "p_to_s_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>participants</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I welcome you to today's Hannover Re Internati...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For your information, this conference isbeing ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At this time, I would like to hand the call ov...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please go ahead, sir.</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>You've seen a year impacted by large losses on...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>And I think the key message is that the profit...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>The guidance for '22 shows boththe growth traj...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>So, I think thekey messages were addressed today</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Thank you very much for all the questions and ...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence          participants  \\\n",
       "0                   Good morning, ladies and gentlemen              Operator   \n",
       "1    I welcome you to today's Hannover Re Internati...              Operator   \n",
       "2    For your information, this conference isbeing ...              Operator   \n",
       "3    At this time, I would like to hand the call ov...              Operator   \n",
       "4                                Please go ahead, sir.              Operator   \n",
       "..                                                 ...                   ...   \n",
       "437  You've seen a year impacted by large losses on...  Jean-Jacques Henchoz   \n",
       "438  And I think the key message is that the profit...  Jean-Jacques Henchoz   \n",
       "439  The guidance for '22 shows boththe growth traj...  Jean-Jacques Henchoz   \n",
       "440   So, I think thekey messages were addressed today  Jean-Jacques Henchoz   \n",
       "441  Thank you very much for all the questions and ...  Jean-Jacques Henchoz   \n",
       "\n",
       "     paragraph  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "..         ...  \n",
       "437         64  \n",
       "438         64  \n",
       "439         64  \n",
       "440         64  \n",
       "441         64  \n",
       "\n",
       "[442 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_split_df = pd.DataFrame()\n",
    "for i in range(len(p_to_s_split_df)):\n",
    "    sentence_list = p_to_s_split_df['text'].iloc[i]\n",
    "    sentence_split_single_df = pd.DataFrame (sentence_list, columns = ['sentence'])\n",
    "    sentence_split_single_df['participants'] = p_to_s_split_df['participants'].iloc[i]\n",
    "    sentence_split_single_df['paragraph'] = i\n",
    "    sentence_split_df = sentence_split_df.append(sentence_split_single_df, ignore_index=True)\n",
    "# drop if the 'sentence' is empty\n",
    "sentence_split_df = sentence_split_df.dropna(inplace=False)\n",
    "\n",
    "sentence_split_df\n",
    "\n",
    "# safe the dataframe with the path\n",
    "path = '/Users/timliu/Documents/GitHub/data_collecting/df_for_NLP/sentence_split_df.csv'\n",
    "sentence_split_df.to_csv(path)\n",
    "sentence_split_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## snetiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/timliu/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/timliu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "There are 5000 negative sentences.\n",
      "There are 5000 positive sentences.\n",
      "==========================================================\n",
      "[[593 235]\n",
      " [157 515]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.72      0.75       828\n",
      "           1       0.69      0.77      0.72       672\n",
      "\n",
      "    accuracy                           0.74      1500\n",
      "   macro avg       0.74      0.74      0.74      1500\n",
      "weighted avg       0.74      0.74      0.74      1500\n",
      "\n",
      "0.7386666666666667\n",
      "==========================================================\n",
      "Unnamed: 0      0\n",
      "sentence        0\n",
      "participants    0\n",
      "paragraph       0\n",
      "dtype: int64\n",
      "==========================================================\n",
      "Counter({'positive': 296, 'negative': 146})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>participants</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen</td>\n",
       "      <td>Operator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I welcome you to today's Hannover Re Internati...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For your information, this conference isbeing ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At this time, I would like to hand the call ov...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please go ahead, sir.</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>You've seen a year impacted by large losses on...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>And I think the key message is that the profit...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>The guidance for '22 shows boththe growth traj...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>So, I think thekey messages were addressed today</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Thank you very much for all the questions and ...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence          participants  \\\n",
       "0                   Good morning, ladies and gentlemen              Operator   \n",
       "1    I welcome you to today's Hannover Re Internati...              Operator   \n",
       "2    For your information, this conference isbeing ...              Operator   \n",
       "3    At this time, I would like to hand the call ov...              Operator   \n",
       "4                                Please go ahead, sir.              Operator   \n",
       "..                                                 ...                   ...   \n",
       "437  You've seen a year impacted by large losses on...  Jean-Jacques Henchoz   \n",
       "438  And I think the key message is that the profit...  Jean-Jacques Henchoz   \n",
       "439  The guidance for '22 shows boththe growth traj...  Jean-Jacques Henchoz   \n",
       "440   So, I think thekey messages were addressed today  Jean-Jacques Henchoz   \n",
       "441  Thank you very much for all the questions and ...  Jean-Jacques Henchoz   \n",
       "\n",
       "     sentiment_score  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                 -1  \n",
       "3                 -1  \n",
       "4                 -1  \n",
       "..               ...  \n",
       "437                1  \n",
       "438               -1  \n",
       "439                1  \n",
       "440                1  \n",
       "441                1  \n",
       "\n",
       "[442 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% # snetiment analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nltk \n",
    "nltk.download('twitter_samples')\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
    "\n",
    "# twitter_samples.fileids()\n",
    "# documents\n",
    "docs_negative = [(t, \"neg\") for t in twitter_samples.strings(\"negative_tweets.json\")]\n",
    "docs_positive = [(t, \"pos\") for t in twitter_samples.strings(\"positive_tweets.json\")]\n",
    "print(\"==========================================================\")\n",
    "print(f'There are {len(docs_negative)} negative sentences.')\n",
    "print(f'There are {len(docs_positive)} positive sentences.')\n",
    "\n",
    "# spliting dataset \n",
    "train_set = docs_negative[:3500] + docs_positive[:3500]\n",
    "test_set = docs_negative[3500:4250] + docs_positive[3500:4250]\n",
    "valid_set = docs_negative[4250:] + docs_positive[4250:]\n",
    "\n",
    "# clean text\n",
    "def process_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    #text = text.str\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\$\\w*', '', text)\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,reduce_len=True)\n",
    "    text_tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    text_clean = []\n",
    "    for word in text_tokens:\n",
    "        if (word not in stopwords_english and  \n",
    "                word not in string.punctuation): \n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            text_clean.append(stem_word)\n",
    "            \n",
    "    sentence = ' '.join(text_clean)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# categorical label\n",
    "def cat_label(label):\n",
    "    if label == 'neg':\n",
    "        value = -1\n",
    "    elif label == 'pos':\n",
    "        value = 1\n",
    "    return value \n",
    "\n",
    "# split for x and y \n",
    "def xy(dataset):\n",
    "    df = pd.DataFrame(dataset, columns = ['text', 'label'])\n",
    "    df['text_clean'] = df['text'].apply(lambda r: process_text(r))\n",
    "    #df['categorical_label'] = df.label.factorize()[0]\n",
    "    df['categorical_label'] = df['label'].apply(lambda r: cat_label(r))\n",
    "\n",
    "    x = df.text_clean\n",
    "    y = df.categorical_label\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# dataframe\n",
    "x_train, y_train = xy(train_set)\n",
    "x_test, y_test = xy(test_set)\n",
    "x_valid, y_valid = xy(valid_set)\n",
    "\n",
    "## using the naive bayes classifier\n",
    "model = Pipeline([\n",
    "    ('bow',CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"==========================================================\")\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "\n",
    "# Apply into earnings call sentence\n",
    "# import dataset\n",
    "path = '/Users/timliu/Documents/GitHub/data_collecting/df_for_NLP/sentence_split_df.csv'\n",
    "df_sentence = pd.read_csv(path)\n",
    "# df_sentence.head()\n",
    "\n",
    "# drop participant columns as we dont need it\n",
    "# df_sentence = df_sentence.drop(['participants'], axis=1)\n",
    "\n",
    "# check NaN values\n",
    "print(\"==========================================================\")\n",
    "print(df_sentence.isnull().sum())\n",
    "\n",
    "# delete NaN rows\n",
    "df_sentence = df_sentence.dropna()  \n",
    "\n",
    "# clean text for sentiment analysis\n",
    "df_sentence['text_clean'] = df_sentence['sentence'].apply(lambda r: process_text(r))\n",
    "# df_sentence.head(5)\n",
    "\n",
    "# making prediction\n",
    "prediction = model.predict(df_sentence.text_clean)\n",
    "prediction_label = np.array(['positive' if p==1 else 'negative' for p in prediction])\n",
    "df_sentence['prediction_label'] = prediction_label\n",
    "df_sentence['sentiment_score'] = prediction\n",
    "# df_sentence.head()\n",
    "\n",
    "print(\"==========================================================\")\n",
    "print(Counter(df_sentence['prediction_label']))\n",
    "\n",
    "# df_sentence left columns with only 'sentence','participants','sentiment_score'\n",
    "df_sentence = df_sentence[['sentence','participants','sentiment_score']]\n",
    "df_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>participants</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Good morning, ladies and gentlemen</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I welcome you to today's Hannover Re Internati...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>For your information, this conference isbeing ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>At this time, I would like to hand the call ov...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Please go ahead, sir.</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>437</td>\n",
       "      <td>You've seen a year impacted by large losses on...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>438</td>\n",
       "      <td>And I think the key message is that the profit...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>439</td>\n",
       "      <td>The guidance for '22 shows boththe growth traj...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>440</td>\n",
       "      <td>So, I think thekey messages were addressed today</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>441</td>\n",
       "      <td>Thank you very much for all the questions and ...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           sentence  \\\n",
       "0             0                 Good morning, ladies and gentlemen   \n",
       "1             1  I welcome you to today's Hannover Re Internati...   \n",
       "2             2  For your information, this conference isbeing ...   \n",
       "3             3  At this time, I would like to hand the call ov...   \n",
       "4             4                              Please go ahead, sir.   \n",
       "..          ...                                                ...   \n",
       "437         437  You've seen a year impacted by large losses on...   \n",
       "438         438  And I think the key message is that the profit...   \n",
       "439         439  The guidance for '22 shows boththe growth traj...   \n",
       "440         440   So, I think thekey messages were addressed today   \n",
       "441         441  Thank you very much for all the questions and ...   \n",
       "\n",
       "             participants  paragraph  sentiment_score  \n",
       "0                Operator          0                1  \n",
       "1                Operator          0                1  \n",
       "2                Operator          0               -1  \n",
       "3                Operator          0               -1  \n",
       "4                Operator          0               -1  \n",
       "..                    ...        ...              ...  \n",
       "437  Jean-Jacques Henchoz         64                1  \n",
       "438  Jean-Jacques Henchoz         64               -1  \n",
       "439  Jean-Jacques Henchoz         64                1  \n",
       "440  Jean-Jacques Henchoz         64                1  \n",
       "441  Jean-Jacques Henchoz         64                1  \n",
       "\n",
       "[442 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/timliu/Documents/GitHub/data_collecting/df_for_NLP/sentence_split_df.csv'\n",
    "sentence_split_df = pd.read_csv(path)\n",
    "\n",
    "\n",
    "sentence_split_df['sentiment_score']=df_sentence['sentiment_score']\n",
    "sentence_split_df\n",
    "# safe to save the dataframe\n",
    "sentence_split_df.to_csv('/Users/timliu/Documents/GitHub/data_collecting/df_for_NLP/tim_test.csv', index=False)\n",
    "sentence_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2,\n",
       " 0.4722222222222222,\n",
       " 0.52,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.3,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -0.3333333333333333,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.6923076923076923,\n",
       " 0.6,\n",
       " 0.0,\n",
       " -0.4,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " -0.4,\n",
       " 0.5,\n",
       " 0.3333333333333333,\n",
       " -0.2,\n",
       " 0.0,\n",
       " -0.14285714285714285,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.3333333333333333,\n",
       " 0.44,\n",
       " -0.2,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.3333333333333333,\n",
       " 0.7142857142857143,\n",
       " 1.0,\n",
       " 0.3333333333333333,\n",
       " -1.0,\n",
       " 0.5384615384615384,\n",
       " 1.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.4444444444444444,\n",
       " -0.1111111111111111,\n",
       " 0.25,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.3333333333333333,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.42857142857142855,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.42857142857142855]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_df = pd.DataFrame()\n",
    "score_list  = []\n",
    "for i in sentence_split_df['paragraph'].unique():\n",
    "    # sum up the sentiment score for each sentence\n",
    "    process_df = sentence_split_df[sentence_split_df['paragraph']==i]\n",
    "    score_list.append(process_df['sentiment_score'].sum()/len(process_df))\n",
    "\n",
    "score_list\n",
    "\n",
    "\n",
    "# if sentence_split_df[sentence_split_df['paragraph']==1]:\n",
    "#     # sum up the sentiment score for each sentence\n",
    "#     test_df['sentiment_score'] = sentence_split_df.groupby('paragraph')['sentiment_score'].transform(sum)\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much, Clemens. On the next slid...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Question And Answer)Ladies and gentlemen, we ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Yes. Two quick questions. The first one would ...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>And on the NatCat, so as Jean-Jacques explaine...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>And there are no further questions at this poi...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Well, thank you very much for joining, and tha...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants  \\\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator   \n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz   \n",
       "2   Thank you very much, Clemens. On the next slid...  Jean-Jacques Henchoz   \n",
       "3   (Question And Answer)Ladies and gentlemen, we ...              Operator   \n",
       "4   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie   \n",
       "..                                                ...                   ...   \n",
       "60  Yes. Two quick questions. The first one would ...        Thomas Fossard   \n",
       "61  And on the NatCat, so as Jean-Jacques explaine...          Klaus Miller   \n",
       "62                              Thank you. Thank you.        Thomas Fossard   \n",
       "63  And there are no further questions at this poi...              Operator   \n",
       "64  Well, thank you very much for joining, and tha...  Jean-Jacques Henchoz   \n",
       "\n",
       "    sentiment_score  \n",
       "0         -0.200000  \n",
       "1          0.472222  \n",
       "2          0.520000  \n",
       "3          0.500000  \n",
       "4          0.500000  \n",
       "..              ...  \n",
       "60         1.000000  \n",
       "61         0.428571  \n",
       "62         1.000000  \n",
       "63         0.000000  \n",
       "64         0.428571  \n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the score_list into paragraph_split_df['sentiment_score']\n",
    "paragraph_split_df = paragraph_split_df.assign(sentiment_score=score_list)\n",
    "paragraph_split_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>meeting_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much, Clemens. On the next slid...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Question And Answer)Ladies and gentlemen, we ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Yes. Two quick questions. The first one would ...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>And on the NatCat, so as Jean-Jacques explaine...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>And there are no further questions at this poi...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Well, thank you very much for joining, and tha...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants  \\\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator   \n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz   \n",
       "2   Thank you very much, Clemens. On the next slid...  Jean-Jacques Henchoz   \n",
       "3   (Question And Answer)Ladies and gentlemen, we ...              Operator   \n",
       "4   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie   \n",
       "..                                                ...                   ...   \n",
       "60  Yes. Two quick questions. The first one would ...        Thomas Fossard   \n",
       "61  And on the NatCat, so as Jean-Jacques explaine...          Klaus Miller   \n",
       "62                              Thank you. Thank you.        Thomas Fossard   \n",
       "63  And there are no further questions at this poi...              Operator   \n",
       "64  Well, thank you very much for joining, and tha...  Jean-Jacques Henchoz   \n",
       "\n",
       "    sentiment_score meeting_date  \n",
       "0         -0.200000   2021-11-04  \n",
       "1          0.472222   2021-11-04  \n",
       "2          0.520000   2021-11-04  \n",
       "3          0.500000   2021-11-04  \n",
       "4          0.500000   2021-11-04  \n",
       "..              ...          ...  \n",
       "60         1.000000   2021-11-04  \n",
       "61         0.428571   2021-11-04  \n",
       "62         1.000000   2021-11-04  \n",
       "63         0.000000   2021-11-04  \n",
       "64         0.428571   2021-11-04  \n",
       "\n",
       "[65 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_date = new_df.iloc[:,:2]\n",
    "# get the column name from extract_date\n",
    "date_extract = extract_date.columns.to_list()\n",
    "date_extract[0]\n",
    "\n",
    "# date_extract[0] split by '_'\n",
    "date = date_extract[0].split('_')[0]\n",
    "paragraph_split_df['meeting_date'] = pd.to_datetime(date)\n",
    "paragraph_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_sentence_count: 14\n",
      "future_sentence_count: 1\n",
      "present_sentence_count: 3\n",
      "past_sentence_count: 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>meeting_date</th>\n",
       "      <th>tense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much, Clemens. On the next slid...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Question And Answer)Ladies and gentlemen, we ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Yes. Two quick questions. The first one would ...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>And on the NatCat, so as Jean-Jacques explaine...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>And there are no further questions at this poi...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Well, thank you very much for joining, and tha...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants  \\\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator   \n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz   \n",
       "2   Thank you very much, Clemens. On the next slid...  Jean-Jacques Henchoz   \n",
       "3   (Question And Answer)Ladies and gentlemen, we ...              Operator   \n",
       "4   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie   \n",
       "..                                                ...                   ...   \n",
       "60  Yes. Two quick questions. The first one would ...        Thomas Fossard   \n",
       "61  And on the NatCat, so as Jean-Jacques explaine...          Klaus Miller   \n",
       "62                              Thank you. Thank you.        Thomas Fossard   \n",
       "63  And there are no further questions at this poi...              Operator   \n",
       "64  Well, thank you very much for joining, and tha...  Jean-Jacques Henchoz   \n",
       "\n",
       "    sentiment_score meeting_date    tense  \n",
       "0         -0.200000   2021-11-04     past  \n",
       "1          0.472222   2021-11-04     past  \n",
       "2          0.520000   2021-11-04     past  \n",
       "3          0.500000   2021-11-04  present  \n",
       "4          0.500000   2021-11-04     past  \n",
       "..              ...          ...      ...  \n",
       "60         1.000000   2021-11-04     past  \n",
       "61         0.428571   2021-11-04     past  \n",
       "62         1.000000   2021-11-04  unknown  \n",
       "63         0.000000   2021-11-04     past  \n",
       "64         0.428571   2021-11-04     past  \n",
       "\n",
       "[65 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### add the past, future and present to the dataframe\n",
    "from nltk import word_tokenize, pos_tag\n",
    "# import nltk\n",
    "# nltk.download()\n",
    "def determine_tense_input(sentence):\n",
    "    text = word_tokenize(sentence)\n",
    "    tagged = pos_tag(text)\n",
    "\n",
    "    tense = {}\n",
    "    tense[\"future\"] = len([word for word in tagged if word[1] == \"MD\"])\n",
    "    tense[\"present\"] = len([word for word in tagged if word[1] in [\"VBP\", \"VBZ\",\"VBG\"]])\n",
    "    tense[\"past\"] = len([word for word in tagged if word[1] in [\"VBD\", \"VBN\"]]) \n",
    "    return(tense)\n",
    "\n",
    "# %%\n",
    "# apply the function to the paragraph_split_df\n",
    "paragraph_split_df['tense'] = paragraph_split_df['text'].apply(lambda x: determine_tense_input(x))\n",
    "# decode the paragraph_split_df['tense'] to different column\n",
    "paragraph_split_df['tense_future'] = paragraph_split_df['tense'].apply(lambda x: x['future'])\n",
    "paragraph_split_df['tense_present'] = paragraph_split_df['tense'].apply(lambda x: x['present'])\n",
    "paragraph_split_df['tense_past'] = paragraph_split_df['tense'].apply(lambda x: x['past'])\n",
    "\n",
    "# if the tense_future > tense_present > tense_past, then the tense is future\n",
    "# else if the tense_present > tense_future > tense_past, then the tense is present\n",
    "# else if the tense_past > tense_future > tense_present, then the tense is past\n",
    "paragraph_split_df['tense'] = paragraph_split_df.apply(lambda x: 'future' if x['tense_future'] > x['tense_present'] > x['tense_past'] else 'present' if x['tense_present'] > x['tense_future'] > x['tense_past'] else 'past', axis=1)\n",
    "# else if the tense_past = tense_future = tense_present, then the tense is unknown\n",
    "paragraph_split_df['tense'] = paragraph_split_df.apply(lambda x: 'unknown' if x['tense_past'] == x['tense_future'] == x['tense_present'] else x['tense'], axis=1)\n",
    "# disregard the tense_future, tense_present, and tense_past\n",
    "paragraph_split_df = paragraph_split_df.drop(columns=['tense_future', 'tense_present', 'tense_past'])\n",
    "\n",
    "# %%\n",
    "# count the amount of rowa of paragraph_split_df['tense']=='unknown'\n",
    "unknown_sentence_count = paragraph_split_df[paragraph_split_df['tense'] == 'unknown'].shape[0]\n",
    "# count the amount of rowa of paragraph_split_df['tense']=='future'\n",
    "future_sentence_count = paragraph_split_df[paragraph_split_df['tense'] == 'future'].shape[0]\n",
    "# count the amount of rowa of paragraph_split_df['tense']=='present'\n",
    "present_sentence_count = paragraph_split_df[paragraph_split_df['tense'] == 'present'].shape[0]\n",
    "# count the amount of rowa of paragraph_split_df['tense']=='past'\n",
    "past_sentence_count = paragraph_split_df[paragraph_split_df['tense'] == 'past'].shape[0]\n",
    "\n",
    "# print the result\n",
    "print(f'unknown_para_count: {unknown_sentence_count}')\n",
    "print(f'future_sentence_count: {future_sentence_count}')\n",
    "print(f'present_sentence_count: {present_sentence_count}')\n",
    "print(f'past_sentence_count: {past_sentence_count}')\n",
    "\n",
    "paragraph_split_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic moedelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much, Clemens. On the next slid...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Question And Answer)Ladies and gentlemen, we ...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Yes. Two quick questions. The first one would ...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>And on the NatCat, so as Jean-Jacques explaine...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>And there are no further questions at this poi...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Well, thank you very much for joining, and tha...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator\n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz\n",
       "2   Thank you very much, Clemens. On the next slid...  Jean-Jacques Henchoz\n",
       "3   (Question And Answer)Ladies and gentlemen, we ...              Operator\n",
       "4   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie\n",
       "..                                                ...                   ...\n",
       "60  Yes. Two quick questions. The first one would ...        Thomas Fossard\n",
       "61  And on the NatCat, so as Jean-Jacques explaine...          Klaus Miller\n",
       "62                              Thank you. Thank you.        Thomas Fossard\n",
       "63  And there are no further questions at this poi...              Operator\n",
       "64  Well, thank you very much for joining, and tha...  Jean-Jacques Henchoz\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pure_df[pure_df['file_name']=='20211104_Hannover_Rueck_SE-_Earnings_Call_2021-11-4_RT000000002967437630.pdf']\n",
    "# data = data[['meeting_text']]\n",
    "# data\n",
    "\n",
    "data_tim = paragraph_split_df.copy()\n",
    "data_tim = data_tim[['text','participants']]\n",
    "data_tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'morning lady gentleman today information conference isbeing time call host today sir'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=[\"NOUN\"]):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    texts_out = []\n",
    "\n",
    "    for row in range(len(data_tim)):\n",
    "        for text in texts:\n",
    "            doc = nlp(data_tim.loc[row,\"text\"])\n",
    "        \n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = \" \".join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return (texts_out)\n",
    "\n",
    "lemmatized_texts = lemmatization(data_tim)\n",
    "lemmatized_texts[0]\n",
    "#lemmatized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['morning', 'lady', 'gentleman', 'today', 'information', 'conference', 'isbeing', 'time', 'call', 'host', 'today', 'sir']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)\n",
    "\n",
    "print (data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)]\n",
      "call\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "corpus = []\n",
    "for text in data_words:\n",
    "    new = id2word.doc2bow(text)\n",
    "    corpus.append(new)\n",
    "\n",
    "print (corpus[0][0:20])\n",
    "\n",
    "word = id2word[[0][:1][0]]\n",
    "print (word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    max_features=100,\n",
    "    max_df=0.8, \n",
    "    min_df=5,\n",
    "    ngram_range=(1,3),\n",
    "    stop_words= \"english\"\n",
    ")\n",
    "\n",
    "vectors = vectoriser.fit_transform(lemmatized_texts)\n",
    "\n",
    "feature_names = vectoriser.get_feature_names()\n",
    "\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['information', 'morning', 'time', 'today']\n"
     ]
    }
   ],
   "source": [
    "all_keywords = []\n",
    "\n",
    "for description in denselist:\n",
    "    x=0\n",
    "    keywords = []\n",
    "    for word in description:\n",
    "        if word > 0:\n",
    "            keywords.append(feature_names[x])\n",
    "        x=x+1\n",
    "    all_keywords.append(keywords)\n",
    "\n",
    "print (all_keywords[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 20\n",
    "\n",
    "model = KMeans(n_clusters=true_k, init=\"k-means++\", max_iter=100, n_init=1)\n",
    "\n",
    "model.fit(vectors)\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectoriser.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/trc_results.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sq/sxhsy98j6f57m406rd5lz1_r0000gn/T/ipykernel_7139/1905964227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"data/trc_results.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cluster {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder_centroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/trc_results.txt'"
     ]
    }
   ],
   "source": [
    "with open (\"data/trc_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(true_k):\n",
    "        f.write(f\"Cluster {i}\")\n",
    "        f.write(\"\\n\")\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            f.write (' %s' % terms[ind],)\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WiP - Coherence Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA topic modeling\n",
    "def get_lda_topics(model, num_topics):\n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        words = model.show_topic(i, topn = 100);\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words];\n",
    "    return pd.DataFrame(word_dict);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  numerator = (co_occur_count / num_docs) + EPSILON\n",
      "/opt/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:203: RuntimeWarning: invalid value encountered in true_divide\n",
      "  denominator = (w_prime_count / num_docs) * (w_star_count / num_docs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:198: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_doc_prob = co_occur_count / num_docs\n"
     ]
    }
   ],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=lemmatized_texts, start=2, limit=20, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=20; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results - table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = get_lda_topics(lda_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>growth</td>\n",
       "      <td>year</td>\n",
       "      <td>result</td>\n",
       "      <td>year</td>\n",
       "      <td>year</td>\n",
       "      <td>year</td>\n",
       "      <td>growth</td>\n",
       "      <td>question</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loss</td>\n",
       "      <td>month</td>\n",
       "      <td>fund</td>\n",
       "      <td>number</td>\n",
       "      <td>number</td>\n",
       "      <td>life</td>\n",
       "      <td>loss</td>\n",
       "      <td>year</td>\n",
       "      <td>covid</td>\n",
       "      <td>impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>underwriting</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>profitability</td>\n",
       "      <td>effect</td>\n",
       "      <td>calculation</td>\n",
       "      <td>business</td>\n",
       "      <td>loss</td>\n",
       "      <td>line</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ratio</td>\n",
       "      <td>number</td>\n",
       "      <td>investment</td>\n",
       "      <td>eur</td>\n",
       "      <td>question</td>\n",
       "      <td>cover</td>\n",
       "      <td>growth</td>\n",
       "      <td>budget</td>\n",
       "      <td>claim</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>difference</td>\n",
       "      <td>year</td>\n",
       "      <td>quarter</td>\n",
       "      <td>side</td>\n",
       "      <td>bit</td>\n",
       "      <td>growth</td>\n",
       "      <td>portfolio</td>\n",
       "      <td>question</td>\n",
       "      <td>bit</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>future</td>\n",
       "      <td>riot</td>\n",
       "      <td>interest</td>\n",
       "      <td>guidance</td>\n",
       "      <td>market</td>\n",
       "      <td>eur</td>\n",
       "      <td>target</td>\n",
       "      <td>my</td>\n",
       "      <td>presentation</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>income</td>\n",
       "      <td>profit</td>\n",
       "      <td>comment</td>\n",
       "      <td>line</td>\n",
       "      <td>profit</td>\n",
       "      <td>lot</td>\n",
       "      <td>morbidity</td>\n",
       "      <td>theprecise</td>\n",
       "      <td>isdeposit</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>regard</td>\n",
       "      <td>thesetreatie</td>\n",
       "      <td>look</td>\n",
       "      <td>bond</td>\n",
       "      <td>asset</td>\n",
       "      <td>way</td>\n",
       "      <td>movement</td>\n",
       "      <td>thatchange</td>\n",
       "      <td>rate</td>\n",
       "      <td>asset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>model</td>\n",
       "      <td>highlight</td>\n",
       "      <td>thatthere</td>\n",
       "      <td>reinsurance</td>\n",
       "      <td>longevity</td>\n",
       "      <td>accounting</td>\n",
       "      <td>population</td>\n",
       "      <td>everyelement</td>\n",
       "      <td>andnobody</td>\n",
       "      <td>gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>date</td>\n",
       "      <td>inflation</td>\n",
       "      <td>nextyear</td>\n",
       "      <td>return</td>\n",
       "      <td>provision</td>\n",
       "      <td>range</td>\n",
       "      <td>top</td>\n",
       "      <td>tochange</td>\n",
       "      <td>increase</td>\n",
       "      <td>profit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic # 01    Topic # 02  Topic # 03     Topic # 04 Topic # 05  \\\n",
       "0           year        growth        year         result       year   \n",
       "1           loss         month        fund         number     number   \n",
       "2   underwriting      business    business  profitability     effect   \n",
       "3          ratio        number  investment            eur   question   \n",
       "4     difference          year     quarter           side        bit   \n",
       "..           ...           ...         ...            ...        ...   \n",
       "95        future          riot    interest       guidance     market   \n",
       "96        income        profit     comment           line     profit   \n",
       "97        regard  thesetreatie        look           bond      asset   \n",
       "98         model     highlight   thatthere    reinsurance  longevity   \n",
       "99          date     inflation    nextyear         return  provision   \n",
       "\n",
       "     Topic # 06  Topic # 07    Topic # 08    Topic # 09 Topic # 10  \n",
       "0          year        year        growth      question    premium  \n",
       "1          life        loss          year         covid     impact  \n",
       "2   calculation    business          loss          line   question  \n",
       "3         cover      growth        budget         claim     number  \n",
       "4        growth   portfolio      question           bit   business  \n",
       "..          ...         ...           ...           ...        ...  \n",
       "95          eur      target            my  presentation      group  \n",
       "96          lot   morbidity    theprecise     isdeposit       line  \n",
       "97          way    movement    thatchange          rate      asset  \n",
       "98   accounting  population  everyelement     andnobody       gain  \n",
       "99        range         top      tochange      increase     profit  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_text_topic(text):\n",
    "#     stemmer = PorterStemmer()\n",
    "#     stopwords_english = stopwords.words('english')\n",
    "#     #text = text.str\n",
    "#     text = str(text)\n",
    "#     text = re.sub(r'\\$\\w*', '', text)\n",
    "#     text = re.sub(r'^RT[\\s]+', '', text)\n",
    "#     text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "#     text = re.sub(r'#', '', text)\n",
    "#     tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,reduce_len=True)\n",
    "#     text_tokens = tokenizer.tokenize(text)\n",
    "\n",
    "#     text_clean = []\n",
    "#     for word in text_tokens:\n",
    "#         if (word not in stopwords_english and  \n",
    "#                 word not in string.punctuation): \n",
    "#             # stem_word = stemmer.stem(word)  # stemming word\n",
    "#             text_clean.append(stem_word)\n",
    "            \n",
    "#     # sentence = ' '.join(text_clean)\n",
    "    \n",
    "#     return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>meeting_date</th>\n",
       "      <th>tense</th>\n",
       "      <th>lemmatized_texts</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>morning lady gentleman today information confe...</td>\n",
       "      <td>['morning', 'lady', 'gentleman', 'today', 'inf...</td>\n",
       "      <td>[good, morn, ladi, gentlemen, welcom, today', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>morning welcome conference call resultsof mont...</td>\n",
       "      <td>['morning', 'welcome', 'conference', 'call', '...</td>\n",
       "      <td>[well, good, morn, everyon, welcom, confer, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much, Clemens. On the next slid...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>slide target metric profitability target group...</td>\n",
       "      <td>['slide', 'target', 'metric', 'profitability',...</td>\n",
       "      <td>[thank, much, clemen, next, slide, target, met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Question And Answer)Ladies and gentlemen, we ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>present</td>\n",
       "      <td>question answer)ladie gentleman question answe...</td>\n",
       "      <td>['question', 'answer)ladie', 'gentleman', 'que...</td>\n",
       "      <td>[question, answer, ladi, gentlemen, begin, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>morning bit catbudget man andnatcat split budg...</td>\n",
       "      <td>['morning', 'bit', 'catbudget', 'man', 'andnat...</td>\n",
       "      <td>[hi, good, morn, everyon, could, dig, littl, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Yes. Two quick questions. The first one would ...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>question one life longevity iguess EBIT contri...</td>\n",
       "      <td>['question', 'one', 'life', 'longevity', 'igue...</td>\n",
       "      <td>[ye, two, quick, question, first, one, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>And on the NatCat, so as Jean-Jacques explaine...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>portfolio profitability hurdle rate pricingpoi...</td>\n",
       "      <td>['portfolio', 'profitability', 'hurdle', 'rate...</td>\n",
       "      <td>[natcat, jean-jacqu, explain, q, investor, day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[thank, thank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>And there are no further questions at this poi...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>question point speaker remark</td>\n",
       "      <td>['question', 'point', 'speaker', 'remark']</td>\n",
       "      <td>[question, point, hand, back, speaker, forclos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Well, thank you very much for joining, and tha...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>question ground year loss bothbusiness segment...</td>\n",
       "      <td>['question', 'ground', 'year', 'loss', 'bothbu...</td>\n",
       "      <td>[well, thank, much, join, thank, great, questi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants  \\\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator   \n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz   \n",
       "2   Thank you very much, Clemens. On the next slid...  Jean-Jacques Henchoz   \n",
       "3   (Question And Answer)Ladies and gentlemen, we ...              Operator   \n",
       "4   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie   \n",
       "..                                                ...                   ...   \n",
       "60  Yes. Two quick questions. The first one would ...        Thomas Fossard   \n",
       "61  And on the NatCat, so as Jean-Jacques explaine...          Klaus Miller   \n",
       "62                              Thank you. Thank you.        Thomas Fossard   \n",
       "63  And there are no further questions at this poi...              Operator   \n",
       "64  Well, thank you very much for joining, and tha...  Jean-Jacques Henchoz   \n",
       "\n",
       "    sentiment_score meeting_date    tense  \\\n",
       "0         -0.200000   2021-11-04     past   \n",
       "1          0.472222   2021-11-04     past   \n",
       "2          0.520000   2021-11-04     past   \n",
       "3          0.500000   2021-11-04  present   \n",
       "4          0.500000   2021-11-04     past   \n",
       "..              ...          ...      ...   \n",
       "60         1.000000   2021-11-04     past   \n",
       "61         0.428571   2021-11-04     past   \n",
       "62         1.000000   2021-11-04  unknown   \n",
       "63         0.000000   2021-11-04     past   \n",
       "64         0.428571   2021-11-04     past   \n",
       "\n",
       "                                     lemmatized_texts  \\\n",
       "0   morning lady gentleman today information confe...   \n",
       "1   morning welcome conference call resultsof mont...   \n",
       "2   slide target metric profitability target group...   \n",
       "3   question answer)ladie gentleman question answe...   \n",
       "4   morning bit catbudget man andnatcat split budg...   \n",
       "..                                                ...   \n",
       "60  question one life longevity iguess EBIT contri...   \n",
       "61  portfolio profitability hurdle rate pricingpoi...   \n",
       "62                                                      \n",
       "63                      question point speaker remark   \n",
       "64  question ground year loss bothbusiness segment...   \n",
       "\n",
       "                                       text_tokenized  \\\n",
       "0   ['morning', 'lady', 'gentleman', 'today', 'inf...   \n",
       "1   ['morning', 'welcome', 'conference', 'call', '...   \n",
       "2   ['slide', 'target', 'metric', 'profitability',...   \n",
       "3   ['question', 'answer)ladie', 'gentleman', 'que...   \n",
       "4   ['morning', 'bit', 'catbudget', 'man', 'andnat...   \n",
       "..                                                ...   \n",
       "60  ['question', 'one', 'life', 'longevity', 'igue...   \n",
       "61  ['portfolio', 'profitability', 'hurdle', 'rate...   \n",
       "62                                                 []   \n",
       "63         ['question', 'point', 'speaker', 'remark']   \n",
       "64  ['question', 'ground', 'year', 'loss', 'bothbu...   \n",
       "\n",
       "                                            tokenized  \n",
       "0   [good, morn, ladi, gentlemen, welcom, today', ...  \n",
       "1   [well, good, morn, everyon, welcom, confer, ca...  \n",
       "2   [thank, much, clemen, next, slide, target, met...  \n",
       "3   [question, answer, ladi, gentlemen, begin, que...  \n",
       "4   [hi, good, morn, everyon, could, dig, littl, b...  \n",
       "..                                                ...  \n",
       "60  [ye, two, quick, question, first, one, would, ...  \n",
       "61  [natcat, jean-jacqu, explain, q, investor, day...  \n",
       "62                                     [thank, thank]  \n",
       "63  [question, point, hand, back, speaker, forclos...  \n",
       "64  [well, thank, much, join, thank, great, questi...  \n",
       "\n",
       "[65 rows x 8 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # apply the process_text_topic function to paragraph_split_df['text']\n",
    "# paragraph_split_df['tokenized'] = paragraph_split_df['text'].apply(process_text_topic)\n",
    "# paragraph_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>meeting_date</th>\n",
       "      <th>tense</th>\n",
       "      <th>lemmatized_texts</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>morning lady gentleman today information confe...</td>\n",
       "      <td>['morning', 'lady', 'gentleman', 'today', 'inf...</td>\n",
       "      <td>[good, morn, ladi, gentlemen, welcom, today', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>morning welcome conference call resultsof mont...</td>\n",
       "      <td>['morning', 'welcome', 'conference', 'call', '...</td>\n",
       "      <td>[well, good, morn, everyon, welcom, confer, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much, Clemens. On the next slid...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>slide target metric profitability target group...</td>\n",
       "      <td>['slide', 'target', 'metric', 'profitability',...</td>\n",
       "      <td>[thank, much, clemen, next, slide, target, met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Question And Answer)Ladies and gentlemen, we ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>present</td>\n",
       "      <td>question answer)ladie gentleman question answe...</td>\n",
       "      <td>['question', 'answer)ladie', 'gentleman', 'que...</td>\n",
       "      <td>[question, answer, ladi, gentlemen, begin, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>morning bit catbudget man andnatcat split budg...</td>\n",
       "      <td>['morning', 'bit', 'catbudget', 'man', 'andnat...</td>\n",
       "      <td>[hi, good, morn, everyon, could, dig, littl, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Yes. Two quick questions. The first one would ...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>question one life longevity iguess EBIT contri...</td>\n",
       "      <td>['question', 'one', 'life', 'longevity', 'igue...</td>\n",
       "      <td>[ye, two, quick, question, first, one, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>And on the NatCat, so as Jean-Jacques explaine...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>portfolio profitability hurdle rate pricingpoi...</td>\n",
       "      <td>['portfolio', 'profitability', 'hurdle', 'rate...</td>\n",
       "      <td>[natcat, jean-jacqu, explain, q, investor, day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[thank, thank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>And there are no further questions at this poi...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>question point speaker remark</td>\n",
       "      <td>['question', 'point', 'speaker', 'remark']</td>\n",
       "      <td>[question, point, hand, back, speaker, forclos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Well, thank you very much for joining, and tha...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>question ground year loss bothbusiness segment...</td>\n",
       "      <td>['question', 'ground', 'year', 'loss', 'bothbu...</td>\n",
       "      <td>[well, thank, much, join, thank, great, questi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants  \\\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator   \n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz   \n",
       "2   Thank you very much, Clemens. On the next slid...  Jean-Jacques Henchoz   \n",
       "3   (Question And Answer)Ladies and gentlemen, we ...              Operator   \n",
       "4   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie   \n",
       "..                                                ...                   ...   \n",
       "60  Yes. Two quick questions. The first one would ...        Thomas Fossard   \n",
       "61  And on the NatCat, so as Jean-Jacques explaine...          Klaus Miller   \n",
       "62                              Thank you. Thank you.        Thomas Fossard   \n",
       "63  And there are no further questions at this poi...              Operator   \n",
       "64  Well, thank you very much for joining, and tha...  Jean-Jacques Henchoz   \n",
       "\n",
       "    sentiment_score meeting_date    tense  \\\n",
       "0         -0.200000   2021-11-04     past   \n",
       "1          0.472222   2021-11-04     past   \n",
       "2          0.520000   2021-11-04     past   \n",
       "3          0.500000   2021-11-04  present   \n",
       "4          0.500000   2021-11-04     past   \n",
       "..              ...          ...      ...   \n",
       "60         1.000000   2021-11-04     past   \n",
       "61         0.428571   2021-11-04     past   \n",
       "62         1.000000   2021-11-04  unknown   \n",
       "63         0.000000   2021-11-04     past   \n",
       "64         0.428571   2021-11-04     past   \n",
       "\n",
       "                                     lemmatized_texts  \\\n",
       "0   morning lady gentleman today information confe...   \n",
       "1   morning welcome conference call resultsof mont...   \n",
       "2   slide target metric profitability target group...   \n",
       "3   question answer)ladie gentleman question answe...   \n",
       "4   morning bit catbudget man andnatcat split budg...   \n",
       "..                                                ...   \n",
       "60  question one life longevity iguess EBIT contri...   \n",
       "61  portfolio profitability hurdle rate pricingpoi...   \n",
       "62                                                      \n",
       "63                      question point speaker remark   \n",
       "64  question ground year loss bothbusiness segment...   \n",
       "\n",
       "                                       text_tokenized  \\\n",
       "0   ['morning', 'lady', 'gentleman', 'today', 'inf...   \n",
       "1   ['morning', 'welcome', 'conference', 'call', '...   \n",
       "2   ['slide', 'target', 'metric', 'profitability',...   \n",
       "3   ['question', 'answer)ladie', 'gentleman', 'que...   \n",
       "4   ['morning', 'bit', 'catbudget', 'man', 'andnat...   \n",
       "..                                                ...   \n",
       "60  ['question', 'one', 'life', 'longevity', 'igue...   \n",
       "61  ['portfolio', 'profitability', 'hurdle', 'rate...   \n",
       "62                                                 []   \n",
       "63         ['question', 'point', 'speaker', 'remark']   \n",
       "64  ['question', 'ground', 'year', 'loss', 'bothbu...   \n",
       "\n",
       "                                            tokenized  \n",
       "0   [good, morn, ladi, gentlemen, welcom, today', ...  \n",
       "1   [well, good, morn, everyon, welcom, confer, ca...  \n",
       "2   [thank, much, clemen, next, slide, target, met...  \n",
       "3   [question, answer, ladi, gentlemen, begin, que...  \n",
       "4   [hi, good, morn, everyon, could, dig, littl, b...  \n",
       "..                                                ...  \n",
       "60  [ye, two, quick, question, first, one, would, ...  \n",
       "61  [natcat, jean-jacqu, explain, q, investor, day...  \n",
       "62                                     [thank, thank]  \n",
       "63  [question, point, hand, back, speaker, forclos...  \n",
       "64  [well, thank, much, join, thank, great, questi...  \n",
       "\n",
       "[65 rows x 8 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=[\"NOUN\"]):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    texts_out = []\n",
    "\n",
    "    for row in range(len(data_tim)):\n",
    "        for text in texts:\n",
    "            doc = nlp(data_tim.loc[row,\"text\"])\n",
    "        \n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = \" \".join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return (texts_out)\n",
    "\n",
    "lemmatized_texts = lemmatization(data_tim)\n",
    "lemmatized_texts[0]\n",
    "#lemmatized_texts\n",
    "\n",
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)\n",
    "\n",
    "# print (data_words[0][0:20])\n",
    "\n",
    "\n",
    "# append the data_words to the paragraph_split_df['lemmatized_texts']\n",
    "paragraph_split_df['lemmatized_texts'] = lemmatized_texts\n",
    "paragraph_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>meeting_date</th>\n",
       "      <th>tense</th>\n",
       "      <th>lemmatized_texts</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>morning lady gentleman today information confe...</td>\n",
       "      <td>['morning', 'lady', 'gentleman', 'today', 'inf...</td>\n",
       "      <td>[good, morn, ladi, gentlemen, welcom, today', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>morning welcome conference call resultsof mont...</td>\n",
       "      <td>['morning', 'welcome', 'conference', 'call', '...</td>\n",
       "      <td>[well, good, morn, everyon, welcom, confer, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much, Clemens. On the next slid...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>slide target metric profitability target group...</td>\n",
       "      <td>['slide', 'target', 'metric', 'profitability',...</td>\n",
       "      <td>[thank, much, clemen, next, slide, target, met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Question And Answer)Ladies and gentlemen, we ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>present</td>\n",
       "      <td>question answer)ladie gentleman question answe...</td>\n",
       "      <td>['question', 'answer)ladie', 'gentleman', 'que...</td>\n",
       "      <td>[question, answer, ladi, gentlemen, begin, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>morning bit catbudget man andnatcat split budg...</td>\n",
       "      <td>['morning', 'bit', 'catbudget', 'man', 'andnat...</td>\n",
       "      <td>[hi, good, morn, everyon, could, dig, littl, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Yes. Two quick questions. The first one would ...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>question one life longevity iguess EBIT contri...</td>\n",
       "      <td>['question', 'one', 'life', 'longevity', 'igue...</td>\n",
       "      <td>[ye, two, quick, question, first, one, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>And on the NatCat, so as Jean-Jacques explaine...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>portfolio profitability hurdle rate pricingpoi...</td>\n",
       "      <td>['portfolio', 'profitability', 'hurdle', 'rate...</td>\n",
       "      <td>[natcat, jean-jacqu, explain, q, investor, day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[thank, thank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>And there are no further questions at this poi...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>question point speaker remark</td>\n",
       "      <td>['question', 'point', 'speaker', 'remark']</td>\n",
       "      <td>[question, point, hand, back, speaker, forclos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Well, thank you very much for joining, and tha...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>past</td>\n",
       "      <td>question ground year loss bothbusiness segment...</td>\n",
       "      <td>['question', 'ground', 'year', 'loss', 'bothbu...</td>\n",
       "      <td>[well, thank, much, join, thank, great, questi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants  \\\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator   \n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz   \n",
       "2   Thank you very much, Clemens. On the next slid...  Jean-Jacques Henchoz   \n",
       "3   (Question And Answer)Ladies and gentlemen, we ...              Operator   \n",
       "4   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie   \n",
       "..                                                ...                   ...   \n",
       "60  Yes. Two quick questions. The first one would ...        Thomas Fossard   \n",
       "61  And on the NatCat, so as Jean-Jacques explaine...          Klaus Miller   \n",
       "62                              Thank you. Thank you.        Thomas Fossard   \n",
       "63  And there are no further questions at this poi...              Operator   \n",
       "64  Well, thank you very much for joining, and tha...  Jean-Jacques Henchoz   \n",
       "\n",
       "    sentiment_score meeting_date    tense  \\\n",
       "0         -0.200000   2021-11-04     past   \n",
       "1          0.472222   2021-11-04     past   \n",
       "2          0.520000   2021-11-04     past   \n",
       "3          0.500000   2021-11-04  present   \n",
       "4          0.500000   2021-11-04     past   \n",
       "..              ...          ...      ...   \n",
       "60         1.000000   2021-11-04     past   \n",
       "61         0.428571   2021-11-04     past   \n",
       "62         1.000000   2021-11-04  unknown   \n",
       "63         0.000000   2021-11-04     past   \n",
       "64         0.428571   2021-11-04     past   \n",
       "\n",
       "                                     lemmatized_texts  \\\n",
       "0   morning lady gentleman today information confe...   \n",
       "1   morning welcome conference call resultsof mont...   \n",
       "2   slide target metric profitability target group...   \n",
       "3   question answer)ladie gentleman question answe...   \n",
       "4   morning bit catbudget man andnatcat split budg...   \n",
       "..                                                ...   \n",
       "60  question one life longevity iguess EBIT contri...   \n",
       "61  portfolio profitability hurdle rate pricingpoi...   \n",
       "62                                                      \n",
       "63                      question point speaker remark   \n",
       "64  question ground year loss bothbusiness segment...   \n",
       "\n",
       "                                       text_tokenized  \\\n",
       "0   ['morning', 'lady', 'gentleman', 'today', 'inf...   \n",
       "1   ['morning', 'welcome', 'conference', 'call', '...   \n",
       "2   ['slide', 'target', 'metric', 'profitability',...   \n",
       "3   ['question', 'answer)ladie', 'gentleman', 'que...   \n",
       "4   ['morning', 'bit', 'catbudget', 'man', 'andnat...   \n",
       "..                                                ...   \n",
       "60  ['question', 'one', 'life', 'longevity', 'igue...   \n",
       "61  ['portfolio', 'profitability', 'hurdle', 'rate...   \n",
       "62                                                 []   \n",
       "63         ['question', 'point', 'speaker', 'remark']   \n",
       "64  ['question', 'ground', 'year', 'loss', 'bothbu...   \n",
       "\n",
       "                                            tokenized  \n",
       "0   [good, morn, ladi, gentlemen, welcom, today', ...  \n",
       "1   [well, good, morn, everyon, welcom, confer, ca...  \n",
       "2   [thank, much, clemen, next, slide, target, met...  \n",
       "3   [question, answer, ladi, gentlemen, begin, que...  \n",
       "4   [hi, good, morn, everyon, could, dig, littl, b...  \n",
       "..                                                ...  \n",
       "60  [ye, two, quick, question, first, one, would, ...  \n",
       "61  [natcat, jean-jacqu, explain, q, investor, day...  \n",
       "62                                     [thank, thank]  \n",
       "63  [question, point, hand, back, speaker, forclos...  \n",
       "64  [well, thank, much, join, thank, great, questi...  \n",
       "\n",
       "[65 rows x 8 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the test by row\n",
    "text_tokenized = paragraph_split_df[['lemmatized_texts']].apply(lambda x: x.str.split())\n",
    "text_tokenized\n",
    "# make each element as string inside the list\n",
    "text_tokenized = text_tokenized.apply(lambda x: [str(i) for i in x])\n",
    "text_tokenized\n",
    "# write back to the dataframe\n",
    "paragraph_split_df['text_tokenized'] = text_tokenized\n",
    "paragraph_split_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'morning lady gentleman today information conference isbeing time call host today sir'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             year\n",
       "1             loss\n",
       "2     underwriting\n",
       "3            ratio\n",
       "4       difference\n",
       "          ...     \n",
       "95          future\n",
       "96          income\n",
       "97          regard\n",
       "98           model\n",
       "99            date\n",
       "Name: Topic # 01, Length: 100, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if 'year' in list(topic_1):\n",
    "    print (\"True\")\n",
    "else:\n",
    "    print (\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['morning', 'lady', 'gentleman', 'today', 'information', 'conference', 'isbeing', 'time', 'call', 'host', 'today', 'sir']\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_1 = paragraph_split_df['text_tokenized'][0]\n",
    "try_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_1 = paragraph_split_df['text_tokenized'][0]\n",
    "topic_1 = topic_df['Topic # 01']\n",
    "\n",
    "count = 0 \n",
    "for word in try_1:\n",
    "    if word in list(topic_1):\n",
    "        count = count + 1\n",
    "    else:\n",
    "        continue\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 0,\n",
       " 'loss': 0,\n",
       " 'underwriting': 0,\n",
       " 'ratio': 0,\n",
       " 'difference': 0,\n",
       " 'quarter': 0,\n",
       " 'impact': 0,\n",
       " 'assumption': 0,\n",
       " 'period': 0,\n",
       " 'storm': 0,\n",
       " 'credit': 0,\n",
       " 'stimulus': 0,\n",
       " 'reporting': 0,\n",
       " 'business': 0,\n",
       " 'lot': 0,\n",
       " 'cleanup': 0,\n",
       " 'number': 0,\n",
       " 'account': 0,\n",
       " 'round': 0,\n",
       " 'position': 0,\n",
       " 'uncertainty': 0,\n",
       " 'thenet': 0,\n",
       " 'activity': 0,\n",
       " 'figure': 0,\n",
       " 'net': 0,\n",
       " 'tail': 0,\n",
       " 'level': 0,\n",
       " 'surety': 0,\n",
       " 'hand': 0,\n",
       " 'protection': 0,\n",
       " 'thatfreeze': 0,\n",
       " 'winter': 0,\n",
       " 'positiverunoff': 0,\n",
       " 'trade': 0,\n",
       " 'andcapacity': 0,\n",
       " 'recovery': 0,\n",
       " 'company': 0,\n",
       " 'situation': 0,\n",
       " 'termlevel': 0,\n",
       " 'ourtransaction': 0,\n",
       " 'half': 0,\n",
       " 'wenow': 0,\n",
       " 'thewinter': 0,\n",
       " 'construction': 0,\n",
       " 'thebulk': 0,\n",
       " 'ofinsolvencie': 0,\n",
       " 'gap': 0,\n",
       " 'excess': 0,\n",
       " 'higherthan': 0,\n",
       " 'thedifference': 0,\n",
       " 'insolvency': 0,\n",
       " 'package': 0,\n",
       " 'amount': 0,\n",
       " 'effect': 0,\n",
       " 'bit': 0,\n",
       " 'budget': 0,\n",
       " 'growth': 0,\n",
       " 'portfolio': 0,\n",
       " 'increase': 0,\n",
       " 'side': 0,\n",
       " 'line': 0,\n",
       " 'mortality': 0,\n",
       " 'treaty': 0,\n",
       " 'way': 0,\n",
       " 'reinsurance': 0,\n",
       " 'change': 0,\n",
       " 'eur': 0,\n",
       " 'time': 0,\n",
       " 'thesetreatie': 0,\n",
       " 'month': 0,\n",
       " 'life': 0,\n",
       " 'rate': 0,\n",
       " 'release': 0,\n",
       " 'longevity': 0,\n",
       " 'investment': 0,\n",
       " 'lag': 0,\n",
       " 'market': 0,\n",
       " 'course': 0,\n",
       " 'health': 0,\n",
       " 'man': 0,\n",
       " 'premium': 0,\n",
       " 'result': 0,\n",
       " 'focus': 0,\n",
       " 'slide': 0,\n",
       " 'gain': 0,\n",
       " 'profit': 0,\n",
       " 'development': 0,\n",
       " 'tofour': 0,\n",
       " 'catastrophe': 0,\n",
       " 'pension': 0,\n",
       " 'thatis': 0,\n",
       " 'expectation': 0,\n",
       " 'term': 0,\n",
       " 'cover': 0,\n",
       " 'population': 0,\n",
       " 'future': 0,\n",
       " 'income': 0,\n",
       " 'regard': 0,\n",
       " 'model': 0,\n",
       " 'date': 0}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df\n",
    "\n",
    "# count the frequency of each word in each topic\n",
    "\n",
    "# Create a dictonary to record the word show up in Topic # 01, so word as the key and frequency as the value\n",
    "topic_01_dict = {}\n",
    "for word in topic_df['Topic # 01']:\n",
    "    if word in topic_01_dict:\n",
    "        topic_01_dict[word] += 0\n",
    "    else:\n",
    "        topic_01_dict[word] = 0\n",
    "topic_01_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising data and topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el71391404710320823209844590608\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el71391404710320823209844590608_data = {\"mdsDat\": {\"x\": [0.15460073763025237, 0.08683665217722139, -0.12257153352487032, -0.006963855509171108, 0.09775952102257453, -0.15941020884448653, -0.03739071749231148, -0.1559424087423077, 0.10703287901064927, 0.03604893427244963], \"y\": [0.0635478028295319, 0.1749640457612034, -0.15278418331132204, 0.11792719693164316, -0.16449798076204927, 0.11338487537693975, -0.11211437172812669, -0.0013511096401225798, -0.05003009315673147, 0.01095381769903386], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [42.72691767183272, 20.342338148004266, 6.856706918117474, 6.84893470236327, 6.4316722033895966, 3.99132176676184, 3.609970914785259, 3.37412084850319, 3.1573812833734984, 2.660635542868888]}, \"tinfo\": {\"Term\": [\"year\", \"growth\", \"question\", \"line\", \"business\", \"loss\", \"covid\", \"month\", \"premium\", \"number\", \"result\", \"life\", \"effect\", \"quarter\", \"portfolio\", \"claim\", \"investment\", \"impact\", \"ratio\", \"cover\", \"side\", \"eur\", \"mortality\", \"calculation\", \"health\", \"course\", \"bit\", \"underwriting\", \"fund\", \"assumption\", \"pension\", \"date\", \"gain\", \"issuance\", \"future\", \"comment\", \"reserve\", \"value\", \"currency\", \"market\", \"treaty\", \"slide\", \"thesetreatie\", \"focus\", \"provision\", \"impairment\", \"volatility\", \"people\", \"month\", \"reinsurance\", \"portfolio\", \"cash\", \"flow\", \"example\", \"payout\", \"block\", \"morbidity\", \"population\", \"movement\", \"runoff\", \"recovery\", \"bond\", \"income\", \"impact\", \"lot\", \"business\", \"expectation\", \"eur\", \"loss\", \"investment\", \"mortality\", \"line\", \"effect\", \"year\", \"quarter\", \"growth\", \"equity\", \"ratio\", \"life\", \"side\", \"health\", \"premium\", \"longevity\", \"question\", \"result\", \"dividend\", \"contract\", \"split\", \"proxy\", \"basis\", \"wholeaccount\", \"cedent\", \"answer\", \"message\", \"billion\", \"improvement\", \"ourguidance\", \"distribution\", \"funding\", \"gapbetween\", \"growthor\", \"on\", \"structure\", \"catbudget\", \"degree\", \"nature\", \"remainder\", \"downassumption\", \"andnatcat\", \"my\", \"theprecise\", \"tochange\", \"thatchange\", \"everyelement\", \"ladie\", \"budget\", \"guidance\", \"target\", \"growth\", \"range\", \"development\", \"return\", \"today\", \"loss\", \"year\", \"outlook\", \"question\", \"number\", \"time\", \"side\", \"quarter\", \"health\", \"life\", \"course\", \"profit\", \"account\", \"information\", \"increase\", \"book\", \"rate\", \"business\", \"mortality\", \"line\", \"longevity\", \"premium\", \"profitability\", \"up\", \"follow\", \"appetite\", \"deposit\", \"yourline\", \"thinking\", \"yoursolvency\", \"pricingpoint\", \"ratesyet\", \"hurdle\", \"andnobody\", \"ex\", \"presentation\", \"quitedifficult\", \"outthis\", \"idea\", \"someupdate\", \"isdeposit\", \"ofcovid\", \"statement\", \"unknown\", \"recalculation\", \"outcome\", \"covidclaim\", \"variant\", \"addback\", \"other\", \"thing\", \"view\", \"risk\", \"result\", \"accounting\", \"profitability\", \"rate\", \"claim\", \"cover\", \"eur\", \"side\", \"ebit\", \"number\", \"covid\", \"point\", \"mortality\", \"question\", \"time\", \"course\", \"longevity\", \"increase\", \"portfolio\", \"quarter\", \"loss\", \"life\", \"effect\", \"toeur\", \"opposite\", \"farstronger\", \"anotherlarge\", \"healthand\", \"frominflation\", \"core\", \"rebound\", \"walk\", \"netincome\", \"right\", \"yearof\", \"support\", \"ebitnumber\", \"thecontribution\", \"amortization\", \"surprise\", \"roughlyeur\", \"ratioalready\", \"amount\", \"digit\", \"bit\", \"bulk\", \"mix\", \"linker\", \"quality\", \"color\", \"thatwe\", \"the\", \"contributor\", \"effect\", \"couple\", \"equity\", \"number\", \"increase\", \"question\", \"year\", \"guidance\", \"life\", \"investment\", \"health\", \"contribution\", \"bond\", \"book\", \"course\", \"profitability\", \"growth\", \"income\", \"side\", \"business\", \"account\", \"reason\", \"flood\", \"month\", \"eur\", \"retro\", \"statistic\", \"agent\", \"ourown\", \"calculation\", \"at\", \"rest\", \"saidthat\", \"buffer\", \"someexpectation\", \"ofthat\", \"assoon\", \"recuperation\", \"sir\", \"host\", \"isbeing\", \"lady\", \"normalmortality\", \"secondone\", \"youthink\", \"kick\", \"goingforward\", \"there\", \"clarification\", \"potential\", \"theimplication\", \"sgoing\", \"sort\", \"trigger\", \"thank\", \"half\", \"cover\", \"retro\", \"life\", \"year\", \"longevity\", \"today\", \"growth\", \"number\", \"mortality\", \"health\", \"point\", \"information\", \"time\", \"claim\", \"ratio\", \"covid\", \"question\", \"guidance\", \"digit\", \"increase\", \"couple\", \"term\", \"morning\", \"release\", \"rate\", \"stimulus\", \"reporting\", \"thenet\", \"tail\", \"protection\", \"thatfreeze\", \"winter\", \"positiverunoff\", \"trade\", \"andcapacity\", \"termlevel\", \"ourtransaction\", \"wenow\", \"thewinter\", \"construction\", \"ofinsolvencie\", \"thebulk\", \"gap\", \"higherthan\", \"thedifference\", \"insolvency\", \"package\", \"storm\", \"underwriting\", \"difference\", \"half\", \"excess\", \"credit\", \"round\", \"uncertainty\", \"period\", \"year\", \"ratio\", \"assumption\", \"loss\", \"impact\", \"quarter\", \"business\", \"lot\", \"cleanup\", \"number\", \"account\", \"position\", \"activity\", \"figure\", \"net\", \"level\", \"surety\", \"hand\", \"speaker\", \"car\", \"thesecond\", \"thirdquarter\", \"hospital\", \"accident\", \"thatha\", \"weeksand\", \"yourquestion\", \"derivative\", \"linker\", \"mind\", \"deviation\", \"analysis\", \"vinit\", \"fact\", \"covid\", \"country\", \"remark\", \"claim\", \"bit\", \"line\", \"picture\", \"inflation\", \"part\", \"question\", \"basis\", \"lag\", \"top\", \"driver\", \"side\", \"quarter\", \"life\", \"result\", \"profitability\", \"health\", \"business\", \"investment\", \"retro\", \"book\", \"contribution\", \"point\", \"lot\", \"people\", \"clarity\", \"quantification\", \"speculating\", \"spillover\", \"howhigh\", \"thelongevity\", \"budgeting\", \"grossand\", \"thegerman\", \"peak\", \"writing\", \"thatis\", \"regard\", \"wehave\", \"ambition\", \"ourpremium\", \"tofour\", \"smallerportion\", \"modeling\", \"coverage\", \"percentage\", \"trigger\", \"fronting\", \"bulk\", \"mix\", \"benefit\", \"session\", \"catastrophe\", \"premium\", \"change\", \"assumption\", \"impact\", \"portfolio\", \"number\", \"question\", \"business\", \"eur\", \"loss\", \"situation\", \"activity\", \"one\", \"life\", \"health\", \"guidance\", \"outlook\", \"release\", \"difference\", \"net\", \"vinit\", \"apology\", \"booking\", \"straight\", \"death\", \"dip\", \"andcredit\", \"thebasis\", \"growththat\", \"status\", \"usualexercise\", \"reserving\", \"wespeak\", \"reasonwhy\", \"inq\", \"cetera\", \"model\", \"planning\", \"exercise\", \"reflection\", \"fund\", \"reallocation\", \"newbusiness\", \"case\", \"perspective\", \"et\", \"cycle\", \"position\", \"decrease\", \"driver\", \"ratio\", \"investment\", \"year\", \"quarter\", \"number\", \"business\", \"health\", \"loss\", \"life\", \"asset\", \"mortality\", \"cash\", \"increase\", \"flow\", \"portfolio\", \"morning\", \"couple\", \"supporting\", \"thesolvency\", \"assetallocation\", \"usualplanning\", \"thatincrease\", \"decline\", \"declined\", \"wasanother\", \"contributor\", \"percentage\", \"capacity\", \"cycle\", \"figure\", \"model\", \"andhealth\", \"digit\", \"risk\", \"driver\", \"month\", \"end\", \"course\", \"asset\", \"point\", \"calculation\", \"morning\", \"number\", \"business\", \"booking\", \"death\", \"straight\", \"life\", \"ratio\", \"growth\", \"year\", \"investment\", \"effect\", \"increase\", \"health\", \"question\"], \"Freq\": [65.0, 46.0, 28.0, 18.0, 29.0, 43.0, 15.0, 13.0, 11.0, 27.0, 13.0, 25.0, 18.0, 23.0, 17.0, 12.0, 15.0, 14.0, 14.0, 10.0, 19.0, 19.0, 21.0, 7.0, 18.0, 11.0, 7.0, 5.0, 5.0, 7.0, 4.7611956466091, 4.7523100420797375, 4.748644171683259, 3.826875177768491, 3.825622534022631, 3.823112239037463, 3.823232418880239, 3.817390599984265, 3.817059720224827, 12.21888799632886, 6.641900791584393, 7.544566197991195, 2.893314307164915, 2.8902466396396918, 2.8897838316874624, 2.8887965850944, 2.888351688561046, 4.760927938305481, 11.270214510496176, 9.418727704604045, 14.082735607203967, 7.569612909839527, 7.568833281628697, 1.965826948327281, 1.9656414784737657, 1.9617947605254178, 1.9608651001070192, 1.9605486650402222, 1.9605914213304407, 1.9592588502852988, 3.8320502296521393, 5.694352065818718, 9.416878013562341, 10.346233360052357, 4.762799585279999, 19.722917379274918, 5.6835212426803166, 12.247387567506186, 24.332361322103623, 10.339595734889794, 13.180072511947989, 11.293152682410673, 11.291567232946356, 29.065149843568303, 11.267819387860335, 15.95600038729764, 5.685616300901021, 6.639511832017412, 8.509445473392084, 7.572688281200826, 6.626938401158756, 5.6857503476487325, 5.702401033750293, 6.677691273223475, 5.701810919906918, 5.270555577572137, 3.56167825208618, 2.693952229099452, 2.687495056904923, 6.148590885844733, 1.82491478213195, 1.8249145987416575, 1.824911481106687, 1.821579462884523, 1.8198356045943276, 1.8136311442226913, 1.8131523121692998, 1.8120917661084943, 0.9558660566614665, 0.9558660566614665, 0.9558660566614665, 0.9558660566614665, 0.9558660566614665, 0.9558659649663204, 0.9558659649663204, 0.9558659649663204, 0.9558659649663204, 0.9558658732711741, 0.9558656898808817, 0.9558656898808817, 0.9558655981857356, 0.9558655064905894, 0.9558655064905894, 0.9558655064905894, 0.955862388855619, 9.550848323549776, 7.000784301238163, 4.408121648252479, 22.606383431585474, 1.8188451136252095, 3.535037511093426, 4.41385626269505, 2.6873965763179175, 13.253013442671113, 18.238926013203095, 2.6834384636375845, 8.948700969759345, 8.771505601460623, 4.407812452219534, 6.161984979238645, 7.049754644230515, 5.273874208302957, 5.279735362047267, 3.539424940448209, 2.684949966427341, 2.6947032123467287, 2.693954429782961, 3.4913146979270957, 2.694106643725632, 2.6839895514661722, 3.562009821734794, 3.0795664467058135, 2.883979782936249, 2.6966332117836846, 2.695081363129606, 2.689802290173295, 2.1789188911860915, 2.178643198072117, 1.4786445352210542, 1.4559460906386341, 0.7747129802884889, 0.7747094568563149, 0.7747089005249189, 0.7746156841088039, 0.774584220477635, 0.7745258674956638, 0.7694840214983094, 0.7695791541670104, 0.7694404422056297, 0.7694787672573481, 0.7692731100846592, 0.7692880074031497, 0.7687504676454994, 0.7686327726479641, 0.7685140268022366, 0.7680884332843637, 0.768239322721855, 0.7677435078188981, 0.7674896970731631, 0.767458666144191, 0.7666966157609902, 0.7657359550694489, 0.7620781997705247, 1.4658257944548416, 2.1829042020480087, 1.478850748725139, 4.916358898658771, 2.149497119869472, 2.8699304530383882, 2.182929175146225, 2.4240038880492953, 2.1578307169218394, 2.834458515976623, 2.7580475114108634, 1.4574725403598183, 2.8752111506483873, 2.1876639262130357, 1.4787622302185894, 2.124788340880623, 2.288256060345921, 1.4710692796759144, 1.4587141484062955, 1.4239894262238402, 1.4804898246466958, 1.4793792635512557, 1.4802642013583536, 1.4673487825584512, 1.3126592307454543, 0.7764126345176005, 0.7692469000716692, 0.7692466530935435, 0.7692463443708861, 0.7667305634369984, 0.7666223252733684, 0.7665691632317909, 0.7665473056676579, 0.7664662350978655, 0.7664176421516151, 0.7663791753085224, 0.766344042670128, 0.7663375594943258, 0.7663429930130934, 0.7663085395645448, 0.7662176516142519, 0.7661125624217259, 0.7660759479145767, 0.766088790777118, 0.7659578306259147, 2.8310922265943423, 2.8560743109967155, 3.5335730977079063, 0.7692467765826063, 0.7666519009039324, 0.7659014578687019, 0.7661066966912382, 0.7660618701614063, 0.7669082641985085, 0.7664314729266597, 0.7662143791540852, 4.238365437100794, 1.4643417050997147, 2.162465388117989, 4.257637634212893, 2.857735238892692, 3.554871256385909, 5.628412664267364, 2.158840984121935, 2.8615611770393956, 2.16277608660024, 2.1647474660003425, 1.4641800579163815, 1.4644400023937816, 1.4634466563718307, 1.4653555503061066, 1.4654706421127275, 2.1632413933892396, 1.4639043068389304, 1.4645142193205831, 1.4658764271734102, 0.771087010597911, 0.7703528681189828, 0.7699456011895456, 0.7697680239170984, 0.7696703440683461, 0.7693477906360567, 2.7798045089901207, 2.1017981087576407, 1.4237912446625554, 4.137935074178568, 0.7457824671342241, 0.7457824671342241, 0.7457824091513985, 0.7457824091513985, 0.7457822352029216, 0.7457821192372703, 0.7457821192372703, 0.7457820612544447, 0.7457818293231422, 0.7457818293231422, 0.7457815973918396, 0.7457814814261884, 0.7450237618607922, 0.7449416581796933, 0.7448890097740168, 0.744854683941241, 0.7447967011156061, 0.744747821593596, 0.7447373267021561, 0.7447112344306204, 0.7446970866211655, 0.7446229265871785, 0.7444617343319136, 0.7445056853137448, 2.1010250817262768, 0.7460559141399181, 3.970037221094682, 2.047079716206038, 4.143729645841212, 4.836409643791451, 2.1015761505011104, 1.4265613161744344, 3.4738211270368944, 2.789480914863366, 2.4811479622979795, 2.1060744581138615, 1.4248904830709408, 1.4251351705951198, 1.4285544178228065, 1.4336534275091348, 1.4245425861171317, 1.431353480747503, 0.7638673684325578, 0.755523581840878, 0.7509369084018592, 0.749906727538805, 0.7477357345813852, 0.747305270083872, 0.747108534356493, 0.7469979031251818, 0.7469863645428805, 1.204899914857015, 1.2047326678580839, 0.6315560447678955, 0.6314857348204101, 0.6313915324445062, 0.6313492889038983, 0.6312563099354735, 0.6312368793460968, 0.6312362316597843, 0.6312261565393668, 0.6311550549752772, 0.631135408490463, 0.6310621479719983, 0.6310507774789557, 0.6310321385061832, 0.6310182492330362, 0.6310297636563704, 0.6309708242019278, 0.630827613561707, 0.6308196973956647, 0.6307797567397238, 0.6306926069481119, 1.2056377015321627, 2.3528913756172845, 1.7789038492637754, 0.6310979146494806, 0.630890439134025, 1.2055879016512416, 0.6316501032135078, 0.6316239798655681, 1.2058112814639277, 4.122404205139867, 1.7810236545996265, 1.2071451554420647, 2.363816836198069, 1.2079102169074853, 1.20838374756711, 0.6346288845301005, 0.634066908706239, 0.6337262257058344, 0.632434235442576, 0.6319644469705352, 0.6316357101843398, 0.63153244020006, 0.6314977529997654, 0.6314895489731397, 0.6314814888768057, 0.6314491045611779, 0.6314436352100941, 0.588860232812324, 0.588234009275346, 0.5881342274769688, 0.5880457061163732, 0.5880317119306908, 0.5880055460579264, 0.587993048924666, 0.5877918580970182, 0.5877453843827055, 1.080529999900378, 0.5879413680714947, 0.5887593444969393, 0.588309057164145, 0.5880001436513608, 0.588049611470517, 1.1225663206562657, 3.7673032595756513, 0.588269222551877, 0.5896247709752327, 2.535028381200656, 1.3175602625269305, 3.1422836131016862, 0.5884700228441104, 0.5883138737675893, 0.5883007257419713, 4.118823665356281, 1.1099530681991658, 0.5886222665664876, 0.5895206281980614, 0.5887818653725027, 1.2153015583731483, 1.1256425681154338, 0.7102590125362374, 0.636331049127188, 0.6023661190482532, 0.595426044377559, 0.5924422236331303, 0.591354257057869, 0.5903698474566575, 0.5899157849481907, 0.5896823098596199, 0.5894344500499522, 0.5892035785308106, 0.5884456143807109, 1.1101078939367421, 0.581478516929725, 0.5814780302356158, 0.5814779693988522, 0.5814779085620886, 0.581476813500343, 0.5814765093165247, 0.5805463152004413, 0.5802704204773256, 0.5802615991465976, 0.5799676967414439, 0.5765725186361209, 0.5741484777888124, 0.574165025388523, 0.5739693743566509, 0.5723744169242532, 0.5718945365326464, 0.5675446470954923, 0.5655793154460432, 1.1101064338544147, 0.5372358931226625, 0.5814762659694702, 0.5803986643750826, 0.5732716375144428, 0.5721599673324157, 0.5814783344194341, 0.5801064653993109, 0.5644149606267023, 2.6973122891759482, 1.058601664734664, 1.1045771020805366, 1.1130850018023184, 1.1102972179451955, 1.1110722783139924, 1.1121500624186709, 1.1109097224815414, 0.903185939048531, 1.0534105853666345, 0.5804063298073014, 0.5803798658151172, 0.5814783344194341, 0.5851170420896152, 0.5832511177119568, 0.5822101398492815, 0.5821484513709487, 0.5818885567166708, 0.5809250848908752, 0.5804579802196334, 1.0778672695934812, 0.5656426072284524, 0.5656424933707291, 0.5656424364418676, 0.5656423225841444, 0.5650968871609912, 0.56509438229108, 0.5650778159923494, 0.5649937889926027, 0.56499299198854, 0.5649703912304781, 0.5649657230638254, 0.5649010518770284, 0.5648851687246372, 0.5648551102857035, 1.078634556790356, 1.0782693012142208, 0.565237102947154, 0.5650631852749138, 0.5707092759123719, 1.5928156933425786, 0.5653478865118609, 0.5653928033836767, 0.5650648931407624, 0.5650933006427094, 0.5650860137484223, 0.5707042092436879, 0.5650126893746595, 0.5692189352440985, 0.5689618445050358, 1.080360298301416, 1.0883197501595452, 1.6228190251383472, 1.0868163727819615, 1.0847862895766969, 1.0889263841089367, 0.5780463245264417, 0.5810009893732293, 0.5784175576330466, 0.5708034362494865, 0.5707041523148263, 0.5701090179954814, 0.5697512770290797, 0.5691754985226847, 0.5682402711840394, 0.5672374123577931, 0.5660216965179605, 0.5178389052199879, 0.5173395132126882, 0.5173071798589015, 0.5172299923718943, 0.5170533582344421, 0.5169094412294566, 0.516896392754338, 0.51677665380619, 0.9869359991914921, 0.5168619486178114, 0.5190246853963982, 0.5174041319479268, 0.9919470933604168, 0.5172643405637508, 0.5184113590934851, 0.9893104378844126, 0.5183136394471, 0.5192062606843549, 1.4748923612749743, 0.5196643485112238, 0.9900355877001995, 0.520434640294241, 0.5179825823632984, 0.5178052766131562, 0.5193228334583933, 1.4599685516366594, 1.4730229753248827, 0.0470846968842039, 0.04708468788939109, 0.047084690887662026, 0.9966991369203674, 0.5221525296104178, 1.4751959302108235, 1.0076351982398744, 0.5322784821088614, 0.5300551082988407, 0.525531173191792, 0.5253111240911692, 0.5184501687124963], \"Total\": [65.0, 46.0, 28.0, 18.0, 29.0, 43.0, 15.0, 13.0, 11.0, 27.0, 13.0, 25.0, 18.0, 23.0, 17.0, 12.0, 15.0, 14.0, 14.0, 10.0, 19.0, 19.0, 21.0, 7.0, 18.0, 11.0, 7.0, 5.0, 5.0, 7.0, 5.331974486435392, 5.328335195780091, 5.326372556937887, 4.395445983905586, 4.395012412477342, 4.394366563313994, 4.39456648451751, 4.392109635958749, 4.392305035768122, 14.360822408257498, 7.909315629481046, 9.000870116344114, 3.4584042876053673, 3.4576012547394077, 3.4579930888898454, 3.457091591804418, 3.457287612934091, 5.867560837497908, 13.986467677618572, 11.7435128477949, 17.667668709963575, 9.525406902279366, 9.526144840587842, 2.525661818932445, 2.5257311467766237, 2.523295791485336, 2.5228591860781613, 2.5228832090499624, 2.5237390364658667, 2.522621259775106, 4.974212792884827, 7.666907257132347, 13.14175430701356, 14.697392334900908, 6.442890809142784, 29.79568468199729, 7.829575392594749, 19.26170733785736, 43.331770569197, 15.937444890633612, 21.775438371269072, 18.47137669323954, 18.980915232193354, 65.42981819945534, 23.48246382861331, 46.022887654937506, 9.228049366577979, 14.062011752364599, 25.038056702302278, 19.478047418739116, 18.584797321483975, 11.51266671047344, 12.306632371352611, 28.10318474323497, 13.450613923496574, 5.856277589391451, 4.127067325752879, 3.25831764649722, 3.2559024699278414, 7.804635960407901, 2.3892801101408225, 2.389279920638343, 2.3892770579388105, 2.388546246019506, 2.3881014196236765, 2.385870237869793, 2.385691980796239, 2.3843899737303995, 1.5202313214391534, 1.5202313214391534, 1.5202313214391534, 1.5202313214391534, 1.5202313214391534, 1.5202312297440073, 1.5202312297440073, 1.5202312297440073, 1.5202312297440073, 1.5202311380488611, 1.5202309582166225, 1.5202309591563903, 1.5202308629634225, 1.5202307819846137, 1.520230797440651, 1.5202307980923693, 1.520227766199824, 15.525693773099125, 11.832905911258951, 7.536507717916366, 46.022887654937506, 3.0869610046216525, 7.598742936872556, 10.36656343479994, 5.5485441085006375, 43.331770569197, 65.42981819945534, 5.654392932057196, 28.10318474323497, 27.821069421760615, 11.494979724431532, 19.478047418739116, 23.48246382861331, 18.584797321483975, 25.038056702302278, 11.615105445693358, 6.998536932976251, 7.110548115809583, 7.191138691730902, 15.576697138953334, 7.996853113692976, 8.851615372928952, 29.79568468199729, 21.775438371269072, 18.47137669323954, 12.306632371352611, 11.51266671047344, 11.746077100302296, 2.7642581933646233, 2.7643685959890094, 2.0599622412074967, 2.057532433084044, 1.355551064011833, 1.355552210361591, 1.3555520703168642, 1.35558016936015, 1.355587153416842, 1.3556005649240332, 1.3551711533797137, 1.3554363713529822, 1.3552003984043108, 1.3554118670339517, 1.35530803430889, 1.3555828595625177, 1.3556671063525387, 1.3555675537678684, 1.3553855288993713, 1.355178055685511, 1.355615866211478, 1.3550752085998652, 1.355300625565525, 1.3556016665864488, 1.3554690717628637, 1.3555631733474744, 1.3544426149945301, 2.7372209278604918, 4.311186235482263, 3.4667993807855346, 13.450613923496574, 5.568432602482319, 11.746077100302296, 8.851615372928952, 12.968909958511817, 10.486576532299802, 19.26170733785736, 19.478047418739116, 5.733180175424089, 27.821069421760615, 15.849740192118848, 7.1637405400916645, 21.775438371269072, 28.10318474323497, 11.494979724431532, 11.615105445693358, 12.306632371352611, 15.576697138953334, 17.667668709963575, 23.48246382861331, 43.331770569197, 25.038056702302278, 18.980915232193354, 1.3505819588378836, 1.3505816877009529, 1.3505814401962857, 1.350648641389969, 1.350655076666845, 1.3506626677488323, 1.3507020811364636, 1.3506469906313672, 1.350652504030147, 1.3506217590051706, 1.350569839058501, 1.350645435824595, 1.3506867117222288, 1.3506826210868246, 1.3506202304272528, 1.350617861830236, 1.3506635428038214, 1.3507241421689404, 1.350670152195935, 5.083904084141314, 6.004371168043881, 7.649357089393822, 1.8837295903016484, 1.8844838350523052, 1.8861028647496914, 2.2190625154915438, 2.2197851605525805, 2.286293447412175, 2.2862087991090685, 2.2942130195906794, 18.980915232193354, 5.114437014651668, 9.228049366577979, 27.821069421760615, 15.576697138953334, 28.10318474323497, 65.42981819945534, 11.832905911258951, 25.038056702302278, 15.937444890633612, 18.584797321483975, 7.1946783019638145, 7.666907257132347, 7.996853113692976, 11.615105445693358, 11.746077100302296, 46.022887654937506, 13.14175430701356, 19.478047418739116, 29.79568468199729, 7.110548115809583, 5.8939906313074415, 3.9250608548542636, 13.986467677618572, 19.26170733785736, 6.336089002214497, 3.3632729520900573, 2.6852665241014324, 2.0072596721288187, 7.341084307005131, 1.3292507144818426, 1.3292507144818426, 1.3292506603013148, 1.3292506668576396, 1.3292505195659199, 1.3292504129915454, 1.3292504187224923, 1.3292503607396666, 1.3292501390371323, 1.3292501401067542, 1.329249937487444, 1.3292498342384347, 1.3290909522194625, 1.329073697757539, 1.3290625396715645, 1.329055307233162, 1.329043102480633, 1.329032755786176, 1.3290306818146091, 1.3290250356992477, 1.3290221483275746, 1.329006336725344, 1.3289724752874799, 1.857595823872806, 5.358355433372589, 1.905740898078083, 10.486576532299802, 6.336089002214497, 25.038056702302278, 65.42981819945534, 12.306632371352611, 5.5485441085006375, 46.022887654937506, 27.821069421760615, 21.775438371269072, 18.584797321483975, 7.1637405400916645, 7.191138691730902, 11.494979724431532, 12.968909958511817, 14.062011752364599, 15.849740192118848, 28.10318474323497, 11.832905911258951, 6.004371168043881, 15.576697138953334, 5.114437014651668, 6.64212250552696, 7.395545268766851, 7.406035267009461, 8.851615372928952, 1.8041494331791483, 1.8042791807708876, 1.2274666813965125, 1.2275044884125996, 1.2275670485272525, 1.2275779965162652, 1.2276515806186024, 1.227637995280785, 1.227665434455554, 1.2277071457849764, 1.2276967115242479, 1.2276731735781656, 1.227751556453832, 1.2277725234485282, 1.2277765814590287, 1.2277645051178137, 1.2278010817867469, 1.2278166373306219, 1.2278393508665595, 1.227905031430477, 1.2279315583972779, 1.2279477002315684, 2.7392075823902604, 5.627005174612294, 4.549273678336792, 1.905740898078083, 1.9056495630163566, 3.67642120713681, 1.9317331049520652, 2.0950891722741845, 4.612029264071858, 65.42981819945534, 14.062011752364599, 7.286451089766164, 43.331770569197, 14.697392334900908, 23.48246382861331, 29.79568468199729, 6.442890809142784, 2.1622889235462686, 27.821069421760615, 7.110548115809583, 2.678210263634874, 2.6917592160010524, 4.97555221148499, 3.5601415418065794, 3.8032690426476927, 2.162906841572217, 2.1630071222014604, 1.1865951466684848, 1.1866515103832238, 1.1866512905433348, 1.1866745653520254, 1.1866668738069748, 1.1866498512441086, 1.1866691958090536, 1.1866676808597716, 1.1866896642821911, 2.6714006163400015, 1.8861028647496914, 2.054139664320823, 2.1226266011595376, 2.122608000680325, 2.216743803668458, 4.291969294937008, 15.849740192118848, 2.7325429806208503, 2.9886267192805454, 12.968909958511817, 7.649357089393822, 18.47137669323954, 3.7561485072426373, 3.7573446220585147, 3.925095557046894, 28.10318474323497, 7.804635960407901, 4.524622932025942, 4.793023199438068, 4.911250050821815, 19.478047418739116, 23.48246382861331, 25.038056702302278, 13.450613923496574, 11.746077100302296, 18.584797321483975, 29.79568468199729, 15.937444890633612, 6.336089002214497, 7.996853113692976, 7.1946783019638145, 7.1637405400916645, 6.442890809142784, 5.867560837497908, 1.70851432234422, 1.1798845509737803, 1.179884155132543, 1.179884100576103, 1.1798840510646869, 1.1798830914647236, 1.1798828983073366, 1.1798961299355721, 1.179899571398547, 1.1798995741899885, 1.1799032339713764, 1.182157367984511, 1.1837947361585206, 1.1838644432813217, 1.1839669458569761, 1.1852254497971777, 1.1851117049849846, 1.1880774418554743, 1.1894531333003338, 3.255457826558428, 1.679616274795099, 1.857595823872806, 1.8841831139177339, 1.8837295903016484, 1.8844838350523052, 2.04842345610405, 2.0488604522436247, 2.1253724589772567, 11.51266671047344, 4.547383025230185, 7.286451089766164, 14.697392334900908, 17.667668709963575, 27.821069421760615, 28.10318474323497, 29.79568468199729, 19.26170733785736, 43.331770569197, 2.6917599937996513, 2.6917592160010524, 3.425692732858867, 25.038056702302278, 18.584797321483975, 11.832905911258951, 5.654392932057196, 7.406035267009461, 4.549273678336792, 3.5601415418065794, 2.216743803668458, 1.1654883268068783, 1.165488231900254, 1.1654882174935635, 1.1654881390768366, 1.1659391309510911, 1.1659409978170283, 1.1659549078950158, 1.166023771656687, 1.166024208470121, 1.1660432746317073, 1.1660471346496326, 1.1661000735567484, 1.1661130496965302, 1.1661378979162682, 2.6180932027202677, 2.687952898359732, 1.8701073042801908, 1.8701626112291154, 2.0304393558469043, 5.707044743686091, 2.101223739445521, 2.1014083447108036, 2.101889406403077, 2.1025922109221247, 2.103292878440462, 2.501985193788521, 2.678210263634874, 2.9670678915966917, 4.911250050821815, 14.062011752364599, 15.937444890633612, 65.42981819945534, 23.48246382861331, 27.821069421760615, 29.79568468199729, 18.584797321483975, 43.331770569197, 25.038056702302278, 7.1143243758036085, 21.775438371269072, 9.525406902279366, 15.576697138953334, 9.526144840587842, 17.667668709963575, 7.395545268766851, 5.114437014651668, 1.12207345371375, 1.1226806500325854, 1.1227128122314423, 1.1227892741437857, 1.1229641034527857, 1.1231062876600504, 1.123119426208966, 1.1232378441307427, 2.2942130195906794, 1.679616274795099, 2.0571633809463137, 2.501985193788521, 4.97555221148499, 2.687952898359732, 2.7357806916648935, 6.004371168043881, 3.4667993807855346, 4.911250050821815, 13.986467677618572, 5.497886984931765, 11.615105445693358, 7.1143243758036085, 7.1637405400916645, 7.341084307005131, 7.395545268766851, 27.821069421760615, 29.79568468199729, 1.165488231900254, 1.1654881390768366, 1.1654882174935635, 25.038056702302278, 14.062011752364599, 46.022887654937506, 65.42981819945534, 15.937444890633612, 18.980915232193354, 15.576697138953334, 18.584797321483975, 28.10318474323497], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.1575, -5.1594, -5.1602, -5.376, -5.3763, -5.377, -5.3769, -5.3785, -5.3786, -4.2151, -4.8246, -4.6972, -5.6556, -5.6567, -5.6569, -5.6572, -5.6574, -5.1576, -4.2959, -4.4753, -4.0731, -4.6939, -4.694, -6.0421, -6.0422, -6.0442, -6.0447, -6.0448, -6.0448, -6.0455, -5.3746, -4.9786, -4.4755, -4.3814, -5.1572, -3.7363, -4.9805, -4.2127, -3.5262, -4.3821, -4.1393, -4.2938, -4.294, -3.3485, -4.2961, -3.9482, -4.9801, -4.825, -4.5769, -4.6935, -4.8269, -4.9801, -4.9772, -4.8193, -4.9773, -4.3138, -4.7057, -4.9849, -4.9873, -4.1597, -5.3744, -5.3744, -5.3744, -5.3762, -5.3772, -5.3806, -5.3808, -5.3814, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -6.0211, -3.7193, -4.0299, -4.4925, -2.8577, -5.3777, -4.7132, -4.4912, -4.9873, -3.3917, -3.0724, -4.9888, -3.7844, -3.8044, -4.4925, -4.1575, -4.0229, -4.3131, -4.312, -4.7119, -4.9883, -4.9846, -4.9849, -4.7256, -4.9848, -4.9886, -4.7056, -4.8511, -4.9167, -4.9839, -4.9845, -4.9864, -4.1096, -4.1097, -4.4973, -4.5128, -5.1437, -5.1437, -5.1437, -5.1438, -5.1439, -5.1439, -5.1505, -5.1503, -5.1505, -5.1505, -5.1507, -5.1507, -5.1514, -5.1516, -5.1517, -5.1523, -5.1521, -5.1527, -5.1531, -5.1531, -5.1541, -5.1554, -5.1601, -4.506, -4.1078, -4.4972, -3.2959, -4.1232, -3.8341, -4.1078, -4.003, -4.1193, -3.8466, -3.8739, -4.5117, -3.8323, -4.1056, -4.4972, -4.1348, -4.0606, -4.5024, -4.5109, -4.535, -4.4961, -4.4968, -4.4962, -4.505, -4.6164, -5.1415, -5.1496, -5.1496, -5.1496, -5.1529, -5.1531, -5.1531, -5.1532, -5.1533, -5.1533, -5.1534, -5.1534, -5.1534, -5.1534, -5.1535, -5.1536, -5.1537, -5.1538, -5.1538, -5.1539, -3.8466, -3.8379, -3.625, -5.1496, -5.153, -5.154, -5.1537, -5.1538, -5.1527, -5.1533, -5.1536, -3.4431, -4.5059, -4.1161, -3.4386, -3.8373, -3.619, -3.1595, -4.1177, -3.8359, -4.1159, -4.115, -4.506, -4.5058, -4.5065, -4.5052, -4.5051, -4.1157, -4.5062, -4.5058, -4.5048, -5.1473, -5.1482, -5.1487, -5.149, -5.1491, -5.1495, -3.8021, -4.0817, -4.4711, -3.4042, -5.1178, -5.1178, -5.1178, -5.1178, -5.1178, -5.1178, -5.1178, -5.1178, -5.1178, -5.1178, -5.1178, -5.1178, -5.1188, -5.1189, -5.119, -5.119, -5.1191, -5.1192, -5.1192, -5.1192, -5.1192, -5.1193, -5.1195, -5.1195, -4.082, -5.1174, -3.4457, -4.108, -3.4028, -3.2483, -4.0818, -4.4692, -3.5792, -3.7986, -3.9157, -4.0796, -4.4703, -4.4702, -4.4678, -4.4642, -4.4706, -4.4658, -5.0938, -5.1048, -5.1109, -5.1123, -5.1151, -5.1157, -5.116, -5.1161, -5.1162, -4.1609, -4.1611, -4.8069, -4.807, -4.8072, -4.8072, -4.8074, -4.8074, -4.8074, -4.8074, -4.8075, -4.8076, -4.8077, -4.8077, -4.8077, -4.8078, -4.8077, -4.8078, -4.8081, -4.8081, -4.8081, -4.8083, -4.1603, -3.4917, -3.7713, -4.8076, -4.808, -4.1604, -4.8068, -4.8068, -4.1602, -2.9309, -3.7701, -4.1591, -3.4871, -4.1584, -4.158, -4.802, -4.8029, -4.8035, -4.8055, -4.8063, -4.8068, -4.8069, -4.807, -4.807, -4.807, -4.8071, -4.8071, -4.7765, -4.7775, -4.7777, -4.7779, -4.7779, -4.7779, -4.7779, -4.7783, -4.7784, -4.1695, -4.778, -4.7766, -4.7774, -4.7779, -4.7779, -4.1313, -2.9205, -4.7775, -4.7752, -3.3167, -3.9711, -3.102, -4.7771, -4.7774, -4.7774, -2.8313, -4.1426, -4.7769, -4.7754, -4.7766, -4.0519, -4.1286, -4.589, -4.6989, -4.7538, -4.7654, -4.7704, -4.7722, -4.7739, -4.7747, -4.7751, -4.7755, -4.7759, -4.7772, -4.0749, -4.7215, -4.7215, -4.7215, -4.7215, -4.7215, -4.7215, -4.7231, -4.7236, -4.7236, -4.7241, -4.73, -4.7342, -4.7342, -4.7345, -4.7373, -4.7381, -4.7458, -4.7492, -4.0749, -4.8007, -4.7215, -4.7234, -4.7357, -4.7377, -4.7215, -4.7239, -4.7513, -3.1871, -4.1224, -4.0799, -4.0722, -4.0747, -4.074, -4.073, -4.0742, -4.2812, -4.1273, -4.7234, -4.7234, -4.7215, -4.7153, -4.7185, -4.7203, -4.7204, -4.7208, -4.7225, -4.7233, -4.038, -4.6827, -4.6827, -4.6827, -4.6827, -4.6837, -4.6837, -4.6837, -4.6839, -4.6839, -4.6839, -4.6839, -4.6841, -4.6841, -4.6841, -4.0373, -4.0376, -4.6835, -4.6838, -4.6738, -3.6474, -4.6833, -4.6832, -4.6838, -4.6837, -4.6837, -4.6738, -4.6839, -4.6764, -4.6769, -4.0357, -4.0283, -3.6288, -4.0297, -4.0316, -4.0278, -4.6611, -4.656, -4.6604, -4.6737, -4.6738, -4.6749, -4.6755, -4.6765, -4.6782, -4.6799, -4.6821, -4.5999, -4.6008, -4.6009, -4.601, -4.6014, -4.6017, -4.6017, -4.6019, -3.9549, -4.6018, -4.5976, -4.6007, -3.9499, -4.601, -4.5988, -3.9525, -4.5989, -4.5972, -3.5532, -4.5963, -3.9518, -4.5949, -4.5996, -4.5999, -4.597, -3.5634, -3.5545, -6.9976, -6.9976, -6.9976, -3.9451, -4.5916, -3.553, -3.9342, -4.5724, -4.5765, -4.5851, -4.5855, -4.5987], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7371, 0.7359, 0.7355, 0.7118, 0.7116, 0.7111, 0.7111, 0.7101, 0.71, 0.6888, 0.6757, 0.6738, 0.6719, 0.6711, 0.6708, 0.6708, 0.6705, 0.6413, 0.6344, 0.6297, 0.6236, 0.6205, 0.6203, 0.5998, 0.5996, 0.5986, 0.5983, 0.5982, 0.5978, 0.5976, 0.5895, 0.5529, 0.5171, 0.4993, 0.5482, 0.4378, 0.53, 0.3975, 0.2733, 0.4177, 0.3483, 0.3583, 0.331, 0.0389, 0.116, -0.209, 0.366, 0.0999, -0.2289, -0.0944, -0.1809, 0.1449, 0.0811, -0.5868, -0.0079, 1.4871, 1.4451, 1.4023, 1.4006, 1.354, 1.323, 1.323, 1.323, 1.3215, 1.3207, 1.3182, 1.318, 1.318, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1285, 1.1066, 1.0676, 1.0562, 0.8816, 1.0635, 0.8272, 0.7386, 0.8675, 0.4078, 0.315, 0.8471, 0.4481, 0.4382, 0.6339, 0.4416, 0.3892, 0.3329, 0.0359, 0.4041, 0.6344, 0.6222, 0.6106, 0.097, 0.5045, 0.3992, -0.5316, -0.3635, -0.2646, 0.0743, 0.1404, 0.1184, 2.442, 2.4418, 2.3484, 2.3341, 2.1205, 2.1205, 2.1205, 2.1203, 2.1203, 2.1202, 2.114, 2.1139, 2.1139, 2.1138, 2.1136, 2.1134, 2.1127, 2.1126, 2.1126, 2.1122, 2.112, 2.1118, 2.1113, 2.111, 2.1101, 2.1088, 2.1048, 2.0554, 1.9994, 1.828, 1.6735, 1.7281, 1.2707, 1.28, 1.0028, 1.099, 0.7637, 0.7252, 1.3104, 0.4103, 0.6996, 1.1021, 0.3528, 0.1718, 0.624, 0.6052, 0.5233, 0.3265, 0.1998, -0.0841, -0.7055, -0.2684, -0.5166, 2.1182, 2.1182, 2.1182, 2.1149, 2.1147, 2.1147, 2.1146, 2.1145, 2.1145, 2.1144, 2.1144, 2.1144, 2.1143, 2.1143, 2.1142, 2.1141, 2.114, 2.114, 2.1138, 2.0957, 1.938, 1.9088, 1.7855, 1.7817, 1.7799, 1.6176, 1.6172, 1.5888, 1.5882, 1.5844, 1.1818, 1.4304, 1.2301, 0.804, 0.9853, 0.6135, 0.2279, 0.9798, 0.512, 0.6838, 0.531, 1.089, 1.0256, 0.9828, 0.6109, 0.5997, -0.3765, 0.4864, 0.0933, -0.3308, 0.4595, 0.6462, 1.0523, -0.2187, -0.5388, 0.5726, 2.5534, 2.4989, 2.4005, 2.1706, 2.166, 2.166, 2.166, 2.166, 2.166, 2.166, 2.166, 2.166, 2.166, 2.166, 2.166, 2.166, 2.1651, 2.165, 2.1649, 2.1649, 2.1648, 2.1648, 2.1648, 2.1647, 2.1647, 2.1646, 2.1644, 1.8296, 1.8077, 1.8061, 1.7726, 1.6141, 0.9451, 0.1391, 0.9765, 1.3857, 0.1601, 0.444, 0.5719, 0.5664, 1.129, 1.1254, 0.6587, 0.5416, 0.4543, 0.3394, -0.8613, -0.0073, 0.665, -0.2896, 0.8212, 0.5592, 0.4515, 0.4499, 0.2716, 2.8174, 2.8171, 2.5565, 2.5564, 2.5562, 2.5561, 2.5559, 2.5559, 2.5559, 2.5558, 2.5557, 2.5557, 2.5555, 2.5555, 2.5554, 2.5554, 2.5554, 2.5553, 2.5551, 2.555, 2.5549, 2.5548, 2.4004, 2.3491, 2.2821, 2.1159, 2.1156, 2.1061, 2.1032, 2.022, 1.8795, 0.4565, 1.1548, 1.4233, 0.3124, 0.7223, 0.2541, -0.628, 0.9025, 1.9937, -0.5629, 0.8005, 1.7765, 1.7712, 1.1569, 1.4916, 1.4255, 1.9899, 1.9898, 2.6208, 2.6197, 2.6195, 2.6194, 2.6193, 2.6193, 2.6193, 2.6189, 2.6188, 2.4163, 2.1558, 2.0719, 2.0383, 2.0378, 1.9945, 1.9803, 1.8847, 1.7857, 1.6984, 1.6891, 1.5626, 1.5502, 1.4678, 1.4673, 1.4236, 1.4012, 1.3711, 1.282, 1.2259, 1.2002, 0.5472, 0.2836, -0.2411, 0.2704, 0.3511, -0.1194, -0.5964, 0.0275, 0.9482, 0.7146, 0.82, 0.8238, 0.9295, 1.0218, 2.9579, 2.6814, 2.6814, 2.6814, 2.6814, 2.6814, 2.6814, 2.6798, 2.6793, 2.6793, 2.6788, 2.671, 2.6654, 2.6654, 2.665, 2.6611, 2.6604, 2.6503, 2.6456, 2.3132, 2.2492, 2.2276, 2.2115, 2.1994, 2.197, 2.1298, 2.1272, 2.0631, 1.9378, 1.9314, 1.5025, 0.8085, 0.6219, 0.1686, 0.1594, 0.0999, 0.3291, -0.3278, 1.8548, 1.8548, 1.6156, -0.3673, -0.0724, 0.3772, 1.1156, 0.8453, 1.3309, 1.5753, 2.7344, 2.7325, 2.7325, 2.7325, 2.7325, 2.7311, 2.7311, 2.7311, 2.7309, 2.7309, 2.7308, 2.7308, 2.7307, 2.7306, 2.7305, 2.5687, 2.542, 2.2589, 2.2586, 2.1863, 2.1792, 2.1426, 2.1426, 2.1418, 2.1415, 2.1411, 1.9775, 1.8994, 1.8044, 1.3, 0.8892, 0.7714, -0.2414, 0.3824, 0.211, 0.1463, -0.015, -0.8565, -0.3124, 0.9326, -0.1862, 0.6395, 0.1471, 0.6378, 0.0185, 0.8876, 1.2542, 2.8533, 2.8518, 2.8517, 2.8515, 2.851, 2.8506, 2.8506, 2.8502, 2.7831, 2.4481, 2.2495, 2.0506, 2.014, 1.9786, 1.9632, 1.8234, 1.7262, 1.3796, 1.3771, 1.2677, 1.1643, 1.0114, 0.9998, 0.975, 0.9705, 0.6792, 0.6196, 0.4177, 0.4177, 0.4177, 0.4029, 0.3333, 0.1863, -0.5468, 0.2273, 0.0484, 0.2375, 0.0605, -0.3662]}, \"token.table\": {\"Topic\": [7, 1, 2, 3, 4, 6, 1, 3, 1, 6, 8, 3, 5, 8, 4, 1, 3, 4, 1, 7, 6, 9, 1, 5, 10, 2, 3, 4, 2, 9, 3, 1, 2, 9, 10, 10, 5, 1, 5, 6, 8, 5, 2, 7, 2, 8, 2, 1, 2, 4, 7, 1, 1, 4, 1, 2, 4, 7, 9, 1, 2, 5, 8, 5, 4, 8, 1, 2, 4, 6, 7, 8, 9, 10, 1, 4, 5, 9, 10, 1, 10, 7, 1, 9, 1, 2, 9, 1, 8, 2, 2, 1, 9, 1, 8, 1, 2, 3, 4, 5, 7, 5, 8, 1, 6, 2, 4, 1, 6, 2, 1, 2, 4, 7, 4, 10, 4, 2, 5, 7, 1, 4, 5, 9, 1, 2, 3, 4, 10, 1, 2, 3, 5, 2, 5, 8, 1, 2, 3, 4, 5, 7, 3, 1, 6, 1, 2, 9, 10, 1, 9, 10, 10, 1, 2, 9, 2, 3, 1, 7, 1, 2, 5, 1, 7, 1, 3, 6, 8, 1, 4, 5, 10, 9, 2, 2, 2, 1, 2, 7, 9, 10, 1, 2, 3, 4, 1, 2, 3, 4, 10, 1, 2, 4, 10, 1, 2, 4, 1, 9, 1, 2, 3, 4, 8, 2, 3, 1, 5, 6, 3, 9, 1, 2, 4, 1, 4, 7, 4, 1, 6, 10, 1, 3, 4, 1, 2, 9, 1, 3, 4, 3, 8, 1, 3, 9, 2, 1, 1, 6, 2, 5, 8, 1, 2, 4, 5, 10, 2, 9, 1, 2, 4, 5, 8, 5, 6, 1, 6, 1, 2, 4, 5, 7, 8, 9, 10, 4, 6, 7, 5, 8, 3, 3, 1, 2, 5, 6, 8, 1, 2, 1, 2, 4, 1, 2, 3, 4, 5, 9, 10, 1, 4, 7, 1, 2, 3, 5, 9, 6, 1, 2, 4, 7, 9, 10, 5, 3, 1, 5, 2, 5, 1, 7, 8, 1, 3, 6, 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 2, 4, 7, 4, 7, 1, 2, 3, 5, 1, 2, 3, 6, 8, 9, 1, 6, 7, 1, 2, 5, 2, 2, 7, 4, 8, 8, 9, 10, 8, 1, 4, 10, 1, 1, 2, 3, 4, 5, 9, 10, 1, 2, 3, 5, 9, 1, 2, 2, 1, 2, 6, 8, 4, 1, 9, 5, 1, 2, 3, 4, 5, 6, 8, 9, 10, 3, 6, 5, 2, 2, 4, 5, 8, 4, 3, 2, 5, 8, 6, 3, 1, 2, 8, 3, 6, 1, 2, 7, 1, 8, 1, 1, 7, 8, 10, 1, 6, 1, 9, 1, 4, 7, 3, 9, 1, 2, 3, 5, 7, 10, 1, 1, 3, 8, 9, 1, 6, 9, 6, 5, 1, 2, 8, 3, 3, 1, 2, 1, 2, 3, 4, 7, 6, 1, 2, 2, 4, 8, 1, 2, 3, 6, 7, 9, 1, 2, 3, 4, 5, 7, 8, 10, 3, 2, 4, 1, 2, 3, 5, 3, 1, 2, 3, 4, 5, 6, 9, 10, 4, 1, 9, 1, 2, 4, 9, 4, 3, 1, 6, 5, 2, 9, 8, 1, 2, 1, 2, 5, 8, 2, 1, 2, 7, 6, 1, 9, 5, 1, 2, 3, 7, 1, 4, 5, 7, 8, 1, 2, 4, 4, 1, 3, 10, 4, 3, 6, 1, 5, 5, 2, 8, 5, 1, 2, 3, 4, 7, 5, 1, 6, 8, 1, 2, 8, 5, 3, 5, 7, 8, 8, 2, 3, 5, 9, 6, 1, 6, 9, 2, 4, 10, 1, 6, 4, 6, 1, 2, 5, 1, 2, 4, 5, 6, 1, 2, 5, 2, 6, 7, 10, 8, 1, 4, 1, 4, 9, 6, 4, 6, 8, 5, 8, 6, 2, 5, 7, 1, 10, 6, 3, 5, 3, 7, 1, 2, 3, 5, 2, 1, 2, 5, 4, 8, 1, 2, 7, 6, 1, 3, 5, 8, 2, 6, 1, 2, 6, 3, 3, 9, 10, 1, 3, 2, 3, 5, 7, 9, 1, 4, 10, 7, 8, 6, 9, 2, 6, 8, 1, 2, 3, 4, 5, 6, 9, 10, 4, 3, 7, 3, 5], \"Freq\": [0.8427085706466647, 0.2812722686670529, 0.4219084030005794, 0.14063613433352645, 0.14063613433352645, 0.14063613433352645, 0.5387512454874012, 0.3591674969916008, 0.3715042541901746, 0.3715042541901746, 0.3715042541901746, 0.7377007723886195, 0.7448050247709611, 0.8446181740962222, 0.7404018769934597, 0.19669922631298087, 0.19669922631298087, 0.5900976789389426, 0.4711185483515968, 0.4711185483515968, 0.8145264963499222, 0.857676333427063, 0.36552637535848587, 0.36552637535848587, 0.36552637535848587, 0.6577947874269686, 0.737914172321379, 0.7403850041790941, 0.8370732868147852, 0.858009451488655, 0.48544579118781606, 0.5622459405427622, 0.2811229702713811, 0.14056148513569056, 0.14056148513569056, 0.8906997311382374, 0.752303693807427, 0.5489640911222211, 0.13724102278055528, 0.13724102278055528, 0.13724102278055528, 0.7523035264192516, 0.7687738454986716, 0.1281289742497786, 0.488180311068067, 0.488180311068067, 0.837485369576626, 0.13072994087131126, 0.13072994087131126, 0.522919763485245, 0.13072994087131126, 0.7926141702248477, 0.7825841370936552, 0.13043068951560918, 0.3751475683432416, 0.3751475683432416, 0.1250491894477472, 0.1250491894477472, 0.8580095213570402, 0.32204680016704573, 0.6440936003340915, 0.06440936003340915, 0.8475417360778793, 0.752303553372675, 0.530861756989158, 0.530861756989158, 0.6712381411420999, 0.13424762822841999, 0.033561907057104996, 0.033561907057104996, 0.033561907057104996, 0.033561907057104996, 0.033561907057104996, 0.033561907057104996, 0.13621965886507575, 0.13621965886507575, 0.544878635460303, 0.13621965886507575, 0.13621965886507575, 0.48610626130239154, 0.48610626130239154, 0.8427073923978359, 0.47576242448991685, 0.47576242448991685, 0.8398591348455312, 0.1049823918556914, 0.1049823918556914, 0.47050576748378803, 0.47050576748378803, 0.6577946699387242, 0.8370722838811037, 0.3819573722436519, 0.3819573722436519, 0.6597201034870254, 0.2199067011623418, 0.23132244803897536, 0.23132244803897536, 0.15421496535931692, 0.07710748267965846, 0.07710748267965846, 0.23132244803897536, 0.7524280768557104, 0.58530384376756, 0.46247288653726576, 0.46247288653726576, 0.4504940467982342, 0.4504940467982342, 0.9102563344154466, 0.8144804316202624, 0.9692112302215232, 0.5559664841314983, 0.13899162103287457, 0.13899162103287457, 0.13899162103287457, 0.43587931524266843, 0.43587931524266843, 0.740355711274697, 0.36595947697510467, 0.36595947697510467, 0.36595947697510467, 0.39104988374487104, 0.19552494187243552, 0.19552494187243552, 0.19552494187243552, 0.34437913789952873, 0.34437913789952873, 0.08609478447488218, 0.08609478447488218, 0.08609478447488218, 0.1907200118017335, 0.1907200118017335, 0.1907200118017335, 0.381440023603467, 0.30717645666974275, 0.30717645666974275, 0.30717645666974275, 0.3154625842060306, 0.1892775505236184, 0.12618503368241224, 0.06309251684120612, 0.06309251684120612, 0.2523700673648245, 0.7376798248692832, 0.5440073069205246, 0.2720036534602623, 0.9106835630555162, 0.3996826210173506, 0.3996826210173506, 0.3996826210173506, 0.9383794029999981, 0.8580095896918205, 0.8903876783411678, 0.8903772623499625, 0.337033069864088, 0.337033069864088, 0.337033069864088, 0.6577946699387242, 0.4860190701835479, 0.3743354680250345, 0.3743354680250345, 0.3948021435812279, 0.5264028581083038, 0.13160071452707595, 0.47111441996144077, 0.47111441996144077, 0.219815309147459, 0.219815309147459, 0.439630618294918, 0.219815309147459, 0.1665453337265595, 0.4996360011796785, 0.1665453337265595, 0.1665453337265595, 0.8576777067120737, 0.8387889657458096, 0.8537846650331973, 0.6577947096146504, 0.4072282981529995, 0.20361414907649975, 0.20361414907649975, 0.20361414907649975, 0.20361414907649975, 0.5232697923675644, 0.1744232641225215, 0.1744232641225215, 0.7403663779988163, 0.5795294834541489, 0.10536899699166342, 0.05268449849583171, 0.21073799398332685, 0.05268449849583171, 0.5456641812067429, 0.18188806040224764, 0.18188806040224764, 0.18188806040224764, 0.6501915802196201, 0.10836526336993667, 0.21673052673987334, 0.47544496073294107, 0.47544496073294107, 0.6229977327303147, 0.10383295545505244, 0.15574943318257867, 0.05191647772752622, 0.05191647772752622, 0.6577948567117767, 0.737769784797652, 0.7918716532070658, 0.524755453157479, 0.524755453157479, 0.534712860793841, 0.534712860793841, 0.7663250813926422, 0.12772084689877372, 0.12772084689877372, 0.4659865582820656, 0.2329932791410328, 0.2329932791410328, 0.7404218436873128, 0.6029481497702198, 0.20098271659007327, 0.20098271659007327, 0.5095462399077274, 0.2547731199538637, 0.2547731199538637, 0.8397940755545277, 0.10497425944431596, 0.10497425944431596, 0.8676535490863315, 0.7234925193774526, 0.7403773154304424, 0.5307339783555992, 0.5307339783555992, 0.52566610824613, 0.17522203608204334, 0.3504440721640867, 0.6577946302628028, 0.9101225718143796, 0.9387251730048869, 0.8144538602881986, 0.6577946302628028, 0.7524210449860651, 0.8475322315487251, 0.3476531094694025, 0.499751344862266, 0.04345663868367531, 0.06518495802551297, 0.021728319341837655, 0.6577946302628028, 0.8576154485934705, 0.08451009477295894, 0.5915706634107125, 0.16902018954591788, 0.08451009477295894, 0.08451009477295894, 0.5247303035834977, 0.5247303035834977, 0.46231932837198536, 0.46231932837198536, 0.37665194184862155, 0.26903710132044395, 0.10761484052817759, 0.10761484052817759, 0.053807420264088794, 0.053807420264088794, 0.053807420264088794, 0.053807420264088794, 0.7403814765704699, 0.8144387938814962, 0.8426964821153857, 0.7523038514930593, 0.8475409080219657, 0.737680424363086, 0.7376900592581455, 0.6803928052089672, 0.06803928052089671, 0.06803928052089671, 0.06803928052089671, 0.06803928052089671, 0.8677814632137529, 0.8382685563761781, 0.684840074600758, 0.1521866832446129, 0.07609334162230645, 0.38519077224628934, 0.19259538612314467, 0.06419846204104822, 0.19259538612314467, 0.06419846204104822, 0.06419846204104822, 0.06419846204104822, 0.5322908067198455, 0.26614540335992276, 0.26614540335992276, 0.27812007051119764, 0.4171801057667964, 0.13906003525559882, 0.13906003525559882, 0.8575315164586158, 0.8143776362464542, 0.6274531500263866, 0.06274531500263866, 0.12549063000527733, 0.06274531500263866, 0.06274531500263866, 0.06274531500263866, 0.7523039661677215, 0.7376983885609018, 0.9100327963638831, 0.7524141354822984, 0.657796168596329, 0.7523040246026652, 0.6630386763868348, 0.22101289212894493, 0.22101289212894493, 0.5258634026604847, 0.26293170133024235, 0.26293170133024235, 0.3594528164469106, 0.19969600913717256, 0.03993920182743451, 0.11981760548230352, 0.15975680730973804, 0.03993920182743451, 0.03993920182743451, 0.03993920182743451, 0.03993920182743451, 0.5955159803560263, 0.16241344918800715, 0.05413781639600239, 0.16241344918800715, 0.5301937761134317, 0.5301937761134317, 0.4875419870318711, 0.24377099351593556, 0.08125699783864518, 0.16251399567729036, 0.5538661283566553, 0.3000108195265216, 0.02307775534819397, 0.04615551069638794, 0.02307775534819397, 0.02307775534819397, 0.776049159936833, 0.1552098319873666, 0.1552098319873666, 0.8356067402588294, 0.06963389502156912, 0.06963389502156912, 0.8373294020716512, 0.4868218151712864, 0.4868218151712864, 0.530649285177999, 0.530649285177999, 0.3720303285858281, 0.3720303285858281, 0.3720303285858281, 0.840722490028115, 0.7864744875936347, 0.07149768069033043, 0.07149768069033043, 0.7927513398435221, 0.40564960269660094, 0.1352165342322003, 0.1352165342322003, 0.1352165342322003, 0.1352165342322003, 0.1352165342322003, 0.1352165342322003, 0.5970029065937175, 0.1377699015216271, 0.09184660101441806, 0.09184660101441806, 0.04592330050720903, 0.7924749631803105, 0.6577947870203368, 0.6577946699387242, 0.2808877086085049, 0.2808877086085049, 0.2808877086085049, 0.2808877086085049, 0.740399740588047, 0.47587133767550555, 0.47587133767550555, 0.7523939564332222, 0.17971990667221382, 0.3234958320099849, 0.10783194400332831, 0.14377592533777106, 0.10783194400332831, 0.035943981334442765, 0.035943981334442765, 0.035943981334442765, 0.035943981334442765, 0.737797459599588, 0.8144884428826538, 0.7523036970509186, 0.6577946302628028, 0.29191176149807896, 0.29191176149807896, 0.29191176149807896, 0.29191176149807896, 0.7404217079992136, 0.7383110874756688, 0.8383311911592577, 0.4981916459963749, 0.8437213360303101, 0.8145490359501859, 0.7378436792078739, 0.3537072898951072, 0.5305609348426608, 0.1768536449475536, 0.7378396458115357, 0.8143669309461782, 0.509541734954532, 0.254770867477266, 0.254770867477266, 0.7918499174199243, 0.8475297575105143, 0.9377389206793957, 0.8521428475093819, 0.17042856950187635, 0.5953740833584105, 0.5953740833584105, 0.6504728890968412, 0.21682429636561373, 0.4756033979415506, 0.4756033979415506, 0.5324603103800564, 0.2662301551900282, 0.2662301551900282, 0.5347286745050721, 0.5347286745050721, 0.2791837572574074, 0.1395918786287037, 0.1395918786287037, 0.1395918786287037, 0.1395918786287037, 0.1395918786287037, 0.7927437912407909, 0.7924078852635936, 0.05660056323311383, 0.05660056323311383, 0.05660056323311383, 0.37338367848788595, 0.37338367848788595, 0.37338367848788595, 0.8145723770721843, 0.7524312734062713, 0.5211650915370988, 0.2605825457685494, 0.2605825457685494, 0.7378982482424417, 0.737691523233194, 0.5715480304394035, 0.42866102282955265, 0.34053922563619615, 0.25540441922714713, 0.25540441922714713, 0.08513480640904904, 0.08513480640904904, 0.8146194549615263, 0.8675552330161309, 0.921403521054022, 0.45064075167728673, 0.45064075167728673, 0.8475405489246229, 0.4684346617238918, 0.2980947847333857, 0.042584969247626524, 0.042584969247626524, 0.042584969247626524, 0.042584969247626524, 0.2490820903024184, 0.3202484018173951, 0.07116631151497668, 0.14233262302995336, 0.03558315575748834, 0.14233262302995336, 0.03558315575748834, 0.03558315575748834, 0.7377831228439076, 0.6478863830821622, 0.3239431915410811, 0.3389211882358729, 0.3389211882358729, 0.2259474588239153, 0.11297372941195764, 0.7376877226074603, 0.4977950611385966, 0.07111358016265666, 0.07111358016265666, 0.07111358016265666, 0.07111358016265666, 0.14222716032531332, 0.07111358016265666, 0.07111358016265666, 0.7403732127893613, 0.47591314586226974, 0.47591314586226974, 0.50899300451289, 0.33932866967526, 0.16966433483763, 0.8575497892423385, 0.7403859090764676, 0.737966419615375, 0.8041473428160628, 0.2010368357040157, 0.7523037266234376, 0.49250424402993115, 0.49250424402993115, 0.8447410428982438, 0.7663805640311404, 0.1703067920069201, 0.6751250594596463, 0.13502501189192925, 0.13502501189192925, 0.13502501189192925, 0.6577946699387242, 0.33460184021935363, 0.33460184021935363, 0.33460184021935363, 0.5542379531158503, 0.9102149242917119, 0.8575982653569785, 0.7523035264192516, 0.44607629318084396, 0.148692097726948, 0.37173024431737, 0.074346048863474, 0.31565213167002376, 0.15782606583501188, 0.31565213167002376, 0.15782606583501188, 0.15782606583501188, 0.48231991550983, 0.38585593240786403, 0.09646398310196601, 0.7404282037699823, 0.28845049573460235, 0.28845049573460235, 0.28845049573460235, 0.7403436192339309, 0.5176698568950675, 0.5176698568950675, 0.7928261098450831, 0.7523035570832967, 0.7524037242533924, 0.48807618835384337, 0.48807618835384337, 0.7524418600320509, 0.41071878654035376, 0.30803908990526535, 0.15401954495263268, 0.05133984831754422, 0.05133984831754422, 0.7523038520984238, 0.3715041468420124, 0.3715041468420124, 0.3715041468420124, 0.8888029597797776, 0.1111003699724722, 0.8416959743282851, 0.7523036367339996, 0.7376442161310004, 0.7524610318085652, 0.8427474213152025, 0.8475408332673681, 0.84754087245665, 0.920720545225258, 0.7379104139154277, 0.8919882634371658, 0.8576151273154504, 0.554277811809562, 0.3650690829087841, 0.3650690829087841, 0.8580095319629627, 0.6577946302628028, 0.7403641357550068, 0.8912072526894554, 0.4623407632633406, 0.4623407632633406, 0.7403768357618623, 0.8146609722732608, 0.26537490238953065, 0.5307498047790613, 0.13268745119476533, 0.6022171371683629, 0.15055428429209072, 0.15055428429209072, 0.15055428429209072, 0.8145334190546533, 0.1866244246829652, 0.3732488493659304, 0.3732488493659304, 0.6577948569937714, 0.8146121898876428, 0.8426948331781838, 0.8905004148621428, 0.8459110665654646, 0.43738917291299007, 0.43738917291299007, 0.4374053675192302, 0.4374053675192302, 0.8576661011748504, 0.8144641789570333, 0.7404005785428387, 0.8143952296009622, 0.8475297595156254, 0.7524329081034412, 0.8475415973277368, 0.8146860645229741, 0.6577948286424576, 0.7524269026826657, 0.8427075485184259, 0.8674520820922383, 0.8907252476213742, 0.8144831236255654, 0.3653340473257433, 0.3653340473257433, 0.7377067385204233, 0.8426910200972845, 0.34797799525460354, 0.34797799525460354, 0.08699449881365089, 0.08699449881365089, 0.6577948636815072, 0.18022745795026693, 0.5406823738508009, 0.18022745795026693, 0.7404215593553879, 0.8438023148313011, 0.4172731732728686, 0.4172731732728686, 0.2086365866364343, 0.8145541708140384, 0.8850323249091642, 0.12643318927273775, 0.5383302369377378, 0.5383302369377378, 0.47730665273522305, 0.47730665273522305, 0.17771442694095282, 0.35542885388190565, 0.35542885388190565, 0.7376720979186288, 0.7235214151850349, 0.857601104312229, 0.8906390745160777, 0.910724078299754, 0.737751986254798, 0.23195472090018324, 0.4639094418003665, 0.23195472090018324, 0.4511121214572086, 0.4511121214572086, 0.8677322617813664, 0.7403828868018593, 0.8902833938736149, 0.8426959089974322, 0.8446913037005285, 0.8144970330058822, 0.8575593318932544, 0.8370722174898619, 0.8145633629177663, 0.8475271286732139, 0.44322299523432585, 0.2751039280764781, 0.01528355155980434, 0.09170130935882603, 0.0764177577990217, 0.06113420623921736, 0.03056710311960868, 0.01528355155980434, 0.7403867613778895, 0.7377073623773651, 0.8426802980582825, 0.7377068147343444, 0.7524100410256979], \"Term\": [\"accident\", \"account\", \"account\", \"account\", \"account\", \"account\", \"accounting\", \"accounting\", \"activity\", \"activity\", \"activity\", \"addback\", \"agent\", \"ambition\", \"amortization\", \"amount\", \"amount\", \"amount\", \"analysis\", \"analysis\", \"andcapacity\", \"andcredit\", \"andhealth\", \"andhealth\", \"andhealth\", \"andnatcat\", \"andnobody\", \"anotherlarge\", \"answer\", \"apology\", \"appetite\", \"asset\", \"asset\", \"asset\", \"asset\", \"assetallocation\", \"assoon\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"at\", \"basis\", \"basis\", \"benefit\", \"benefit\", \"billion\", \"bit\", \"bit\", \"bit\", \"bit\", \"block\", \"bond\", \"bond\", \"book\", \"book\", \"book\", \"book\", \"booking\", \"budget\", \"budget\", \"budget\", \"budgeting\", \"buffer\", \"bulk\", \"bulk\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"calculation\", \"calculation\", \"calculation\", \"calculation\", \"calculation\", \"capacity\", \"capacity\", \"car\", \"case\", \"case\", \"cash\", \"cash\", \"cash\", \"catastrophe\", \"catastrophe\", \"catbudget\", \"cedent\", \"cetera\", \"cetera\", \"change\", \"change\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"clarification\", \"clarity\", \"cleanup\", \"cleanup\", \"color\", \"color\", \"comment\", \"construction\", \"contract\", \"contribution\", \"contribution\", \"contribution\", \"contribution\", \"contributor\", \"contributor\", \"core\", \"country\", \"country\", \"country\", \"couple\", \"couple\", \"couple\", \"couple\", \"course\", \"course\", \"course\", \"course\", \"course\", \"cover\", \"cover\", \"cover\", \"cover\", \"coverage\", \"coverage\", \"coverage\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covidclaim\", \"credit\", \"credit\", \"currency\", \"cycle\", \"cycle\", \"cycle\", \"date\", \"death\", \"decline\", \"declined\", \"decrease\", \"decrease\", \"decrease\", \"degree\", \"deposit\", \"derivative\", \"derivative\", \"development\", \"development\", \"development\", \"deviation\", \"deviation\", \"difference\", \"difference\", \"difference\", \"difference\", \"digit\", \"digit\", \"digit\", \"digit\", \"dip\", \"distribution\", \"dividend\", \"downassumption\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver\", \"ebit\", \"ebit\", \"ebit\", \"ebitnumber\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"end\", \"end\", \"end\", \"end\", \"equity\", \"equity\", \"equity\", \"et\", \"et\", \"eur\", \"eur\", \"eur\", \"eur\", \"eur\", \"everyelement\", \"ex\", \"example\", \"excess\", \"excess\", \"exercise\", \"exercise\", \"expectation\", \"expectation\", \"expectation\", \"fact\", \"fact\", \"fact\", \"farstronger\", \"figure\", \"figure\", \"figure\", \"flood\", \"flood\", \"flood\", \"flow\", \"flow\", \"flow\", \"focus\", \"follow\", \"frominflation\", \"fronting\", \"fronting\", \"fund\", \"fund\", \"fund\", \"funding\", \"future\", \"gain\", \"gap\", \"gapbetween\", \"goingforward\", \"grossand\", \"growth\", \"growth\", \"growth\", \"growth\", \"growth\", \"growthor\", \"growththat\", \"guidance\", \"guidance\", \"guidance\", \"guidance\", \"guidance\", \"half\", \"half\", \"hand\", \"hand\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"healthand\", \"higherthan\", \"hospital\", \"host\", \"howhigh\", \"hurdle\", \"idea\", \"impact\", \"impact\", \"impact\", \"impact\", \"impact\", \"impairment\", \"improvement\", \"income\", \"income\", \"income\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"inflation\", \"inflation\", \"inflation\", \"information\", \"information\", \"information\", \"information\", \"inq\", \"insolvency\", \"investment\", \"investment\", \"investment\", \"investment\", \"investment\", \"investment\", \"isbeing\", \"isdeposit\", \"issuance\", \"kick\", \"ladie\", \"lady\", \"lag\", \"lag\", \"lag\", \"level\", \"level\", \"level\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"line\", \"line\", \"line\", \"line\", \"linker\", \"linker\", \"longevity\", \"longevity\", \"longevity\", \"longevity\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"lot\", \"lot\", \"lot\", \"market\", \"market\", \"market\", \"message\", \"mind\", \"mind\", \"mix\", \"mix\", \"model\", \"model\", \"model\", \"modeling\", \"month\", \"month\", \"month\", \"morbidity\", \"morning\", \"morning\", \"morning\", \"morning\", \"morning\", \"morning\", \"morning\", \"mortality\", \"mortality\", \"mortality\", \"mortality\", \"mortality\", \"movement\", \"my\", \"nature\", \"net\", \"net\", \"net\", \"net\", \"netincome\", \"newbusiness\", \"newbusiness\", \"normalmortality\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"ofcovid\", \"ofinsolvencie\", \"ofthat\", \"on\", \"one\", \"one\", \"one\", \"one\", \"opposite\", \"other\", \"ourguidance\", \"ourown\", \"ourpremium\", \"ourtransaction\", \"outcome\", \"outlook\", \"outlook\", \"outlook\", \"outthis\", \"package\", \"part\", \"part\", \"part\", \"payout\", \"peak\", \"pension\", \"people\", \"people\", \"percentage\", \"percentage\", \"period\", \"period\", \"perspective\", \"perspective\", \"picture\", \"picture\", \"picture\", \"planning\", \"planning\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"population\", \"portfolio\", \"portfolio\", \"portfolio\", \"portfolio\", \"position\", \"position\", \"position\", \"positiverunoff\", \"potential\", \"premium\", \"premium\", \"premium\", \"presentation\", \"pricingpoint\", \"profit\", \"profit\", \"profitability\", \"profitability\", \"profitability\", \"profitability\", \"profitability\", \"protection\", \"provision\", \"proxy\", \"quality\", \"quality\", \"quantification\", \"quarter\", \"quarter\", \"quarter\", \"quarter\", \"quarter\", \"quarter\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"quitedifficult\", \"range\", \"range\", \"rate\", \"rate\", \"rate\", \"rate\", \"ratesyet\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"ratioalready\", \"reallocation\", \"reallocation\", \"reason\", \"reason\", \"reason\", \"reasonwhy\", \"rebound\", \"recalculation\", \"recovery\", \"recovery\", \"recuperation\", \"reflection\", \"reflection\", \"regard\", \"reinsurance\", \"reinsurance\", \"release\", \"release\", \"release\", \"release\", \"remainder\", \"remark\", \"remark\", \"remark\", \"reporting\", \"reserve\", \"reserving\", \"rest\", \"result\", \"result\", \"result\", \"result\", \"retro\", \"retro\", \"retro\", \"retro\", \"retro\", \"return\", \"return\", \"return\", \"right\", \"risk\", \"risk\", \"risk\", \"roughlyeur\", \"round\", \"round\", \"runoff\", \"saidthat\", \"secondone\", \"session\", \"session\", \"sgoing\", \"side\", \"side\", \"side\", \"side\", \"side\", \"sir\", \"situation\", \"situation\", \"situation\", \"slide\", \"slide\", \"smallerportion\", \"someexpectation\", \"someupdate\", \"sort\", \"speaker\", \"speculating\", \"spillover\", \"split\", \"statement\", \"statistic\", \"status\", \"stimulus\", \"storm\", \"storm\", \"straight\", \"structure\", \"support\", \"supporting\", \"surety\", \"surety\", \"surprise\", \"tail\", \"target\", \"target\", \"target\", \"term\", \"term\", \"term\", \"term\", \"termlevel\", \"thank\", \"thank\", \"thank\", \"thatchange\", \"thatfreeze\", \"thatha\", \"thatincrease\", \"thatis\", \"thatwe\", \"thatwe\", \"the\", \"the\", \"thebasis\", \"thebulk\", \"thecontribution\", \"thedifference\", \"thegerman\", \"theimplication\", \"thelongevity\", \"thenet\", \"theprecise\", \"there\", \"thesecond\", \"thesetreatie\", \"thesolvency\", \"thewinter\", \"thing\", \"thing\", \"thinking\", \"thirdquarter\", \"time\", \"time\", \"time\", \"time\", \"tochange\", \"today\", \"today\", \"today\", \"toeur\", \"tofour\", \"top\", \"top\", \"top\", \"trade\", \"treaty\", \"treaty\", \"trigger\", \"trigger\", \"uncertainty\", \"uncertainty\", \"underwriting\", \"underwriting\", \"underwriting\", \"unknown\", \"up\", \"usualexercise\", \"usualplanning\", \"value\", \"variant\", \"view\", \"view\", \"view\", \"vinit\", \"vinit\", \"volatility\", \"walk\", \"wasanother\", \"weeksand\", \"wehave\", \"wenow\", \"wespeak\", \"wholeaccount\", \"winter\", \"writing\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yearof\", \"yourline\", \"yourquestion\", \"yoursolvency\", \"youthink\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [7, 8, 4, 5, 6, 1, 9, 10, 3, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el71391404710320823209844590608\", ldavis_el71391404710320823209844590608_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el71391404710320823209844590608\", ldavis_el71391404710320823209844590608_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el71391404710320823209844590608\", ldavis_el71391404710320823209844590608_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "6      0.154601  0.063548       1        1  42.726918\n",
       "7      0.086837  0.174964       2        1  20.342338\n",
       "3     -0.122572 -0.152784       3        1   6.856707\n",
       "4     -0.006964  0.117927       4        1   6.848935\n",
       "5      0.097760 -0.164498       5        1   6.431672\n",
       "0     -0.159410  0.113385       6        1   3.991322\n",
       "8     -0.037391 -0.112114       7        1   3.609971\n",
       "9     -0.155942 -0.001351       8        1   3.374121\n",
       "2      0.107033 -0.050030       9        1   3.157381\n",
       "1      0.036049  0.010954      10        1   2.660636, topic_info=           Term       Freq      Total Category  logprob  loglift\n",
       "231        year  65.000000  65.000000  Default  30.0000  30.0000\n",
       "87       growth  46.000000  46.000000  Default  29.0000  29.0000\n",
       "266    question  28.000000  28.000000  Default  28.0000  28.0000\n",
       "111        line  18.000000  18.000000  Default  27.0000  27.0000\n",
       "28     business  29.000000  29.000000  Default  26.0000  26.0000\n",
       "..          ...        ...        ...      ...      ...      ...\n",
       "105  investment   0.532278  15.937445  Topic10  -4.5724   0.2273\n",
       "59       effect   0.530055  18.980915  Topic10  -4.5765   0.0484\n",
       "99     increase   0.525531  15.576697  Topic10  -4.5851   0.2375\n",
       "91       health   0.525311  18.584797  Topic10  -4.5855   0.0605\n",
       "266    question   0.518450  28.103185  Topic10  -4.5987  -0.3662\n",
       "\n",
       "[537 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "536       7  0.842709      accident\n",
       "12        1  0.281272       account\n",
       "12        2  0.421908       account\n",
       "12        3  0.140636       account\n",
       "12        4  0.140636       account\n",
       "...     ...       ...           ...\n",
       "467       4  0.740387        yearof\n",
       "563       3  0.737707      yourline\n",
       "543       7  0.842680  yourquestion\n",
       "469       3  0.737707  yoursolvency\n",
       "481       5  0.752410      youthink\n",
       "\n",
       "[679 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[7, 8, 4, 5, 6, 1, 9, 10, 3, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=30)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
