{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftotext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(contents):\n",
    "    ### Cleaning all the unwanted rows in the transcript\n",
    "    df = pd.DataFrame(contents)\n",
    "\n",
    "    # remove the unnessary string\n",
    "    df[0] = df[0].str.replace('\\n','')\n",
    "    df[0] = df[0].str.replace('Bloomberg Transcript','')\n",
    "    df[0] = df[0].str.replace('\\x0c\\n','')\n",
    "    df[0] = df[0].str.replace('FINAL','')\n",
    "    df[0] = df[0].str.replace('A - ','')\n",
    "    df[0] = df[0].str.replace('Q - ','')\n",
    "\n",
    "    # using re to remove the unnessary string\n",
    "    def drop_unnessary(x):\n",
    "        page = re.findall(r'Page \\d+ of \\d+', x) # 'page ... of ... '\n",
    "        BIO = re.findall(r'{BIO', x) # '{BIO 18731996 <GO>}'\n",
    "        Company_Name = re.findall(r'Company N ame:', x) # 'Company N ame: H annover Rueck SE'\n",
    "        Company_Ticker = re.findall(r'Company Ticker:', x) # 'Company Ticker: H N R1 GR Equity'\n",
    "        Date = re.findall(r'Date:', x) # Date: 2015-03-10\n",
    "        if page == [] and BIO == [] and Company_Name == [] and Company_Ticker == [] and Date == []:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    true_false = df[0].apply(lambda x: drop_unnessary(x))\n",
    "    df = df[true_false]\n",
    "\n",
    "    # drop the final page declaration\n",
    "    df = df[df[0] != 'This transcript may not be 100 percent accurate and may contain misspellings and other']\n",
    "    df = df[df[0] != 'inaccuracies. This transcript is provided \"as is\", without express or implied warranties of']\n",
    "    df = df[df[0] != 'any kind. Bloomberg retains all rights to this transcript and provides it solely for your']\n",
    "    df = df[df[0] != 'personal, non-commercial use. Bloomberg, its suppliers and third-party agents shall']\n",
    "    df = df[df[0] != 'have no liability for errors in this transcript or for lost profits, losses, or direct, indirect,']\n",
    "    df = df[df[0] != 'incidental, consequential, special or punitive damages in connection with the']\n",
    "    df = df[df[0] != 'furnishing, performance or use of such transcript. Neither the information nor any']\n",
    "    df = df[df[0] != 'opinion expressed in this transcript constitutes a solicitation of the purchase or sale of']\n",
    "    df = df[df[0] != 'securities or commodities. Any opinion expressed in the transcript does not necessarily']\n",
    "    # df = df[df[0] != 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights']  \n",
    "    df = df[df[0] != 'reserved. Any reproduction, redistribution or retransmission is expressly prohibited.']\n",
    "    # ¬© could not be identified, would apply re\n",
    "    def drop_Bloomberg_mark(x):\n",
    "        Bloomberg_mark = re.findall(r'reflect the views of Bloomberg LP', x) # 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights'\n",
    "        if Bloomberg_mark == []:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    true_false = df[0].apply(lambda x: drop_Bloomberg_mark(x))\n",
    "    df = df[true_false]\n",
    "\n",
    "    # drop the empthy row\n",
    "    df = df[df[0] != '']\n",
    "    df = df[df[0] != '\f']\n",
    "\n",
    "    return df\n",
    "\n",
    "def participants_list(df):\n",
    "    # reset the index to make sure the index is continuous for better processing\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #  'Company Participants' index\n",
    "    # df.loc[df[0] == 'Company Participants']\n",
    "    Participant_start_index = df.index[df.iloc[:,0] == 'Company Participants'].tolist()\n",
    "    #  'Other Participants' index\n",
    "    # df.loc[df[0] == 'Other Participants']\n",
    "    Participant_middle_index = df.index[df.iloc[:,0] == 'Other Participants'].tolist()\n",
    "    #  'MANAGEMENT DISCUSSION SECTION' index, is the beginning of the management discussion, would stop before this row\n",
    "    # df.loc[df[0] == 'MANAGEMENT DISCUSSION SECTION']\n",
    "    Participant_end_index = df.index[df.iloc[:,0] == 'MANAGEMENT DISCUSSION SECTION' ].tolist()\n",
    "    # try to find the 'MANAGEMENT DISCUSSION SECTION' or 'Presentation' index\n",
    "    if Participant_end_index == []:\n",
    "        Participant_end_index = df.index[df.iloc[:,0] == 'Presentation'].tolist()\n",
    "\n",
    "    print(Participant_start_index, Participant_middle_index, Participant_end_index)\n",
    "\n",
    "    # make the list of company_paticipants and other_participants\n",
    "    company_paticipants = df.loc[Participant_start_index[0]+1:Participant_middle_index[0]-1]\n",
    "    company_paticipants.drop(company_paticipants.index[company_paticipants.iloc[:,0] == ''].tolist(), inplace=True)\n",
    "    company_paticipants = company_paticipants.values.tolist()\n",
    "\n",
    "    other_paticipants = df.loc[Participant_middle_index[0]+1:Participant_end_index[0]-1]\n",
    "    other_paticipants.drop(other_paticipants.index[other_paticipants.iloc[:,0] == ''].tolist(), inplace=True)\n",
    "    other_paticipants = other_paticipants.values.tolist()\n",
    "\n",
    "    # print(\"==========================\")\n",
    "    # print(\"the company paticipants is: \", company_paticipants)\n",
    "    # print(\"==========================\")\n",
    "    # print(\"the other paticipants is: \", other_paticipants)\n",
    "\n",
    "    #%%\n",
    "    # after extract the paticipants, we can drop those information to make the transcript more clear\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(range(df.index[df.iloc[:,0] == 'Company Participants'].tolist()[0],df.index[df.iloc[:,0].isin(['MANAGEMENT DISCUSSION SECTION','Presentation'])].tolist()[0]+1))\n",
    "\n",
    "    # drop the first row of the df\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.iloc[1: , :]\n",
    "\n",
    "\n",
    "    # reset the index again to make sure the index is continuous for better processing\n",
    "    df = df.reset_index(drop=True)\n",
    "    # # save to csv\n",
    "    # df.to_csv('/Users/timliu/Desktop/output/df.csv')\n",
    "    return df, company_paticipants, other_paticipants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [7] [14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [10] [24]\n",
      "[1] [4] [12]\n",
      "[1] [4] [17]\n",
      "[1] [4] [17]\n",
      "[1] [5] [21]\n",
      "[1] [6] [13]\n",
      "[1] [5] [12]\n",
      "[1] [4] [17]\n",
      "[1] [4] [13]\n",
      "[1] [6] [13]\n",
      "[1] [8] [21]\n",
      "[1] [4] [16]\n",
      "[1] [6] [20]\n",
      "[1] [5] [16]\n",
      "[1] [6] [18]\n",
      "[1] [6] [14]\n",
      "[1] [11] [27]\n",
      "[1] [5] [19]\n",
      "[1] [5] [15]\n",
      "[1] [6] [16]\n",
      "[1] [4] [17]\n",
      "[1] [6] [15]\n",
      "[1] [4] [12]\n",
      "[1] [5] [12]\n",
      "[1] [4] [12]\n",
      "[2] [5] [14]\n",
      "[1] [4] [13]\n",
      "[1] [4] [12]\n",
      "[1] [10] [28]\n",
      "[1] [6] [14]\n",
      "[2] [5] [13]\n",
      "[1] [4] [15]\n",
      "[1] [4] [17]\n",
      "[1] [5] [15]\n",
      "[1] [5] [10]\n",
      "[1] [9] [17]\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/timliu/Documents/GitHub/data_collecting/BBG_original_file/European (Re)Insurers/HNR1 GY\" #資料夾目錄\n",
    "save_path = \"/Users/timliu/Documents/GitHub/data_collecting/output/HNR1 GY_text\"\n",
    "df = pd.DataFrame()\n",
    "# create a dataframe with 2500 rows\n",
    "df_clean_na = pd.DataFrame(np.zeros((2500,1)), columns=['index'])\n",
    "\n",
    "all_participants = []\n",
    "\n",
    "files= os.listdir(path) #得到資料夾下的所有檔名稱\n",
    "for file in files:\n",
    "    if file.endswith(\".pdf\"):\n",
    "        # print(file)\n",
    "        # Load PDF\n",
    "        with open(path+\"/\"+file, \"rb\") as f:\n",
    "            pdf = pdftotext.PDF(f)\n",
    "        # Save all text to a txt file.\n",
    "        with open(save_path+\"/\"+file.replace(\".pdf\", \".txt\"), \"w\") as f:\n",
    "            f.write(\"\\n\\n\".join(pdf))\n",
    "        # open the text file\n",
    "        with open(save_path+\"/\"+file.replace(\".pdf\", \".txt\")) as f:\n",
    "            contents = f.readlines()\n",
    "            df_clean = cleaning_text(contents)\n",
    "            # extract all the participants\n",
    "            df_pure_text,company_paticipants,other_paticipants = participants_list(df_clean)\n",
    "            all_participants.append(company_paticipants)\n",
    "            all_participants.append(other_paticipants)\n",
    "            # using the file name to set as the dataframe's column name\n",
    "            # df[f\"{files.index(file)}\"] = df_clean\n",
    "            df[f\"{files[files.index(file)]}\"] = df_pure_text\n",
    "            df_clean_na[f\"{files[files.index(file)]}\"] = df[f\"{files[files.index(file)]}\"].dropna(inplace=False).reset_index(drop=True)\n",
    "\n",
    "# drop the first column of the df\n",
    "df_clean_na = df_clean_na.iloc[:,1:]\n",
    "\n",
    "# save the dataframe\n",
    "# df_clean_na.to_csv('/Users/timliu/Documents/GitHub/data_collecting/output/test/df_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if error of unhashable type: 'list' pop up, \n",
    "# run it twice but I don't know why, but no more then three times\n",
    "# get the value inside the all_participants \n",
    "all_participants = [item for sublist in all_participants for item in sublist]\n",
    "all_participants = [i[0] for i in all_participants]\n",
    "# print(all_participants)\n",
    "# %%\n",
    "# exclude the title of the participants, i.e.'Roland Vogel, CFO' to 'Roland Vogel\" by using re\n",
    "all_participants = [re.sub(r'\\,.*', '', participant) for participant in all_participants]\n",
    "# exclude the 'Property & Casualty Reinsurance'\n",
    "all_participants = [re.sub(r'Property & Casualty Reinsurance', '', participant) for participant in all_participants]\n",
    "# exclude the '[0682QB-E Ulrich Wallin]'\n",
    "all_participants = [re.sub(r'\\[0682QB-E Ulrich Wallin\\]', '', participant) for participant in all_participants]\n",
    "# drop duplicated participants\n",
    "# all_participants = [i[0] for i in all_participants]\n",
    "# drop the empty string\n",
    "all_participants = [participant for participant in all_participants if participant != '']\n",
    "# remove the sapce in the string\n",
    "all_participants = [participant.strip() for participant in all_participants]\n",
    "# add the 'Operator' to the list\n",
    "all_participants.append('Operator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clemens Jungsthofel',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Klaus Miller',\n",
       " 'Sven Althoff',\n",
       " 'Unidentified Speaker',\n",
       " 'Andrew Ritchie',\n",
       " 'Darius Satkauskas',\n",
       " 'Iain Pearce',\n",
       " 'Thomas Fossard',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hardcastle',\n",
       " 'Andreas Markert',\n",
       " 'Claude Jacques ChÃ¨vre',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Karl Steinle',\n",
       " 'Klaus Wilhelm Miller',\n",
       " 'Roland Helmut Vogel',\n",
       " 'Silke Sehm',\n",
       " 'Unidentified Speaker',\n",
       " 'Andreas SchÃ¤fer',\n",
       " 'Andrew James Ritchie',\n",
       " 'Dieter Hein',\n",
       " 'Edward Morris',\n",
       " 'Ivan Bokhmat',\n",
       " 'James Austin Shuck',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Hermann Haid',\n",
       " 'Roland PfÃ¤nder',\n",
       " 'Thomas Fossard',\n",
       " 'Unidentified Participant',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Anasuya Iyer',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Frank Kopfinger',\n",
       " 'In-Yong Hwang',\n",
       " 'Kamran Hossain',\n",
       " 'Thomas Fossard',\n",
       " 'William Hawkins',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Anasuya Iyer',\n",
       " 'Frank Kopfinger',\n",
       " 'In-Yong Hwang',\n",
       " 'Jochen Schmitt',\n",
       " 'Jonny Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Huttner',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Xinmei Wang',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew James Ritchie',\n",
       " 'Frank Kopfinger',\n",
       " 'Guilhem Horvath',\n",
       " 'James R Oram',\n",
       " 'Jochen Schmitt',\n",
       " 'Jonathan Peter Phillip Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Hermann Haid',\n",
       " 'Roland PfÃ¤nder',\n",
       " 'Thomas Fossard',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Karl Steinle',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Anasuya Iyer',\n",
       " 'Andreas Schäfer',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Edward Morris',\n",
       " 'Frank Kopfinger',\n",
       " 'In-Yong Hwang',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Olivia Brindle',\n",
       " 'Philipp Häßler',\n",
       " 'Roland Pfänder',\n",
       " 'Stefan Scharff',\n",
       " 'Thomas Fossard',\n",
       " 'Vinit Malhotra',\n",
       " 'Xinmei Wang',\n",
       " 'Clemens Jungsthofel',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Klaus Miller',\n",
       " 'Sven Althoff',\n",
       " 'Andrew Ritchie',\n",
       " 'Emanuele Musio',\n",
       " 'Kamran Hossain',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Thomas Fossard',\n",
       " 'Vinit Malhotra',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Sven Althoff',\n",
       " 'Unidentified Speaker',\n",
       " 'Andrew Richie',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Hermann Haid',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Roland Helmut Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew James Ritchie',\n",
       " 'Frank Kopfinger',\n",
       " 'Guilhem Horvath',\n",
       " 'Ivan Bokhmat',\n",
       " 'Jonathan Peter Phillip Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Roland PfÃ¤nder',\n",
       " 'Sami Taipalus',\n",
       " 'Thomas Fossard',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew Ritchie',\n",
       " 'Farooq Hanif',\n",
       " 'Frank Kopfinger',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Sami Taipalus',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Jean-Jacques Hencho',\n",
       " 'Klaus Miller',\n",
       " 'Roland Helmut Vogel',\n",
       " 'Sven Althoff',\n",
       " 'Andrew Ritchie',\n",
       " 'Kamran Hossain',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Andreas MÃ¤rkert',\n",
       " 'Claude Jacques ChÃ¨vre',\n",
       " 'JÃ¼rgen GrÃ¤ber',\n",
       " 'Karl Steinle',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew James Ritchie',\n",
       " 'Daniel Bischof',\n",
       " 'Edward Morris',\n",
       " 'Frank Kopfinger',\n",
       " 'Guilhem Horvath',\n",
       " 'Ivan Bokhmat',\n",
       " 'Kamran Hossain',\n",
       " 'Olivia Sylvia Brindle',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Thomas Fossard',\n",
       " 'Unidentified Participant',\n",
       " 'Vinit Malhotra',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andreas Schäfer',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Guilhem Horvath',\n",
       " 'Ivan Bokhmat',\n",
       " 'Jonny Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Nadine van der Meulen',\n",
       " 'Olivia Brindle',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Karl Steinle',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Unverified Participant',\n",
       " 'Andreas Schäfer',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Frank Kopfinger',\n",
       " 'Ivan Bokhmat',\n",
       " 'Jochen Schmitt',\n",
       " 'Jonathan Denham',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Roland Pfänder',\n",
       " 'Thomas Fossard',\n",
       " 'Tim Friebertshäuser',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Karl Steinle',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew J. Ritchie',\n",
       " 'In-Yong Hwang',\n",
       " 'Jonny Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Olivia Brindle',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Xin Mei Wang',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Unidentified Participant',\n",
       " 'Unverified Participant',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Ben Cohen',\n",
       " 'Frank Kopfinger',\n",
       " 'Janet Van den Berg',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Olivia S. Brindle',\n",
       " 'Peter Casanova',\n",
       " 'Rötger Franz',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Clemens Jungsthofel',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Klaus Miller',\n",
       " 'Sven Althoff',\n",
       " 'Andrew Ritchie',\n",
       " 'Ashik Musaddi',\n",
       " 'Kamran Hossain',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Will Hardcastle',\n",
       " 'Andreas Maerkert',\n",
       " 'Claude Chevre',\n",
       " 'Eberhard Mueller',\n",
       " 'Juergen Graeber',\n",
       " 'Karl Steinle',\n",
       " 'Klaus Miller',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andreas Schaefer',\n",
       " 'Andrew Broadfield',\n",
       " 'Andrew Ritchie',\n",
       " 'Frank Kopfinger',\n",
       " 'Guilhem Horvath',\n",
       " 'In-Yong Hwang',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Michael Huttner',\n",
       " 'Olivia Brindle',\n",
       " 'Roland Pfaender',\n",
       " 'Unidentified Participant',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Xinmei Wang',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Roland Helmut Vogel',\n",
       " 'Sven Althoff',\n",
       " 'Andreas Schafer',\n",
       " 'Emanuele Musio',\n",
       " 'Farooq Hanif',\n",
       " 'James Shuck',\n",
       " 'Jonny Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Roland Pfander',\n",
       " 'Sami Taipalus',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andreas Schäfer',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Frank Kopfinger',\n",
       " 'Guilhem Horvath',\n",
       " 'Kamran Hossain',\n",
       " 'Roland Pfänder',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Klaus Wilhelm Miller',\n",
       " 'Roland Helmut Vogel',\n",
       " 'Sven Althoff',\n",
       " 'Andreas SchÃ¤fer',\n",
       " 'Andrew James Ritchie',\n",
       " 'Emanuele Musio',\n",
       " 'Farooq Hanif',\n",
       " 'Frank Kopfinger',\n",
       " 'Kamran Hossain',\n",
       " 'Sami Taipalus',\n",
       " 'Thomas Fossard',\n",
       " 'Vinit Malhotra',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Andy D. Broadfield',\n",
       " 'Edward Morris',\n",
       " 'Frank Kopfinger',\n",
       " 'In-Yong Hwang',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Thilo Gorlt',\n",
       " 'Thomas Fossard',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Xinmei Wang',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Klaus Miller',\n",
       " 'Michael Pickel',\n",
       " 'Roland Vogel',\n",
       " 'Andrew Ritchie',\n",
       " 'Edward Morris',\n",
       " 'Kamran Hossain',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Sami Taipalus',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Edward Morris',\n",
       " 'Frank Kopfinger',\n",
       " 'In-Yong Hwang',\n",
       " 'Jonny Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Vinit Malhotra',\n",
       " 'Clemens Jungsthofel',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Klaus Miller',\n",
       " 'Andrew Ritchie',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Frank Kopfinger',\n",
       " 'Guilhem Horvath',\n",
       " 'Ivan Bokhmat',\n",
       " 'Jonny Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Vinit Malhotra',\n",
       " 'JÃ¼rgen GrÃ¤ber',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew James Ritchie',\n",
       " 'Frank Kopfinger',\n",
       " 'Guilhem Horvath',\n",
       " 'Ivan Bokhmat',\n",
       " 'Kamran Hossain',\n",
       " 'Thomas Seidl',\n",
       " 'Unidentified Participant',\n",
       " 'Vinit Malhotra',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Sven Althoff',\n",
       " 'Andrew Ritchie',\n",
       " 'James Shuck',\n",
       " 'Jonathan Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Sami Taipalus',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Frank Kopfinger',\n",
       " 'In-Yong Hwang',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Xinmei Wang',\n",
       " 'Andreas Maerkert',\n",
       " 'Juergen Graeber',\n",
       " 'Property and Casual Reinsurance',\n",
       " 'Karl Steinle',\n",
       " 'Klaus Miller',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Unidentified Speaker',\n",
       " 'Anasuya Iyer',\n",
       " 'Andreas Schaefer',\n",
       " 'Andrew Ritchie',\n",
       " 'Daniel Bischof',\n",
       " 'Jochen Schmitt',\n",
       " 'Jonny Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Olivia Brindle',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Rafael Villarreal',\n",
       " 'Thomas Fossard',\n",
       " 'Thomas Seidl',\n",
       " 'Unidentified Participant',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Xinmei Wang',\n",
       " 'Clemens Jungsthofel',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Klaus Miller',\n",
       " 'Sven Althoff',\n",
       " 'Andrew Ritchie',\n",
       " 'Emanuele Musio',\n",
       " 'Jochen Schmitt',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Sven Althoff',\n",
       " 'Ulrich Wallin',\n",
       " 'Andrew James Ritchie',\n",
       " 'Edward Morris',\n",
       " 'Frank Kopfinger',\n",
       " 'James Austin Shuck',\n",
       " 'Michael Hermann Haid',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Vinit Malhotra',\n",
       " 'Roland Helmut Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andreas SchÃ¤fer',\n",
       " 'Andrew James Ritchie',\n",
       " 'Frank Kopfinger',\n",
       " 'Jonathan Peter Phillip Urwin',\n",
       " 'Kamran Hossain',\n",
       " 'Sami Taipalus',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'William Hawkins',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Andreas Schäfer',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Andy D. Broadfield',\n",
       " 'Frank Kopfinger',\n",
       " 'In-Yong Hwang',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Michael I. Huttner',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Xin Mei Wang',\n",
       " 'Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Unidentified Speaker',\n",
       " 'Andrew Ritchie',\n",
       " 'Bill Hawkins',\n",
       " 'Edward Morris',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Paris Hadjiantonis',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Roland Vogel',\n",
       " 'Sven Althoff',\n",
       " 'Andreas Schafer',\n",
       " 'Andrew Ritchie',\n",
       " 'Vikram Gandhi',\n",
       " 'Vinit Malhotra',\n",
       " 'Claude Jacques Chevre',\n",
       " 'Clemens Jungsthofel',\n",
       " 'Jean-Jacques Henchoz',\n",
       " 'Karl Steinle',\n",
       " 'Klaus Wilhelm Miller',\n",
       " 'Sven Althoff',\n",
       " 'Unidentified Speaker',\n",
       " 'Andrew James Ritchie',\n",
       " 'Henry Heathfield',\n",
       " 'Iain Pearce',\n",
       " 'Thomas Fossard',\n",
       " 'Unidentified Participant',\n",
       " 'Vinit Malhotra',\n",
       " 'William Fraser Hardcastle',\n",
       " 'Operator']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "# identify the len before NaN of each column\n",
    "for column in df_clean_na.columns:\n",
    "    # end_index = len(df_clean_na[column])-df_clean_na.isnull().sum(axis = 0)[column]-1\n",
    "    # # 這邊要注意775是NaN 所以774還是有值的\n",
    "    # identify all the rows in df with all_participants in it\n",
    "    both_participants_row_index = df_clean_na[df_clean_na[column].isin(all_participants)].index.tolist()\n",
    "    # # append the end_index to the end of both_participants_row_index\n",
    "    # both_participants_row_index.append(end_index)\n",
    "    # apply the both_participants_row_index to the df_clean_na['participants']\n",
    "    new_df[column] = df_clean_na[column]\n",
    "    new_df[f\"participants_{column}\"] = df_clean_na[column].apply(lambda x: x if x in all_participants else np.nan)\n",
    "    # fill the NaN with the value of the previous row\n",
    "    new_df[f\"participants_{column}\"] = new_df[f\"participants_{column}\"].fillna(method='ffill')\n",
    "    # # exclude the row if pure_df[column]==pure_df[f\"participants_{column}\"]\n",
    "    # pure_df = pure_df[pure_df[column] != pure_df[f\"participants_{column}\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20211104_Hannover_Rueck_SE-_Earnings_Call_2021...</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well. Good morning to all of you. Welcome to H...</td>\n",
       "      <td>20191023_Hannover_Rueck_SE-_Shareholder_Mtg_Ca...</td>\n",
       "      <td>2019-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>20150506_Hannover_Rueck_SE-_Earnings_Call_2015...</td>\n",
       "      <td>2015-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good morning, ladies and gentlemen. Welcome to...</td>\n",
       "      <td>20160804_Hannover_Rueck_SE-_Earnings_Call_2016...</td>\n",
       "      <td>2016-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good morning, ladies and gentlemen. I'd like t...</td>\n",
       "      <td>20171108_Hannover_Rueck_SE-_Earnings_Call_2017...</td>\n",
       "      <td>2017-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Good afternoon everybody here in Frankfurt, an...</td>\n",
       "      <td>20160310_Hannover_Rueck_SE-_Earnings_Call_2016...</td>\n",
       "      <td>2016-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20201104_Hannover_Rueck_SE-_Earnings_Call_2020...</td>\n",
       "      <td>2020-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20210204_Hannover_Rueck_SE-_M-A_Call_2021-2-4_...</td>\n",
       "      <td>2021-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yes. Good morning, ladies and gentlemen. I'd l...</td>\n",
       "      <td>20180809_Hannover_Rueck_SE-_Earnings_Call_2018...</td>\n",
       "      <td>2018-08-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20190507_Hannover_Rueck_SE-_Earnings_Call_2019...</td>\n",
       "      <td>2019-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20200805_Hannover_Rueck_SE-_Earnings_Call_2020...</td>\n",
       "      <td>2020-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Well. Good morning to all of you. Welcome to H...</td>\n",
       "      <td>20171019_Hannover_Rueck_SE-_Shareholder_Mtg_Ca...</td>\n",
       "      <td>2017-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Good morning, ladies and gentlemen. Welcome to...</td>\n",
       "      <td>20170810_Hannover_Rueck_SE-_Earnings_Call_2017...</td>\n",
       "      <td>2017-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Good afternoon to everybody here in Frankfurt ...</td>\n",
       "      <td>20180313_Hannover_Rueck_SE-_Earnings_Call_2018...</td>\n",
       "      <td>2018-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Good afternoon to everybody here in London at ...</td>\n",
       "      <td>20170309_Hannover_Rueck_SE-_Earnings_Call_2017...</td>\n",
       "      <td>2017-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Well, good afternoon to everybody here in Lond...</td>\n",
       "      <td>20150310_Hannover_Rueck_SE-_Earnings_Call_2015...</td>\n",
       "      <td>2015-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Good morning, ladies and gentlemen, I welcome ...</td>\n",
       "      <td>20210805_Hannover_Rueck_SE-_Earnings_Call_2021...</td>\n",
       "      <td>2021-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Good morning, to all of you. Welcome to Hannov...</td>\n",
       "      <td>20151014_Hannover_Rueck_SE-_Guidance_Call_2015...</td>\n",
       "      <td>2015-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Good morning, ladies and gentlemen and welcome...</td>\n",
       "      <td>20191106_Hannover_Rueck_SE-_Earnings_Call_2019...</td>\n",
       "      <td>2019-11-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>20180507_Hannover_Rueck_SE-_Earnings_Call_2018...</td>\n",
       "      <td>2018-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thank you very much. Good morning, ladies and ...</td>\n",
       "      <td>20190808_Hannover_Rueck_SE-_Earnings_Call_2019...</td>\n",
       "      <td>2019-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Welcome to today's Hannover Re International C...</td>\n",
       "      <td>20151104_Hannover_Rueck_SE-_Earnings_Call_2015...</td>\n",
       "      <td>2015-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Good afternoon, ladies and gentlemen. I welcom...</td>\n",
       "      <td>20200311_Hannover_Rueck_SE-_Earnings_Call_2020...</td>\n",
       "      <td>2020-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Good morning, ladies and gentlemen and welcome...</td>\n",
       "      <td>20161110_Hannover_Rueck_SE-_Earnings_Call_2016...</td>\n",
       "      <td>2016-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Good afternoon, ladies and gentlemen. I welcom...</td>\n",
       "      <td>20210311_Hannover_Rueck_SE-_Earnings_Call_2021...</td>\n",
       "      <td>2021-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>20170510_Hannover_Rueck_SE-_Earnings_Call_2017...</td>\n",
       "      <td>2017-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Operator. Ladies and gentlemen, welcome to tod...</td>\n",
       "      <td>20180207_Hannover_Rueck_SE-_Guidance_Call_2018...</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Good morning ladies and gentlemen. I welcome y...</td>\n",
       "      <td>20200205_Hannover_Rueck_SE-_M-A_Call_2020-2-5_...</td>\n",
       "      <td>2020-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Good morning, ladies and gentlemen, and welcom...</td>\n",
       "      <td>20160510_Hannover_Rueck_SE-_Earnings_Call_2016...</td>\n",
       "      <td>2016-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Good morning, to all of you. Welcome to Hannov...</td>\n",
       "      <td>20161020_Hannover_Rueck_SE-_Guidance_Call_2016...</td>\n",
       "      <td>2016-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20210505_Hannover_Rueck_SE-_Earnings_Call_2021...</td>\n",
       "      <td>2021-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Operator. Good morning, ladies and gentlemen. ...</td>\n",
       "      <td>20190205_Hannover_Rueck_SE-_Guidance_Call_2019...</td>\n",
       "      <td>2019-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Good morning, ladies and gentlemen. I'd like t...</td>\n",
       "      <td>20181108_Hannover_Rueck_SE-_Earnings_Call_2018...</td>\n",
       "      <td>2018-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20150805_Hannover_Rueck_SE-_Earnings_Call_2015...</td>\n",
       "      <td>2015-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Well, good afternoon to everybody here in Lond...</td>\n",
       "      <td>20190307_Hannover_Rueck_SE-_Earnings_Call_2019...</td>\n",
       "      <td>2019-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>20200506_Hannover_Rueck_SE-_Earnings_Call_2020...</td>\n",
       "      <td>2020-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Hello. Good morning, to the Hannover Re's Inve...</td>\n",
       "      <td>20211014_Hannover_Rueck_SE-_Shareholder_Mtg_Ca...</td>\n",
       "      <td>2021-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         meeting_text  \\\n",
       "0   Good morning, ladies and gentlemen. I welcome ...   \n",
       "1   Well. Good morning to all of you. Welcome to H...   \n",
       "2   Good morning, ladies and gentlemen, and welcom...   \n",
       "3   Good morning, ladies and gentlemen. Welcome to...   \n",
       "4   Good morning, ladies and gentlemen. I'd like t...   \n",
       "5   Good afternoon everybody here in Frankfurt, an...   \n",
       "6   Good morning, ladies and gentlemen. I welcome ...   \n",
       "7   Good morning, ladies and gentlemen. I welcome ...   \n",
       "8   Yes. Good morning, ladies and gentlemen. I'd l...   \n",
       "9   Good morning, ladies and gentlemen. I welcome ...   \n",
       "10  Good morning, ladies and gentlemen. I welcome ...   \n",
       "11  Well. Good morning to all of you. Welcome to H...   \n",
       "12  Good morning, ladies and gentlemen. Welcome to...   \n",
       "13  Good afternoon to everybody here in Frankfurt ...   \n",
       "14  Good afternoon to everybody here in London at ...   \n",
       "15  Well, good afternoon to everybody here in Lond...   \n",
       "16  Good morning, ladies and gentlemen, I welcome ...   \n",
       "17  Good morning, to all of you. Welcome to Hannov...   \n",
       "18  Good morning, ladies and gentlemen and welcome...   \n",
       "19  Good morning, ladies and gentlemen, and welcom...   \n",
       "20  Thank you very much. Good morning, ladies and ...   \n",
       "21  Welcome to today's Hannover Re International C...   \n",
       "22  Good afternoon, ladies and gentlemen. I welcom...   \n",
       "23  Good morning, ladies and gentlemen and welcome...   \n",
       "24  Good afternoon, ladies and gentlemen. I welcom...   \n",
       "25  Good morning, ladies and gentlemen, and welcom...   \n",
       "26  Operator. Ladies and gentlemen, welcome to tod...   \n",
       "27  Good morning ladies and gentlemen. I welcome y...   \n",
       "28  Good morning, ladies and gentlemen, and welcom...   \n",
       "29  Good morning, to all of you. Welcome to Hannov...   \n",
       "30  Good morning, ladies and gentlemen. I welcome ...   \n",
       "31  Operator. Good morning, ladies and gentlemen. ...   \n",
       "32  Good morning, ladies and gentlemen. I'd like t...   \n",
       "33  Good morning, ladies and gentlemen. I welcome ...   \n",
       "34  Well, good afternoon to everybody here in Lond...   \n",
       "35  Good morning, ladies and gentlemen. I welcome ...   \n",
       "36  Hello. Good morning, to the Hannover Re's Inve...   \n",
       "\n",
       "                                            file_name       date  \n",
       "0   20211104_Hannover_Rueck_SE-_Earnings_Call_2021... 2021-11-04  \n",
       "1   20191023_Hannover_Rueck_SE-_Shareholder_Mtg_Ca... 2019-10-23  \n",
       "2   20150506_Hannover_Rueck_SE-_Earnings_Call_2015... 2015-05-06  \n",
       "3   20160804_Hannover_Rueck_SE-_Earnings_Call_2016... 2016-08-04  \n",
       "4   20171108_Hannover_Rueck_SE-_Earnings_Call_2017... 2017-11-08  \n",
       "5   20160310_Hannover_Rueck_SE-_Earnings_Call_2016... 2016-03-10  \n",
       "6   20201104_Hannover_Rueck_SE-_Earnings_Call_2020... 2020-11-04  \n",
       "7   20210204_Hannover_Rueck_SE-_M-A_Call_2021-2-4_... 2021-02-04  \n",
       "8   20180809_Hannover_Rueck_SE-_Earnings_Call_2018... 2018-08-09  \n",
       "9   20190507_Hannover_Rueck_SE-_Earnings_Call_2019... 2019-05-07  \n",
       "10  20200805_Hannover_Rueck_SE-_Earnings_Call_2020... 2020-08-05  \n",
       "11  20171019_Hannover_Rueck_SE-_Shareholder_Mtg_Ca... 2017-10-19  \n",
       "12  20170810_Hannover_Rueck_SE-_Earnings_Call_2017... 2017-08-10  \n",
       "13  20180313_Hannover_Rueck_SE-_Earnings_Call_2018... 2018-03-13  \n",
       "14  20170309_Hannover_Rueck_SE-_Earnings_Call_2017... 2017-03-09  \n",
       "15  20150310_Hannover_Rueck_SE-_Earnings_Call_2015... 2015-03-10  \n",
       "16  20210805_Hannover_Rueck_SE-_Earnings_Call_2021... 2021-08-05  \n",
       "17  20151014_Hannover_Rueck_SE-_Guidance_Call_2015... 2015-10-14  \n",
       "18  20191106_Hannover_Rueck_SE-_Earnings_Call_2019... 2019-11-06  \n",
       "19  20180507_Hannover_Rueck_SE-_Earnings_Call_2018... 2018-05-07  \n",
       "20  20190808_Hannover_Rueck_SE-_Earnings_Call_2019... 2019-08-08  \n",
       "21  20151104_Hannover_Rueck_SE-_Earnings_Call_2015... 2015-11-04  \n",
       "22  20200311_Hannover_Rueck_SE-_Earnings_Call_2020... 2020-03-11  \n",
       "23  20161110_Hannover_Rueck_SE-_Earnings_Call_2016... 2016-11-10  \n",
       "24  20210311_Hannover_Rueck_SE-_Earnings_Call_2021... 2021-03-11  \n",
       "25  20170510_Hannover_Rueck_SE-_Earnings_Call_2017... 2017-05-10  \n",
       "26  20180207_Hannover_Rueck_SE-_Guidance_Call_2018... 2018-02-07  \n",
       "27  20200205_Hannover_Rueck_SE-_M-A_Call_2020-2-5_... 2020-02-05  \n",
       "28  20160510_Hannover_Rueck_SE-_Earnings_Call_2016... 2016-05-10  \n",
       "29  20161020_Hannover_Rueck_SE-_Guidance_Call_2016... 2016-10-20  \n",
       "30  20210505_Hannover_Rueck_SE-_Earnings_Call_2021... 2021-05-05  \n",
       "31  20190205_Hannover_Rueck_SE-_Guidance_Call_2019... 2019-02-05  \n",
       "32  20181108_Hannover_Rueck_SE-_Earnings_Call_2018... 2018-11-08  \n",
       "33  20150805_Hannover_Rueck_SE-_Earnings_Call_2015... 2015-08-05  \n",
       "34  20190307_Hannover_Rueck_SE-_Earnings_Call_2019... 2019-03-07  \n",
       "35  20200506_Hannover_Rueck_SE-_Earnings_Call_2020... 2020-05-06  \n",
       "36  20211014_Hannover_Rueck_SE-_Shareholder_Mtg_Ca... 2021-10-14  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_df = pd.DataFrame()\n",
    "# identify the len before NaN of each column\n",
    "for column in df_clean_na.columns:\n",
    "    # exclude the row if pure_df[column]==pure_df[f\"participants_{column}\"]\n",
    "    pure_df = new_df[new_df[column] != new_df[f\"participants_{column}\"]]\n",
    "# drop the column if the column start with participants\n",
    "pure_df = pure_df.drop(pure_df.columns[pure_df.columns.str.startswith('participants_')], axis=1).T\n",
    "\n",
    "# append the text of each roll into one string by using s.str.cat(sep='. ')\n",
    "pure_df = pure_df.apply(lambda x: x.str.cat(sep='. '), axis=1)\n",
    "# change the pure_df to dataframe\n",
    "pure_df = pd.DataFrame(pure_df)\n",
    "# rename the column\n",
    "pure_df.columns = ['meeting_text']\n",
    "# extract the index as column from the text\n",
    "pure_df['file_name'] = pure_df.index\n",
    "# extract the date from the index column\n",
    "pure_df['date'] = pure_df['file_name'].apply(lambda x: x.split('_')[0])\n",
    "# change the date column to datetime\n",
    "pure_df['date'] = pd.to_datetime(pure_df['date'])\n",
    "# reset the index\n",
    "pure_df = pure_df.reset_index(drop=True)\n",
    "pure_df\n",
    "\n",
    "#save the dataframe\n",
    "# pure_df.to_csv('/Users/timliu/Documents/GitHub/data_collecting/output/test/pure_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes. With regard to the major loss budget, hap...</td>\n",
       "      <td>Sven Althoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay. Now, I'm happy to take the question on t...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hey, good morning. Thank you very much. So, a ...</td>\n",
       "      <td>Vinit Malhotra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>On the cash flow, nothing really significant. ...</td>\n",
       "      <td>Unidentified Speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hi, morning, everyone. Just a quick follow-up ...</td>\n",
       "      <td>William Hardcastle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yes. Good morning. Couple of questions. The fi...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hi. Thanks for taking my questions. The first ...</td>\n",
       "      <td>Iain Pearce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Good morning. Thank you for taking my question...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator\n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz\n",
       "2   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie\n",
       "3   Yes. With regard to the major loss budget, hap...          Sven Althoff\n",
       "4   Okay. Now, I'm happy to take the question on t...          Klaus Miller\n",
       "5   Hey, good morning. Thank you very much. So, a ...        Vinit Malhotra\n",
       "6   On the cash flow, nothing really significant. ...  Unidentified Speaker\n",
       "7   Hi, morning, everyone. Just a quick follow-up ...    William Hardcastle\n",
       "8   Yes. Good morning. Couple of questions. The fi...        Thomas Fossard\n",
       "9   Hi. Thanks for taking my questions. The first ...           Iain Pearce\n",
       "10  Good morning. Thank you for taking my question...     Darius Satkauskas"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take two of the first column as test df\n",
    "single_meeting_df = new_df.iloc[:,:2]\n",
    "# rename the second column to 'participants'\n",
    "single_meeting_df.columns = ['text', 'participants']\n",
    "# drop the NaN\n",
    "single_meeting_df = single_meeting_df.dropna(inplace=False)\n",
    "# if the text is empty, drop it\n",
    "single_meeting_df = single_meeting_df[single_meeting_df['text'] != '']\n",
    "# drop if 'text' == 'participants'\n",
    "single_meeting_df = single_meeting_df[single_meeting_df['text'] != single_meeting_df['participants']]\n",
    "\n",
    "list_participants = [] \n",
    "list_participants.append(single_meeting_df['participants'].unique().tolist())\n",
    "list_participants = list_participants[0]\n",
    "\n",
    "# create participants_split_df with column of 'participants' and 'text'\n",
    "participants_split_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(list_participants)):\n",
    "    processing_df = single_meeting_df.copy()\n",
    "    # 萃取出所有的participantsj中Operator說的話\n",
    "    processing_df['participants'] = processing_df['participants'].apply(lambda x: x if x == f\"{list_participants[i]}\" else np.nan)\n",
    "    # drop the NaN\n",
    "    processing_df = processing_df.dropna(inplace=False)\n",
    "    processing_df = processing_df.apply(''.join).to_frame().T\n",
    "    processing_df['participants'] =  f\"{list_participants[i]}\"\n",
    "    participants_split_df = participants_split_df.append(processing_df, ignore_index=True)\n",
    "\n",
    "\n",
    "participants_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Good morning, ladies and gentlemen, I welcome...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Well, good morning, everyone and welcome to o...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Hi, Good morning, everyone, Could I just dig ...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Yes, With regard to the major loss budget, ha...</td>\n",
       "      <td>Sven Althoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Okay, Now, I'm happy to take the question on ...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Hey, good morning, Thank you very much, So, a...</td>\n",
       "      <td>Vinit Malhotra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[On the cash flow, nothing really significant,...</td>\n",
       "      <td>Unidentified Speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Hi, morning, everyone, Just a quick follow-up...</td>\n",
       "      <td>William Hardcastle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Yes, Good morning, Couple of questions, The f...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Hi, Thanks for taking my questions, The first...</td>\n",
       "      <td>Iain Pearce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Good morning, Thank you for taking my questio...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants\n",
       "0   [Good morning, ladies and gentlemen, I welcome...              Operator\n",
       "1   [Well, good morning, everyone and welcome to o...  Jean-Jacques Henchoz\n",
       "2   [Hi, Good morning, everyone, Could I just dig ...        Andrew Ritchie\n",
       "3   [Yes, With regard to the major loss budget, ha...          Sven Althoff\n",
       "4   [Okay, Now, I'm happy to take the question on ...          Klaus Miller\n",
       "5   [Hey, good morning, Thank you very much, So, a...        Vinit Malhotra\n",
       "6   [On the cash flow, nothing really significant,...  Unidentified Speaker\n",
       "7   [Hi, morning, everyone, Just a quick follow-up...    William Hardcastle\n",
       "8   [Yes, Good morning, Couple of questions, The f...        Thomas Fossard\n",
       "9   [Hi, Thanks for taking my questions, The first...           Iain Pearce\n",
       "10  [Good morning, Thank you for taking my questio...     Darius Satkauskas"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a function to split the text by '.' in participants_split_df\n",
    "def split_text(text):\n",
    "    text = text.split(\". \")\n",
    "    return text\n",
    "# apply the function to the participants_split_df\n",
    "participants_split_df['text'] = participants_split_df['text'].apply(lambda x: split_text(x))\n",
    "participants_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_split_df = pd.DataFrame()\n",
    "for i in range(len(participants_split_df)):\n",
    "    sentence_list = participants_split_df['text'].iloc[i]\n",
    "    sentence_split_single_df = pd.DataFrame (sentence_list, columns = ['sentence'])\n",
    "    sentence_split_single_df['participants'] = participants_split_df['participants'].iloc[i]\n",
    "    sentence_split_single_df['paragraph'] = i\n",
    "    sentence_split_df = sentence_split_df.append(sentence_split_single_df, ignore_index=True)\n",
    "# drop if the 'sentence' is empty\n",
    "sentence_split_df = sentence_split_df.dropna(inplace=False)\n",
    "\n",
    "sentence_split_df\n",
    "\n",
    "# safe the dataframe with the path\n",
    "path = '/Users/timliu/Documents/GitHub/data_collecting/df_for_NLP/sentence_split_df.csv'\n",
    "sentence_split_df.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/timliu/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/timliu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "There are 5000 negative sentences.\n",
      "There are 5000 positive sentences.\n",
      "==========================================================\n",
      "[[593 235]\n",
      " [157 515]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.72      0.75       828\n",
      "           1       0.69      0.77      0.72       672\n",
      "\n",
      "    accuracy                           0.74      1500\n",
      "   macro avg       0.74      0.74      0.74      1500\n",
      "weighted avg       0.74      0.74      0.74      1500\n",
      "\n",
      "0.7386666666666667\n",
      "==========================================================\n",
      "Unnamed: 0      0\n",
      "sentence        0\n",
      "participants    0\n",
      "paragraph       0\n",
      "dtype: int64\n",
      "==========================================================\n",
      "Counter({'positive': 262, 'negative': 128})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>participants</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen</td>\n",
       "      <td>Operator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I welcome you to today's Hannover Re Internati...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For your information, this conference isbeing ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At this time, I would like to hand the call ov...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please go ahead, sir.(Question And Answer)Ladi...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>So, that's really the usualplanning cycle that...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>So thatincreases -- and then, of course, the h...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>So that's the main driver.I don't have the exa...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>And again,another contributor was, of course, ...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>That wasanother contributor.Thank you.</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence       participants  \\\n",
       "0                   Good morning, ladies and gentlemen           Operator   \n",
       "1    I welcome you to today's Hannover Re Internati...           Operator   \n",
       "2    For your information, this conference isbeing ...           Operator   \n",
       "3    At this time, I would like to hand the call ov...           Operator   \n",
       "4    Please go ahead, sir.(Question And Answer)Ladi...           Operator   \n",
       "..                                                 ...                ...   \n",
       "385  So, that's really the usualplanning cycle that...  Darius Satkauskas   \n",
       "386  So thatincreases -- and then, of course, the h...  Darius Satkauskas   \n",
       "387  So that's the main driver.I don't have the exa...  Darius Satkauskas   \n",
       "388  And again,another contributor was, of course, ...  Darius Satkauskas   \n",
       "389             That wasanother contributor.Thank you.  Darius Satkauskas   \n",
       "\n",
       "     sentiment_score  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                 -1  \n",
       "3                 -1  \n",
       "4                  1  \n",
       "..               ...  \n",
       "385                1  \n",
       "386                1  \n",
       "387               -1  \n",
       "388               -1  \n",
       "389                1  \n",
       "\n",
       "[390 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% # snetiment analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nltk \n",
    "nltk.download('twitter_samples')\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
    "\n",
    "# twitter_samples.fileids()\n",
    "# documents\n",
    "docs_negative = [(t, \"neg\") for t in twitter_samples.strings(\"negative_tweets.json\")]\n",
    "docs_positive = [(t, \"pos\") for t in twitter_samples.strings(\"positive_tweets.json\")]\n",
    "print(\"==========================================================\")\n",
    "print(f'There are {len(docs_negative)} negative sentences.')\n",
    "print(f'There are {len(docs_positive)} positive sentences.')\n",
    "\n",
    "# spliting dataset \n",
    "train_set = docs_negative[:3500] + docs_positive[:3500]\n",
    "test_set = docs_negative[3500:4250] + docs_positive[3500:4250]\n",
    "valid_set = docs_negative[4250:] + docs_positive[4250:]\n",
    "\n",
    "# clean text\n",
    "def process_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    #text = text.str\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\$\\w*', '', text)\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,reduce_len=True)\n",
    "    text_tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    text_clean = []\n",
    "    for word in text_tokens:\n",
    "        if (word not in stopwords_english and  \n",
    "                word not in string.punctuation): \n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            text_clean.append(stem_word)\n",
    "            \n",
    "    sentence = ' '.join(text_clean)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# categorical label\n",
    "def cat_label(label):\n",
    "    if label == 'neg':\n",
    "        value = -1\n",
    "    elif label == 'pos':\n",
    "        value = 1\n",
    "    return value \n",
    "\n",
    "# split for x and y \n",
    "def xy(dataset):\n",
    "    df = pd.DataFrame(dataset, columns = ['text', 'label'])\n",
    "    df['text_clean'] = df['text'].apply(lambda r: process_text(r))\n",
    "    #df['categorical_label'] = df.label.factorize()[0]\n",
    "    df['categorical_label'] = df['label'].apply(lambda r: cat_label(r))\n",
    "\n",
    "    x = df.text_clean\n",
    "    y = df.categorical_label\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# dataframe\n",
    "x_train, y_train = xy(train_set)\n",
    "x_test, y_test = xy(test_set)\n",
    "x_valid, y_valid = xy(valid_set)\n",
    "\n",
    "## using the naive bayes classifier\n",
    "model = Pipeline([\n",
    "    ('bow',CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"==========================================================\")\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "\n",
    "# Apply into earnings call sentence\n",
    "# import dataset\n",
    "path = '/Users/timliu/Documents/GitHub/data_collecting/df_for_NLP/sentence_split_df.csv'\n",
    "df_sentence = pd.read_csv(path)\n",
    "# df_sentence.head()\n",
    "\n",
    "# drop participant columns as we dont need it\n",
    "# df_sentence = df_sentence.drop(['participants'], axis=1)\n",
    "\n",
    "# check NaN values\n",
    "print(\"==========================================================\")\n",
    "print(df_sentence.isnull().sum())\n",
    "\n",
    "# delete NaN rows\n",
    "df_sentence = df_sentence.dropna()  \n",
    "\n",
    "# clean text for sentiment analysis\n",
    "df_sentence['text_clean'] = df_sentence['sentence'].apply(lambda r: process_text(r))\n",
    "# df_sentence.head(5)\n",
    "\n",
    "# making prediction\n",
    "prediction = model.predict(df_sentence.text_clean)\n",
    "prediction_label = np.array(['positive' if p==1 else 'negative' for p in prediction])\n",
    "df_sentence['prediction_label'] = prediction_label\n",
    "df_sentence['sentiment_score'] = prediction\n",
    "# df_sentence.head()\n",
    "\n",
    "print(\"==========================================================\")\n",
    "print(Counter(df_sentence['prediction_label']))\n",
    "\n",
    "# df_sentence left columns with only 'sentence','participants','sentiment_score'\n",
    "df_sentence = df_sentence[['sentence','participants','sentiment_score']]\n",
    "df_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>participants</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Good morning, ladies and gentlemen</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I welcome you to today's Hannover Re Internati...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>For your information, this conference isbeing ...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>At this time, I would like to hand the call ov...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Please go ahead, sir.(Question And Answer)Ladi...</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>So, that's really the usualplanning cycle that...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>So thatincreases -- and then, of course, the h...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>387</td>\n",
       "      <td>So that's the main driver.I don't have the exa...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>388</td>\n",
       "      <td>And again,another contributor was, of course, ...</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>389</td>\n",
       "      <td>That wasanother contributor.Thank you.</td>\n",
       "      <td>Darius Satkauskas</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           sentence  \\\n",
       "0             0                 Good morning, ladies and gentlemen   \n",
       "1             1  I welcome you to today's Hannover Re Internati...   \n",
       "2             2  For your information, this conference isbeing ...   \n",
       "3             3  At this time, I would like to hand the call ov...   \n",
       "4             4  Please go ahead, sir.(Question And Answer)Ladi...   \n",
       "..          ...                                                ...   \n",
       "385         385  So, that's really the usualplanning cycle that...   \n",
       "386         386  So thatincreases -- and then, of course, the h...   \n",
       "387         387  So that's the main driver.I don't have the exa...   \n",
       "388         388  And again,another contributor was, of course, ...   \n",
       "389         389             That wasanother contributor.Thank you.   \n",
       "\n",
       "          participants  paragraph  \n",
       "0             Operator          0  \n",
       "1             Operator          0  \n",
       "2             Operator          0  \n",
       "3             Operator          0  \n",
       "4             Operator          0  \n",
       "..                 ...        ...  \n",
       "385  Darius Satkauskas         10  \n",
       "386  Darius Satkauskas         10  \n",
       "387  Darius Satkauskas         10  \n",
       "388  Darius Satkauskas         10  \n",
       "389  Darius Satkauskas         10  \n",
       "\n",
       "[390 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/timliu/Documents/GitHub/data_collecting/df_for_NLP/sentence_split_df.csv'\n",
    "sentence_split_df = pd.read_csv(path)\n",
    "sentence_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_split_df['sentiment_score']=df_sentence['sentiment_score']\n",
    "sentence_split_df\n",
    "# safe to save the dataframe\n",
    "sentence_split_df.to_csv('/Users/timliu/Documents/GitHub/data_collecting/df_for_NLP/tim_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30434782608695654,\n",
       " 0.43884892086330934,\n",
       " 0.6,\n",
       " 0.037037037037037035,\n",
       " 0.22580645161290322,\n",
       " 0.2765957446808511,\n",
       " 0.16666666666666666,\n",
       " 0.23076923076923078,\n",
       " 0.5135135135135135,\n",
       " 0.75,\n",
       " 0.16666666666666666]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_df = pd.DataFrame()\n",
    "score_list  = []\n",
    "for i in sentence_split_df['paragraph'].unique():\n",
    "    # sum up the sentiment score for each sentence\n",
    "    process_df = sentence_split_df[sentence_split_df['paragraph']==i]\n",
    "    score_list.append(process_df['sentiment_score'].sum()/len(process_df))\n",
    "\n",
    "score_list\n",
    "\n",
    "\n",
    "# if sentence_split_df[sentence_split_df['paragraph']==1]:\n",
    "#     # sum up the sentiment score for each sentence\n",
    "#     test_df['sentiment_score'] = sentence_split_df.groupby('paragraph')['sentiment_score'].transform(sum)\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning, ladies and gentlemen. I welcome ...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, good morning, everyone and welcome to ou...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much, Clemens. On the next slid...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Question And Answer)Ladies and gentlemen, we ...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi. Good morning, everyone. Could I just dig i...</td>\n",
       "      <td>Andrew Ritchie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Yes. Two quick questions. The first one would ...</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>And on the NatCat, so as Jean-Jacques explaine...</td>\n",
       "      <td>Klaus Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>Thomas Fossard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>And there are no further questions at this poi...</td>\n",
       "      <td>Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Well, thank you very much for joining, and tha...</td>\n",
       "      <td>Jean-Jacques Henchoz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          participants\n",
       "0   Good morning, ladies and gentlemen. I welcome ...              Operator\n",
       "1   Well, good morning, everyone and welcome to ou...  Jean-Jacques Henchoz\n",
       "2   Thank you very much, Clemens. On the next slid...  Jean-Jacques Henchoz\n",
       "3   (Question And Answer)Ladies and gentlemen, we ...              Operator\n",
       "4   Hi. Good morning, everyone. Could I just dig i...        Andrew Ritchie\n",
       "..                                                ...                   ...\n",
       "60  Yes. Two quick questions. The first one would ...        Thomas Fossard\n",
       "61  And on the NatCat, so as Jean-Jacques explaine...          Klaus Miller\n",
       "62                              Thank you. Thank you.        Thomas Fossard\n",
       "63  And there are no further questions at this poi...              Operator\n",
       "64  Well, thank you very much for joining, and tha...  Jean-Jacques Henchoz\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragrapg_df = new_df.iloc[:,:2]\n",
    "# drop the NaN\n",
    "paragrapg_df = paragrapg_df.dropna(inplace=False)\n",
    "#rename the second column to 'participants', first column to 'text'\n",
    "paragrapg_df.columns = ['text', 'participants']\n",
    "# if the text is empty, drop it\n",
    "paragrapg_df = paragrapg_df[paragrapg_df['text'] != '']\n",
    "# reset the index\n",
    "paragrapg_df = paragrapg_df.reset_index(drop=True)\n",
    "# if 'text' == 'participants', get the index of the row\n",
    "paragrapg_index = paragrapg_df[paragrapg_df['text'] == paragrapg_df['participants']].index.tolist()\n",
    "\n",
    "# +1 for every value in paragrapg_index\n",
    "start_paragrapg_index = []\n",
    "for i in range(len(paragrapg_index)):\n",
    "    start_paragrapg_index.append(paragrapg_index[i]+1)\n",
    "# disregard the last value in the list\n",
    "start_paragrapg_index = start_paragrapg_index[:-1]\n",
    "print(len(start_paragrapg_index))\n",
    "# -1 for every value in paragrapg_index\n",
    "end_paragrapg_index = []\n",
    "for i in range(len(paragrapg_index)):\n",
    "    end_paragrapg_index.append(paragrapg_index[i])\n",
    "# disregard the first value in the list\n",
    "end_paragrapg_index = end_paragrapg_index[1:]\n",
    "print(len(end_paragrapg_index))\n",
    "\n",
    "# extracct the text of the paragrapg_df between end_paragrapg_index and start_paragrapg_index\n",
    "paragraph_split_df = pd.DataFrame()\n",
    "for i in range(len(start_paragrapg_index)):\n",
    "    paragraph = paragrapg_df.iloc[start_paragrapg_index[i]:end_paragrapg_index[i]]\n",
    "    # merge the paragraph to one cell \n",
    "    paragraph_text = paragraph.apply(''.join).to_frame().T\n",
    "    # appemd the paragraph_text['text'].iloc[:,0] to the paragraph_split_df\n",
    "    paragraph_split_df = paragraph_split_df.append(paragraph_text, ignore_index=True)\n",
    "\n",
    "# look up for paragrapg_df['participants'] from the start_paragrapg_index\n",
    "participants = paragrapg_df.iloc[start_paragrapg_index,1].to_frame()\n",
    "# reset the index\n",
    "participants = participants.reset_index(drop=True)\n",
    "\n",
    "paragraph_split_df['participants'] = participants\n",
    "paragraph_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
