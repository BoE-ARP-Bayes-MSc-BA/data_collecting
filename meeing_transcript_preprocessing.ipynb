{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer the pdf to text and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftotext\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your PDF\n",
    "with open(\"/Users/timliu/Documents/on the desktop/MSc BA/論文/ARP/European (Re)Insurers/HNR1 GY/20150310_Hannover_Rueck_SE-_Earnings_Call_2015-3-10_FS000000002198853065.pdf\", \"rb\") as f:\n",
    "    pdf = pdftotext.PDF(f)\n",
    "\n",
    "# Save all text to a txt file.\n",
    "with open('/Users/timliu/Desktop/output/test.txt', 'w') as f:\n",
    "    f.write(\"\\n\\n\".join(pdf))\n",
    "\n",
    "# open the text file\n",
    "with open('/Users/timliu/Desktop/output/test.txt') as f:\n",
    "    contents = f.readlines()\n",
    "\n",
    "# contents\n",
    "\n",
    "# ToDo:\n",
    "# write a function to processsing all the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting from the text, will do some preprocessing to the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Cleaning all the unwanted rows in the transcript\n",
    "# df = pd.DataFrame(contents)\n",
    "\n",
    "# # remove the unnessary string\n",
    "# df[0] = df[0].str.replace('\\n','')\n",
    "# df[0] = df[0].str.replace('Bloomberg Transcript','')\n",
    "# df[0] = df[0].str.replace('\\x0c\\n','')\n",
    "# df[0] = df[0].str.replace('FINAL','')\n",
    "# df[0] = df[0].str.replace('A - ','')\n",
    "# df[0] = df[0].str.replace('Q - ','')\n",
    "\n",
    "# # using re to remove the unnessary string\n",
    "# def drop_unnessary(x):\n",
    "#     page = re.findall(r'Page \\d+ of \\d+', x) # 'page ... of ... '\n",
    "#     BIO = re.findall(r'{BIO', x) # '{BIO 18731996 <GO>}'\n",
    "#     Company_Name = re.findall(r'Company N ame:', x) # 'Company N ame: H annover Rueck SE'\n",
    "#     Company_Ticker = re.findall(r'Company Ticker:', x) # 'Company Ticker: H N R1 GR Equity'\n",
    "#     Date = re.findall(r'Date:', x) # Date: 2015-03-10\n",
    "#     if page == [] and BIO == [] and Company_Name == [] and Company_Ticker == [] and Date == []:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# true_false = df[0].apply(lambda x: drop_unnessary(x))\n",
    "# df = df[true_false]\n",
    "\n",
    "# # drop the final page declaration\n",
    "# df = df[df[0] != 'This transcript may not be 100 percent accurate and may contain misspellings and other']\n",
    "# df = df[df[0] != 'inaccuracies. This transcript is provided \"as is\", without express or implied warranties of']\n",
    "# df = df[df[0] != 'any kind. Bloomberg retains all rights to this transcript and provides it solely for your']\n",
    "# df = df[df[0] != 'personal, non-commercial use. Bloomberg, its suppliers and third-party agents shall']\n",
    "# df = df[df[0] != 'have no liability for errors in this transcript or for lost profits, losses, or direct, indirect,']\n",
    "# df = df[df[0] != 'incidental, consequential, special or punitive damages in connection with the']\n",
    "# df = df[df[0] != 'furnishing, performance or use of such transcript. Neither the information nor any']\n",
    "# df = df[df[0] != 'opinion expressed in this transcript constitutes a solicitation of the purchase or sale of']\n",
    "# df = df[df[0] != 'securities or commodities. Any opinion expressed in the transcript does not necessarily']\n",
    "# # df = df[df[0] != 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights']  \n",
    "# df = df[df[0] != 'reserved. Any reproduction, redistribution or retransmission is expressly prohibited.']\n",
    "# # ¬© could not be identified, would apply re\n",
    "# def drop_Bloomberg_mark(x):\n",
    "#     Bloomberg_mark = re.findall(r'reflect the views of Bloomberg LP', x) # 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights'\n",
    "#     if Bloomberg_mark == []:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# true_false = df[0].apply(lambda x: drop_Bloomberg_mark(x))\n",
    "# df = df[true_false]\n",
    "\n",
    "\n",
    "# # drop the empthy row\n",
    "# df = df[df[0] != '']\n",
    "# df = df[df[0] != '\f']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(contents):\n",
    "    ### Cleaning all the unwanted rows in the transcript\n",
    "    df = pd.DataFrame(contents)\n",
    "\n",
    "    # remove the unnessary string\n",
    "    df[0] = df[0].str.replace('\\n','')\n",
    "    df[0] = df[0].str.replace('Bloomberg Transcript','')\n",
    "    df[0] = df[0].str.replace('\\x0c\\n','')\n",
    "    df[0] = df[0].str.replace('FINAL','')\n",
    "    df[0] = df[0].str.replace('A - ','')\n",
    "    df[0] = df[0].str.replace('Q - ','')\n",
    "\n",
    "    # using re to remove the unnessary string\n",
    "    def drop_unnessary(x):\n",
    "        page = re.findall(r'Page \\d+ of \\d+', x) # 'page ... of ... '\n",
    "        BIO = re.findall(r'{BIO', x) # '{BIO 18731996 <GO>}'\n",
    "        Company_Name = re.findall(r'Company N ame:', x) # 'Company N ame: H annover Rueck SE'\n",
    "        Company_Ticker = re.findall(r'Company Ticker:', x) # 'Company Ticker: H N R1 GR Equity'\n",
    "        Date = re.findall(r'Date:', x) # Date: 2015-03-10\n",
    "        if page == [] and BIO == [] and Company_Name == [] and Company_Ticker == [] and Date == []:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    true_false = df[0].apply(lambda x: drop_unnessary(x))\n",
    "    df = df[true_false]\n",
    "\n",
    "    # drop the final page declaration\n",
    "    df = df[df[0] != 'This transcript may not be 100 percent accurate and may contain misspellings and other']\n",
    "    df = df[df[0] != 'inaccuracies. This transcript is provided \"as is\", without express or implied warranties of']\n",
    "    df = df[df[0] != 'any kind. Bloomberg retains all rights to this transcript and provides it solely for your']\n",
    "    df = df[df[0] != 'personal, non-commercial use. Bloomberg, its suppliers and third-party agents shall']\n",
    "    df = df[df[0] != 'have no liability for errors in this transcript or for lost profits, losses, or direct, indirect,']\n",
    "    df = df[df[0] != 'incidental, consequential, special or punitive damages in connection with the']\n",
    "    df = df[df[0] != 'furnishing, performance or use of such transcript. Neither the information nor any']\n",
    "    df = df[df[0] != 'opinion expressed in this transcript constitutes a solicitation of the purchase or sale of']\n",
    "    df = df[df[0] != 'securities or commodities. Any opinion expressed in the transcript does not necessarily']\n",
    "    # df = df[df[0] != 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights']  \n",
    "    df = df[df[0] != 'reserved. Any reproduction, redistribution or retransmission is expressly prohibited.']\n",
    "    # ¬© could not be identified, would apply re\n",
    "    def drop_Bloomberg_mark(x):\n",
    "        Bloomberg_mark = re.findall(r'reflect the views of Bloomberg LP', x) # 'reflect the views of Bloomberg LP. ¬© COPYRIGHT 2022, BLOOMBERG LP. All rights'\n",
    "        if Bloomberg_mark == []:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    true_false = df[0].apply(lambda x: drop_Bloomberg_mark(x))\n",
    "    df = df[true_false]\n",
    "\n",
    "    # drop the empthy row\n",
    "    df = df[df[0] != '']\n",
    "    df = df[df[0] != '\f']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q4 2014 Earnings Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Company Participants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Roland Vogel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ulrich Wallin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unidentified Participant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>For all of those others here in the room, we w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>Hannover Re for a snack and a refreshment outs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>attending. Thank you for coming.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>Ulrich Wallin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>Thank you very much.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "4                                 Q4 2014 Earnings Call\n",
       "5                                  Company Participants\n",
       "8                                          Roland Vogel\n",
       "9                                         Ulrich Wallin\n",
       "10                             Unidentified Participant\n",
       "...                                                 ...\n",
       "1511  For all of those others here in the room, we w...\n",
       "1512  Hannover Re for a snack and a refreshment outs...\n",
       "1513                   attending. Thank you for coming.\n",
       "1515                                      Ulrich Wallin\n",
       "1521                               Thank you very much.\n",
       "\n",
       "[964 rows x 1 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleaning_text(contents)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a list of the participants in the meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participants_list(df):\n",
    "    # reset the index to make sure the index is continuous for better processing\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #  'Company Participants' index\n",
    "    df.loc[df[0] == 'Company Participants']\n",
    "    Participant_start_index = df.index[df[0] == 'Company Participants'].tolist()\n",
    "    #  'Other Participants' index\n",
    "    df.loc[df[0] == 'Other Participants']\n",
    "    Participant_middle_index = df.index[df[0] == 'Other Participants'].tolist()\n",
    "    #  'MANAGEMENT DISCUSSION SECTION' index, is the beginning of the management discussion, would stop before this row\n",
    "    df.loc[df[0] == 'MANAGEMENT DISCUSSION SECTION']\n",
    "    Participant_end_index = df.index[df[0] == 'MANAGEMENT DISCUSSION SECTION'].tolist()\n",
    "\n",
    "    print(Participant_start_index, Participant_middle_index, Participant_end_index)\n",
    "\n",
    "    # make the list of company_paticipants and other_participants\n",
    "    company_paticipants = df.loc[Participant_start_index[0]+1:Participant_middle_index[0]-1]\n",
    "    company_paticipants.drop(company_paticipants.index[company_paticipants[0] == ''].tolist(), inplace=True)\n",
    "\n",
    "    other_paticipants = df.loc[Participant_middle_index[0]+1:Participant_end_index[0]-1]\n",
    "    other_paticipants.drop(other_paticipants.index[other_paticipants[0] == ''].tolist(), inplace=True)\n",
    "\n",
    "    print(\"==========================\")\n",
    "    print(\"the company paticipants is: \", company_paticipants)\n",
    "    print(\"==========================\")\n",
    "    print(\"the other paticipants is: \", other_paticipants)\n",
    "\n",
    "    # after extract the paticipants, we can drop those information to make the transcript more clear\n",
    "    df = df.drop(range(df.index[df[0] == 'Company Participants'].tolist()[0],df.index[df[0] == 'MANAGEMENT DISCUSSION SECTION'].tolist()[0]+1))\n",
    "    # Q4 2014 Earnings Call\n",
    "    df.drop(df.index[df[0] == 'Q4 2014 Earnings Call'].tolist(), inplace=True)\n",
    "\n",
    "    # reset the index again to make sure the index is continuous for better processing\n",
    "    df = df.reset_index(drop=True)\n",
    "    # save to csv\n",
    "    df.to_csv('/Users/timliu/Desktop/output/df.csv')\n",
    "    return df, company_paticipants, other_paticipants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [6] [18]\n",
      "==========================\n",
      "the company paticipants is:                            0\n",
      "2              Roland Vogel\n",
      "3             Ulrich Wallin\n",
      "4  Unidentified Participant\n",
      "5    Unverified Participant\n",
      "==========================\n",
      "the other paticipants is:                       0\n",
      "7    Andrew J. Ritchie\n",
      "8            Ben Cohen\n",
      "9      Frank Kopfinger\n",
      "10  Janet Van den Berg\n",
      "11      Kamran Hossain\n",
      "12        Michael Haid\n",
      "13   Olivia S. Brindle\n",
      "14      Peter Casanova\n",
      "15        Rötger Franz\n",
      "16      Thomas Fossard\n",
      "17       Vikram Gandhi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df,company_paticipants,other_paticipants = participants_list(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spilt the text into different df by different participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of both company_paticipants and other_participants\n",
    "# change the company_paticipants to list \n",
    "company_paticipants_list = company_paticipants[0].tolist()\n",
    "other_paticipants_list = other_paticipants[0].tolist()\n",
    "# merge the list\n",
    "both_participants_list = company_paticipants_list + other_paticipants_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a dict to store all the data\n",
    "# participants_dict = {}\n",
    "# for name in both_participants_list:\n",
    "#     participants_dict[name] = pd.DataFrame()\n",
    "# participants_dict\n",
    "\n",
    "# for i in range(len(both_participants_list)):\n",
    "#     participants_1_start = df[df[0] == both_participants_list[i]].index\n",
    "#     collect_index = []\n",
    "#     for i in range(len(participants_1_start)):\n",
    "#         collect_index.append(both_participants_row_index.index(participants_1_start[i]))\n",
    "#         # #  add 1 into the collect_index\n",
    "#     collect_index_end = [x+1 for x in collect_index]\n",
    "#     # get the value of both_participants_row_index by collect_index_end\n",
    "#     participants_1_end = [both_participants_row_index[x] for x in collect_index_end]\n",
    "#     participants_1_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Roland Vogel',\n",
       " 'Ulrich Wallin',\n",
       " 'Unidentified Participant',\n",
       " 'Unverified Participant',\n",
       " 'Andrew J. Ritchie',\n",
       " 'Ben Cohen',\n",
       " 'Frank Kopfinger',\n",
       " 'Janet Van den Berg',\n",
       " 'Kamran Hossain',\n",
       " 'Michael Haid',\n",
       " 'Olivia S. Brindle',\n",
       " 'Peter Casanova',\n",
       " 'Rötger Franz',\n",
       " 'Thomas Fossard',\n",
       " 'Vikram Gandhi']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_participants_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roland Vogel\n",
      "[86, 584, 659, 785, 803, 845, 902, 924, 930, 934] [329, 604, 672, 792, 805, 856, 914, 928, 932, 936]\n",
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# list of both company_paticipants and other_participants\n",
    "# change the company_paticipants to list \n",
    "company_paticipants_list = company_paticipants[0].tolist()\n",
    "other_paticipants_list = other_paticipants[0].tolist()\n",
    "# merge the list\n",
    "both_participants_list = company_paticipants_list + other_paticipants_list\n",
    "\n",
    "# identify all the rows in df with both_participants in it\n",
    "both_participants_row_index = df[df[0].isin(both_participants_list)].index.tolist()\n",
    "both_participants_row_index\n",
    "\n",
    "# identify all the rows in df with both_participants_list[0] in it\n",
    "participants_1_start = df[df[0] == both_participants_list[0]].index\n",
    "participants_1_start\n",
    "\n",
    "\n",
    "collect_index = []\n",
    "for i in range(len(participants_1_start)):\n",
    "    collect_index.append(both_participants_row_index.index(participants_1_start[i]))\n",
    "\n",
    "collect_index\n",
    "#  add 1 into the collect_index\n",
    "collect_index_end = [x+1 for x in collect_index]\n",
    "collect_index, collect_index_end\n",
    "\n",
    "# get the value of both_participants_row_index by collect_index_end\n",
    "participants_1_end = [both_participants_row_index[x] for x in collect_index_end]\n",
    "participants_1_end\n",
    "\n",
    "# participants_1_start to list\n",
    "participants_1_start = participants_1_start.tolist()\n",
    "print(both_participants_list[0])\n",
    "print(participants_1_start, participants_1_end)\n",
    "print(len(participants_1_start), len(participants_1_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 23, 28, 40, 43, 51, 59, 62, 64, 66]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_index_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roland Vogel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes, thank you, Uli. The good thing is that I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Roland Vogel\n",
       "0  Yes, thank you, Uli. The good thing is that I ..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,len(participants_1_start)):\n",
    "    # participants_1 = df.loc[participants_1_start[0]+1:participants_1_end[0]-1]\n",
    "    participants_1 = df.loc[participants_1_start[0]+1:participants_1_end[0]-1]\n",
    "    participants_merge = df.loc[participants_1_start[i]+1:participants_1_end[i]-1]\n",
    "    participants_1 = pd.concat([participants_1, participants_merge])\n",
    "\n",
    "# concat all the rows into singl row\n",
    "participants_1['value'] = 1\n",
    "participants_1 = participants_1.groupby('value')[0].apply(''.join).reset_index()\n",
    "\n",
    "# drop the \"value\" column\n",
    "participants_1.drop(participants_1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# rename the column\n",
    "participants_1.rename(columns={0: both_participants_list[0]}, inplace=True) #################################\n",
    "\n",
    "# save to csv to check\n",
    "participants_1.to_csv('/Users/timliu/Desktop/output/Andrew_J_Ritchie.csv')\n",
    "\n",
    "# the company paticipants is:                            0\n",
    "# 2              Roland Vogel\n",
    "# 3             Ulrich Wallin\n",
    "# 4  Unidentified Participant\n",
    "# 5    Unverified Participant\n",
    "# ==========================\n",
    "# the other paticipants is:                       0\n",
    "# 7    Andrew J. Ritchie\n",
    "# 8            Ben Cohen\n",
    "# 9      Frank Kopfinger\n",
    "# 10  Janet Van den Berg\n",
    "# 11      Kamran Hossain\n",
    "# 12        Michael Haid\n",
    "# 13   Olivia S. Brindle\n",
    "# 14      Peter Casanova\n",
    "# 15        Rötger Franz\n",
    "# 16      Thomas Fossard\n",
    "# 17       Vikram Gandhi\n",
    "\n",
    "participants_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testified the time and date extracted from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>results, even with a little bit of a more depr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>positive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>On the right hand side, the assets under own m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tell you with the development of the U.S. doll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>government bonds, this today is approaching €3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>million have not been used. We, I think, addre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>three quarters that some of that falls down a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>other areas. So, my guidance would not be that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>redundancies. But what we see is that the – wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Q4 was better than before, so you see somethin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name\n",
       "100  results, even with a little bit of a more depr...\n",
       "101                                          positive.\n",
       "102  On the right hand side, the assets under own m...\n",
       "103  tell you with the development of the U.S. doll...\n",
       "104  government bonds, this today is approaching €3...\n",
       "..                                                 ...\n",
       "595  million have not been used. We, I think, addre...\n",
       "596  three quarters that some of that falls down a ...\n",
       "597  other areas. So, my guidance would not be that...\n",
       "598  redundancies. But what we see is that the – wh...\n",
       "599  Q4 was better than before, so you see somethin...\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing = df.iloc[100:600]\n",
    "df_testing.rename(columns={0: 'name'}, inplace=True)\n",
    "df_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>results, even with a little bit of a more depr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>positive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>On the right hand side, the assets under own m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tell you with the development of the U.S. doll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>government bonds, this today is approaching €3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>million have not been used. We, I think, addre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>three quarters that some of that falls down a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>other areas. So, my guidance would not be that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>redundancies. But what we see is that the – wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Q4 was better than before, so you see somethin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name\n",
       "100  results, even with a little bit of a more depr...\n",
       "101                                          positive.\n",
       "102  On the right hand side, the assets under own m...\n",
       "103  tell you with the development of the U.S. doll...\n",
       "104  government bonds, this today is approaching €3...\n",
       "..                                                 ...\n",
       "595  million have not been used. We, I think, addre...\n",
       "596  three quarters that some of that falls down a ...\n",
       "597  other areas. So, my guidance would not be that...\n",
       "598  redundancies. But what we see is that the – wh...\n",
       "599  Q4 was better than before, so you see somethin...\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/sxhsy98j6f57m406rd5lz1_r0000gn/T/ipykernel_89010/1066517891.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing['date_time'] = df_testing['name'].apply(lambda x: find_date_time(x))\n"
     ]
    }
   ],
   "source": [
    "# find all the date and time in the transcript using re\n",
    "def find_date_time(x):\n",
    "    # find the month like 'March'\n",
    "    # list of month\n",
    "    month = [\n",
    "        # month\n",
    "        'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December',\n",
    "        'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
    "        ]\n",
    "    # find the month\n",
    "    month_list = re.findall(r'\\b' + '|'.join(month) + '\\b', x)\n",
    "    # write back to the original df\n",
    "    return month_list\n",
    "\n",
    "    # # find the day like '1st'\n",
    "    # # list of day\n",
    "    # day = [\n",
    "    #     '1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th',\n",
    "    #     '9th', '10th', '11th', '12th', '13th', '14th', '15th',\n",
    "    #     '16th', '17th', '18th', '19th', '20th', '21st', '22nd',\n",
    "    #     '23rd', '24th', '25th', '26th', '27th', '28th', '29th',\n",
    "    #     '30th', '31st'\n",
    "    #     ]\n",
    "    # # find the day\n",
    "    # day_list = re.findall(r'\\b(' + '|'.join(day) + ')\\b', x)\n",
    "    # # print the day_list\n",
    "    # print(day_list)\n",
    "\n",
    "\n",
    "# apply the function to the df_testing apply lambda\n",
    "df_testing['date_time'] = df_testing['name'].apply(lambda x: find_date_time(x))\n",
    "\n",
    "\n",
    "# # list of month\n",
    "# month_list = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "# # list of short month\n",
    "# short_month_list = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "# # find all the month_list or short_month_list inside the participants_1\n",
    "# for i in range(len(month_list)):\n",
    "#     participants_1[month_list[i]] = participants_1[0].str.contains(month_list[i])\n",
    "#     participants_1[short_month_list[i]] = participants_1[0].str.contains(short_month_list[i])\n",
    "\n",
    "# participants_1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([]), list(['April']), list(['February']), list(['June']),\n",
       "       list(['Mar']), list(['October']), list(['September'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_testing['date_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = [\n",
    "    'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December',\n",
    "    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
    "    ]\n",
    "\n",
    "\n",
    "month_list = re.findall(r'\\b(' + '|'.join(month) + ')\\b', df_testing.iloc[19,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sq/sxhsy98j6f57m406rd5lz1_r0000gn/T/ipykernel_89010/1150918621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_date_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/sq/sxhsy98j6f57m406rd5lz1_r0000gn/T/ipykernel_89010/2353169291.py\u001b[0m in \u001b[0;36mfind_date_time\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmonth_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\b(' + '|'.join(month) + ')\\b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# write back to the original df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdf_testing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonth_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# # find the day like '1st'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "for i in range(len(df2)):\n",
    "    list = []\n",
    "    list.append(find_date_time(df2.iloc[i,0]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
